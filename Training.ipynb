{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "R3gv09NjPsOC",
    "outputId": "4f6e4353-6ffc-4f0a-cac7-b3acd0520f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Change google colab working directory\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "my_project_dir = \"/content/drive/My Drive/Colab Notebooks\"\n",
    "os.chdir(my_project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "FCCMl9nfdP9A",
    "outputId": "e51a4762-9943-47a5-ea60-4d744b7f735b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'dummy_dataset_fpga' already exists and is not an empty directory.\n",
      "warning: redirecting to https://gitlab.com/hoquangnam45/dummy_dataset_fpga.git/\n",
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 3 (delta 1), reused 0 (delta 0)\u001b[K\n",
      "Unpacking objects: 100% (3/3), done.\n",
      "From https://gitlab.com/hoquangnam45/dummy_dataset_fpga\n",
      "   ce12ecd..5ef4ef5  master     -> origin/master\n",
      "Updating ce12ecd..5ef4ef5\n",
      "Fast-forward\n",
      " lasagne_mnist.py | 363 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
      " 1 file changed, 363 insertions(+)\n",
      " create mode 100644 lasagne_mnist.py\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull helper repo\n",
    "%%shell\n",
    "git clone https://gitlab.com/hoquangnam45/dummy_dataset_fpga\n",
    "cd ./dummy_dataset_fpga\n",
    "git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F2Byw_JiQN0L",
    "outputId": "0c183285-3e0a-4b77-f23c-086db3542475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNN-PYNQ  dummy_dataset_fpga  Training.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FE0gWB4_RX9j",
    "outputId": "52b27aa1-03d4-4129-e899-614a0e2e37a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-12 06:16:15--  https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1404/x86_64/libcudnn5_5.1.10-1+cuda8.0_amd64.deb\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.211.70, 2606:2800:21f:3aa:dcf:37b:1ed6:1fb\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.211.70|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 41228340 (39M) [application/x-deb]\n",
      "Saving to: ‘/tmp/libcudnn5_5.1.10-1+cuda8.0_amd64.deb’\n",
      "\n",
      "\r",
      "          libcudnn5   0%[                    ]       0  --.-KB/s               \r",
      "         libcudnn5_  69%[============>       ]  27.20M   136MB/s               \r",
      "libcudnn5_5.1.10-1+ 100%[===================>]  39.32M   158MB/s    in 0.2s    \n",
      "\n",
      "2019-10-12 06:16:15 (158 MB/s) - ‘/tmp/libcudnn5_5.1.10-1+cuda8.0_amd64.deb’ saved [41228340/41228340]\n",
      "\n",
      "--2019-10-12 06:16:15--  https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1404/x86_64/libcudnn5-dev_5.1.10-1+cuda8.0_amd64.deb\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.211.70, 2606:2800:21f:3aa:dcf:37b:1ed6:1fb\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.211.70|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33920080 (32M) [application/x-deb]\n",
      "Saving to: ‘/tmp/libcudnn5-dev_5.1.10-1+cuda8.0_amd64.deb’\n",
      "\n",
      "libcudnn5-dev_5.1.1 100%[===================>]  32.35M   167MB/s    in 0.2s    \n",
      "\n",
      "2019-10-12 06:16:15 (167 MB/s) - ‘/tmp/libcudnn5-dev_5.1.10-1+cuda8.0_amd64.deb’ saved [33920080/33920080]\n",
      "\n",
      "--2019-10-12 06:16:15--  http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 192.229.211.70, 2606:2800:21f:3aa:dcf:37b:1ed6:1fb\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|192.229.211.70|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2690 (2.6K) [application/x-deb]\n",
      "Saving to: ‘/tmp/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb’\n",
      "\n",
      "cuda-repo-ubuntu160 100%[===================>]   2.63K  --.-KB/s    in 0s      \n",
      "\n",
      "2019-10-12 06:16:15 (322 MB/s) - ‘/tmp/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb’ saved [2690/2690]\n",
      "\n",
      "Selecting previously unselected package cuda-repo-ubuntu1604.\n",
      "(Reading database ... 131183 files and directories currently installed.)\n",
      "Preparing to unpack .../cuda-repo-ubuntu1604_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-repo-ubuntu1604 (8.0.61-1) ...\n",
      "Setting up cuda-repo-ubuntu1604 (8.0.61-1) ...\n",
      "\n",
      "Configuration file '/etc/apt/sources.list.d/cuda.list'\n",
      " ==> File on system created by you or by a script.\n",
      " ==> File also in package provided by package maintainer.\n",
      "   What would you like to do about it ?  Your options are:\n",
      "    Y or I  : install the package maintainer's version\n",
      "    N or O  : keep your currently-installed version\n",
      "      D     : show the differences between the versions\n",
      "      Z     : start a shell to examine the situation\n",
      " The default action is to keep your current version.\n",
      "*** cuda.list (Y/I/N/O/D/Z) [default=N] ? Y\n",
      "Installing new version of config file /etc/apt/sources.list.d/cuda.list ...\n",
      "Warning: The postinst maintainerscript of the package cuda-repo-ubuntu1604\n",
      "Warning: seems to use apt-key (provided by apt) without depending on gnupg or gnupg2.\n",
      "Warning: This will BREAK in the future and should be fixed by the package maintainer(s).\n",
      "Note: Check first if apt-key functionality is needed at all - it probably isn't!\n",
      "Warning: apt-key should not be used in scripts (called from postinst maintainerscript of the package cuda-repo-ubuntu1604)\n",
      "OK\n",
      "\u001b[1mdpkg:\u001b[0m \u001b[1;31merror:\u001b[0m cannot access archive 'libcudnn5-dev_5.1.10-1+cuda8.0_amd64.deb': No such file or directory\n",
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Ign:2 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Get:3 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release [564 B]\n",
      "Get:4 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release.gpg [819 B]\n",
      "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
      "Get:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
      "Get:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
      "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:10 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Packages [234 kB]\n",
      "Get:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [20.6 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
      "Get:14 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [11.3 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [5,665 B]\n",
      "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [680 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [31.7 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [776 kB]\n",
      "Get:21 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [72.2 kB]\n",
      "Get:22 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,710 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [8,734 B]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [21.9 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,295 kB]\n",
      "Get:26 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [823 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [975 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [4,227 B]\n",
      "Fetched 6,964 kB in 3s (2,029 kB/s)\n",
      "Reading package lists... Done\n",
      "CUDA_HOME=/usr/local/cuda: 1: CUDA_HOME=/usr/local/cuda: Syntax error: Unterminated quoted string\n",
      "export LD_LIBRARY_PATH=\\\\${LD_LIBRARY_PATH}:\\\\${CUDA_HOME}/lib64: 1: export LD_LIBRARY_PATH=\\\\${LD_LIBRARY_PATH}:\\\\${CUDA_HOME}/lib64: Syntax error: Unterminated quoted string\n",
      "export LIBRARY_PATH=\\\\${LIBRARY_PATH}:\\\\${CUDA_HOME}/lib64: 1: export LIBRARY_PATH=\\\\${LIBRARY_PATH}:\\\\${CUDA_HOME}/lib64: Syntax error: Unterminated quoted string\n",
      "export C_INCLUDE_PATH=\\\\${C_INCLUDE_PATH}:\\\\${CUDA_HOME}/include: 1: export C_INCLUDE_PATH=\\\\${C_INCLUDE_PATH}:\\\\${CUDA_HOME}/include: Syntax error: Unterminated quoted string\n",
      "export CXX_INCLUDE_PATH=\\\\${CXX_INCLUDE_PATH}:\\\\${CUDA_HOME}/include: 1: export CXX_INCLUDE_PATH=\\\\${CXX_INCLUDE_PATH}:\\\\${CUDA_HOME}/include: Syntax error: Unterminated quoted string\n",
      "export PATH=\\\\${PATH}:\\\\${CUDA_HOME}/bin: 1: export PATH=\\\\${PATH}:\\\\${CUDA_HOME}/bin: Syntax error: Unterminated quoted string\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Note, selecting 'cuda-8-0' for regex 'cuda-8.0'\n",
      "Note, selecting 'libcuda-8.0-1' for regex 'cuda-8.0'\n",
      "The following additional packages will be installed:\n",
      "  cuda-command-line-tools-8-0 cuda-core-8-0 cuda-cublas-8-0\n",
      "  cuda-cublas-dev-8-0 cuda-cudart-8-0 cuda-cudart-dev-8-0 cuda-cufft-8-0\n",
      "  cuda-cufft-dev-8-0 cuda-curand-8-0 cuda-curand-dev-8-0 cuda-cusolver-8-0\n",
      "  cuda-cusolver-dev-8-0 cuda-cusparse-8-0 cuda-cusparse-dev-8-0\n",
      "  cuda-demo-suite-8-0 cuda-documentation-8-0 cuda-driver-dev-8-0\n",
      "  cuda-license-8-0 cuda-misc-headers-8-0 cuda-npp-8-0 cuda-npp-dev-8-0\n",
      "  cuda-nvgraph-8-0 cuda-nvgraph-dev-8-0 cuda-nvml-dev-8-0 cuda-nvrtc-8-0\n",
      "  cuda-nvrtc-dev-8-0 cuda-runtime-8-0 cuda-samples-8-0 cuda-toolkit-8-0\n",
      "  cuda-visual-tools-8-0\n",
      "The following NEW packages will be installed:\n",
      "  cuda-8-0 cuda-command-line-tools-8-0 cuda-core-8-0 cuda-cublas-8-0\n",
      "  cuda-cublas-dev-8-0 cuda-cudart-8-0 cuda-cudart-dev-8-0 cuda-cufft-8-0\n",
      "  cuda-cufft-dev-8-0 cuda-curand-8-0 cuda-curand-dev-8-0 cuda-cusolver-8-0\n",
      "  cuda-cusolver-dev-8-0 cuda-cusparse-8-0 cuda-cusparse-dev-8-0\n",
      "  cuda-demo-suite-8-0 cuda-documentation-8-0 cuda-driver-dev-8-0\n",
      "  cuda-license-8-0 cuda-misc-headers-8-0 cuda-npp-8-0 cuda-npp-dev-8-0\n",
      "  cuda-nvgraph-8-0 cuda-nvgraph-dev-8-0 cuda-nvml-dev-8-0 cuda-nvrtc-8-0\n",
      "  cuda-nvrtc-dev-8-0 cuda-runtime-8-0 cuda-samples-8-0 cuda-toolkit-8-0\n",
      "  cuda-visual-tools-8-0\n",
      "0 upgraded, 31 newly installed, 0 to remove and 147 not upgraded.\n",
      "Need to get 1,352 MB of archives.\n",
      "After this operation, 2,144 MB of additional disk space will be used.\n",
      "Get:1 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-license-8-0 8.0.61-1 [27.6 kB]\n",
      "Get:2 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-misc-headers-8-0 8.0.61-1 [1,077 kB]\n",
      "Get:3 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-core-8-0 8.0.61-1 [20.0 MB]\n",
      "Get:4 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-cudart-8-0 8.0.61-1 [135 kB]\n",
      "Get:5 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-driver-dev-8-0 8.0.61-1 [14.1 kB]\n",
      "Get:6 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-cudart-dev-8-0 8.0.61-1 [1,071 kB]\n",
      "Get:7 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-command-line-tools-8-0 8.0.61-1 [26.1 MB]\n",
      "Get:8 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-nvrtc-8-0 8.0.61-1 [9,585 kB]\n",
      "Get:9 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-nvrtc-dev-8-0 8.0.61-1 [10.8 kB]\n",
      "Get:10 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-cusolver-8-0 8.0.61-1 [29.3 MB]\n",
      "Get:11 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-cusolver-dev-8-0 8.0.61-1 [6,816 kB]\n",
      "Get:12 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-cublas-8-0 8.0.61.2-1 [58.1 MB]\n",
      "Get:13 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-cublas-dev-8-0 8.0.61.2-1 [66.6 MB]\n",
      "Get:14 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-cufft-8-0 8.0.61-1 [117 MB]\n",
      "Get:15 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-cufft-dev-8-0 8.0.61-1 [94.8 MB]\n",
      "Get:16 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-curand-8-0 8.0.61-1 [43.7 MB]\n",
      "Get:17 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-curand-dev-8-0 8.0.61-1 [67.7 MB]\n",
      "Get:18 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-cusparse-8-0 8.0.61-1 [28.8 MB]\n",
      "Get:19 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-cusparse-dev-8-0 8.0.61-1 [29.6 MB]\n",
      "Get:20 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-npp-8-0 8.0.61-1 [157 MB]\n",
      "Get:21 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-npp-dev-8-0 8.0.61-1 [82.3 MB]\n",
      "Get:22 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-samples-8-0 8.0.61-1 [101 MB]\n",
      "Get:23 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-documentation-8-0 8.0.61-1 [113 MB]\n",
      "Get:24 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-nvml-dev-8-0 8.0.61-1 [48.4 kB]\n",
      "Get:25 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-nvgraph-8-0 8.0.61-1 [2,948 kB]\n",
      "Get:26 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-nvgraph-dev-8-0 8.0.61-1 [3,028 kB]\n",
      "Get:27 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-visual-tools-8-0 8.0.61-1 [286 MB]\n",
      "Get:28 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-toolkit-8-0 8.0.61-1 [2,892 B]\n",
      "Get:29 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-runtime-8-0 8.0.61-1 [2,574 B]\n",
      "Get:30 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-demo-suite-8-0 8.0.61-1 [4,988 kB]\n",
      "Get:31 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  cuda-8-0 8.0.61-1 [2,556 B]\n",
      "Fetched 1,352 MB in 25s (53.6 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 31.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package cuda-license-8-0.\n",
      "(Reading database ... 131186 files and directories currently installed.)\n",
      "Preparing to unpack .../00-cuda-license-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-license-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-misc-headers-8-0.\n",
      "Preparing to unpack .../01-cuda-misc-headers-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-misc-headers-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-core-8-0.\n",
      "Preparing to unpack .../02-cuda-core-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-core-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-cudart-8-0.\n",
      "Preparing to unpack .../03-cuda-cudart-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-cudart-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-driver-dev-8-0.\n",
      "Preparing to unpack .../04-cuda-driver-dev-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-driver-dev-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-cudart-dev-8-0.\n",
      "Preparing to unpack .../05-cuda-cudart-dev-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-cudart-dev-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-command-line-tools-8-0.\n",
      "Preparing to unpack .../06-cuda-command-line-tools-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-command-line-tools-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-nvrtc-8-0.\n",
      "Preparing to unpack .../07-cuda-nvrtc-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-nvrtc-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-nvrtc-dev-8-0.\n",
      "Preparing to unpack .../08-cuda-nvrtc-dev-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-nvrtc-dev-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-cusolver-8-0.\n",
      "Preparing to unpack .../09-cuda-cusolver-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-cusolver-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-cusolver-dev-8-0.\n",
      "Preparing to unpack .../10-cuda-cusolver-dev-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-cusolver-dev-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-cublas-8-0.\n",
      "Preparing to unpack .../11-cuda-cublas-8-0_8.0.61.2-1_amd64.deb ...\n",
      "Unpacking cuda-cublas-8-0 (8.0.61.2-1) ...\n",
      "Selecting previously unselected package cuda-cublas-dev-8-0.\n",
      "Preparing to unpack .../12-cuda-cublas-dev-8-0_8.0.61.2-1_amd64.deb ...\n",
      "Unpacking cuda-cublas-dev-8-0 (8.0.61.2-1) ...\n",
      "Selecting previously unselected package cuda-cufft-8-0.\n",
      "Preparing to unpack .../13-cuda-cufft-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-cufft-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-cufft-dev-8-0.\n",
      "Preparing to unpack .../14-cuda-cufft-dev-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-cufft-dev-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-curand-8-0.\n",
      "Preparing to unpack .../15-cuda-curand-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-curand-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-curand-dev-8-0.\n",
      "Preparing to unpack .../16-cuda-curand-dev-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-curand-dev-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-cusparse-8-0.\n",
      "Preparing to unpack .../17-cuda-cusparse-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-cusparse-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-cusparse-dev-8-0.\n",
      "Preparing to unpack .../18-cuda-cusparse-dev-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-cusparse-dev-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-npp-8-0.\n",
      "Preparing to unpack .../19-cuda-npp-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-npp-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-npp-dev-8-0.\n",
      "Preparing to unpack .../20-cuda-npp-dev-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-npp-dev-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-samples-8-0.\n",
      "Preparing to unpack .../21-cuda-samples-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-samples-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-documentation-8-0.\n",
      "Preparing to unpack .../22-cuda-documentation-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-documentation-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-nvml-dev-8-0.\n",
      "Preparing to unpack .../23-cuda-nvml-dev-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-nvml-dev-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-nvgraph-8-0.\n",
      "Preparing to unpack .../24-cuda-nvgraph-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-nvgraph-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-nvgraph-dev-8-0.\n",
      "Preparing to unpack .../25-cuda-nvgraph-dev-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-nvgraph-dev-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-visual-tools-8-0.\n",
      "Preparing to unpack .../26-cuda-visual-tools-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-visual-tools-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-toolkit-8-0.\n",
      "Preparing to unpack .../27-cuda-toolkit-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-toolkit-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-runtime-8-0.\n",
      "Preparing to unpack .../28-cuda-runtime-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-runtime-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-demo-suite-8-0.\n",
      "Preparing to unpack .../29-cuda-demo-suite-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-demo-suite-8-0 (8.0.61-1) ...\n",
      "Selecting previously unselected package cuda-8-0.\n",
      "Preparing to unpack .../30-cuda-8-0_8.0.61-1_amd64.deb ...\n",
      "Unpacking cuda-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-license-8-0 (8.0.61-1) ...\n",
      "*** LICENSE AGREEMENT ***\n",
      "By using this software you agree to fully comply with the terms and \n",
      "conditions of the EULA (End User License Agreement). The EULA is located\n",
      "at /usr/local/cuda-8.0/doc/EULA.txt. The EULA can also be found at\n",
      "http://docs.nvidia.com/cuda/eula/index.html. If you do not agree to the\n",
      "terms and conditions of the EULA, do not use the software.\n",
      "\n",
      "Setting up cuda-nvgraph-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-cufft-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-npp-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-nvgraph-dev-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-cudart-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-driver-dev-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-cusolver-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-nvml-dev-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-cufft-dev-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-misc-headers-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-cusparse-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-nvrtc-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-nvrtc-dev-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-curand-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-cublas-8-0 (8.0.61.2-1) ...\n",
      "Setting up cuda-cusolver-dev-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-core-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-curand-dev-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-npp-dev-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-cudart-dev-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-cublas-dev-8-0 (8.0.61.2-1) ...\n",
      "Setting up cuda-runtime-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-cusparse-dev-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-command-line-tools-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-demo-suite-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-samples-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-visual-tools-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-documentation-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-toolkit-8-0 (8.0.61-1) ...\n",
      "Setting up cuda-8-0 (8.0.61-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "Ign:1 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Hit:2 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release\n",
      "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Hit:12 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Fetched 163 kB in 1s (131 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  cpp-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0 libstdc++-5-dev\n",
      "Suggested packages:\n",
      "  gcc-5-locales g++-5-multilib gcc-5-doc libstdc++6-5-dbg gcc-5-multilib\n",
      "  libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan2-dbg\n",
      "  liblsan0-dbg libtsan0-dbg libubsan0-dbg libcilkrts5-dbg libmpx0-dbg\n",
      "  libquadmath0-dbg libstdc++-5-doc\n",
      "The following NEW packages will be installed:\n",
      "  cpp-5 g++-5 gcc-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0\n",
      "  libstdc++-5-dev\n",
      "0 upgraded, 9 newly installed, 0 to remove and 147 not upgraded.\n",
      "Need to get 29.1 MB of archives.\n",
      "After this operation, 100 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5-base amd64 5.5.0-12ubuntu1 [17.1 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libisl15 amd64 0.18-4 [548 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cpp-5 amd64 5.5.0-12ubuntu1 [7,785 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libasan2 amd64 5.5.0-12ubuntu1 [264 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmpx0 amd64 5.5.0-12ubuntu1 [9,888 B]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgcc-5-dev amd64 5.5.0-12ubuntu1 [2,224 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5 amd64 5.5.0-12ubuntu1 [8,357 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libstdc++-5-dev amd64 5.5.0-12ubuntu1 [1,415 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 g++-5 amd64 5.5.0-12ubuntu1 [8,450 kB]\n",
      "Fetched 29.1 MB in 7s (4,054 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 9.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package gcc-5-base:amd64.\n",
      "(Reading database ... 140186 files and directories currently installed.)\n",
      "Preparing to unpack .../0-gcc-5-base_5.5.0-12ubuntu1_amd64.deb ...\n",
      "Unpacking gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
      "Selecting previously unselected package libisl15:amd64.\n",
      "Preparing to unpack .../1-libisl15_0.18-4_amd64.deb ...\n",
      "Unpacking libisl15:amd64 (0.18-4) ...\n",
      "Selecting previously unselected package cpp-5.\n",
      "Preparing to unpack .../2-cpp-5_5.5.0-12ubuntu1_amd64.deb ...\n",
      "Unpacking cpp-5 (5.5.0-12ubuntu1) ...\n",
      "Selecting previously unselected package libasan2:amd64.\n",
      "Preparing to unpack .../3-libasan2_5.5.0-12ubuntu1_amd64.deb ...\n",
      "Unpacking libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
      "Selecting previously unselected package libmpx0:amd64.\n",
      "Preparing to unpack .../4-libmpx0_5.5.0-12ubuntu1_amd64.deb ...\n",
      "Unpacking libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
      "Selecting previously unselected package libgcc-5-dev:amd64.\n",
      "Preparing to unpack .../5-libgcc-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
      "Unpacking libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
      "Selecting previously unselected package gcc-5.\n",
      "Preparing to unpack .../6-gcc-5_5.5.0-12ubuntu1_amd64.deb ...\n",
      "Unpacking gcc-5 (5.5.0-12ubuntu1) ...\n",
      "Selecting previously unselected package libstdc++-5-dev:amd64.\n",
      "Preparing to unpack .../7-libstdc++-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
      "Unpacking libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
      "Selecting previously unselected package g++-5.\n",
      "Preparing to unpack .../8-g++-5_5.5.0-12ubuntu1_amd64.deb ...\n",
      "Unpacking g++-5 (5.5.0-12ubuntu1) ...\n",
      "Setting up libisl15:amd64 (0.18-4) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Setting up gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
      "Setting up libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
      "Setting up libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
      "Setting up libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
      "Setting up cpp-5 (5.5.0-12ubuntu1) ...\n",
      "Setting up libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
      "Setting up gcc-5 (5.5.0-12ubuntu1) ...\n",
      "Setting up g++-5 (5.5.0-12ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Ign:3 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Hit:4 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release\n",
      "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Fetched 163 kB in 1s (134 kB/s)\n",
      "Reading package lists... Done\n",
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Ign:3 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Hit:4 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release\n",
      "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Hit:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Fetched 163 kB in 1s (135 kB/s)\n",
      "Reading package lists... Done\n",
      "--2019-10-12 06:17:57--  https://bootstrap.pypa.io/get-pip.py\n",
      "Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.0.175, 151.101.64.175, 151.101.128.175, ...\n",
      "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.0.175|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1775417 (1.7M) [text/x-python]\n",
      "Saving to: ‘/tmp/get-pip.py’\n",
      "\n",
      "get-pip.py          100%[===================>]   1.69M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2019-10-12 06:17:57 (23.6 MB/s) - ‘/tmp/get-pip.py’ saved [1775417/1775417]\n",
      "\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/db/9e38760b32e3e7f40cce46dd5fb107b8c73840df38f0046d8e6514e675a1/pip-19.2.3-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 3.4MB/s \n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.2.3\n",
      "    Uninstalling pip-19.2.3:\n",
      "      Successfully uninstalled pip-19.2.3\n",
      "Successfully installed pip-19.2.3\n",
      "fatal: destination path 'BNN-PYNQ' already exists and is not an empty directory.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "liblapack-dev is already the newest version (3.7.1-4ubuntu1).\n",
      "python-dev is already the newest version (2.7.15~rc1-1).\n",
      "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
      "gfortran is already the newest version (4:7.4.0-1ubuntu2.3).\n",
      "git is already the newest version (1:2.17.1-1ubuntu0.4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 147 not upgraded.\n",
      "Collecting git+https://github.com/Theano/Theano.git\n",
      "  Cloning https://github.com/Theano/Theano.git to /tmp/pip-req-build-wUBeRN\n",
      "  Running command git clone -q https://github.com/Theano/Theano.git /tmp/pip-req-build-wUBeRN\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python2.7/dist-packages (from Theano==1.0.4+21.g8f510a1f0) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python2.7/dist-packages (from Theano==1.0.4+21.g8f510a1f0) (1.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from Theano==1.0.4+21.g8f510a1f0) (1.12.0)\n",
      "Building wheels for collected packages: Theano\n",
      "  Building wheel for Theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for Theano: filename=Theano-1.0.4+21.g8f510a1f0-cp27-none-any.whl size=2667498 sha256=d3a2a6e1a6ecd1bf5d624322961cad84a6dd46fe03313e5f8a5c4af31bb76a9d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-Dm3I71/wheels/14/72/17/35fc1366380e8e05fc8ed5d44e24a2da28ef975aa4be6aaa17\n",
      "Successfully built Theano\n",
      "Installing collected packages: Theano\n",
      "  Found existing installation: Theano 1.0.4\n",
      "    Uninstalling Theano-1.0.4:\n",
      "      Successfully uninstalled Theano-1.0.4\n",
      "Successfully installed Theano-1.0.4+21.g8f510a1f0\n",
      "Collecting https://github.com/Lasagne/Lasagne/archive/master.zip\n",
      "\u001b[?25l  Downloading https://github.com/Lasagne/Lasagne/archive/master.zip\n",
      "\u001b[K     | 1.5MB 3.7MB/s\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python2.7/dist-packages (from Lasagne==0.2.dev1) (1.16.4)\n",
      "Building wheels for collected packages: Lasagne\n",
      "  Building wheel for Lasagne (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for Lasagne: filename=Lasagne-0.2.dev1-cp27-none-any.whl size=122749 sha256=18c2b4332cc06880b2763d8a72b004e8e1e19c38aab3da6866d6b15bd39ff7c5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-afzgBJ/wheels/ca/4a/00/87f1777b229481fe76562df7c0cfb993bc88ed0cc37e3f0ed4\n",
      "Successfully built Lasagne\n",
      "Installing collected packages: Lasagne\n",
      "Successfully installed Lasagne-0.2.dev1\n",
      "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
      "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
      "Ign:3 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease\n",
      "Hit:4 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release\n",
      "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Hit:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Fetched 163 kB in 1s (133 kB/s)\n",
      "Reading package lists... Done\n",
      "Cloning into 'libgpuarray'...\n",
      "remote: Enumerating objects: 11420, done.\u001b[K\n",
      "remote: Total 11420 (delta 0), reused 0 (delta 0), pack-reused 11420\u001b[K\n",
      "Receiving objects: 100% (11420/11420), 2.59 MiB | 15.13 MiB/s, done.\n",
      "Resolving deltas: 100% (8380/8380), done.\n",
      "-- The C compiler identification is GNU 7.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Looking for strlcat\n",
      "-- Looking for strlcat - not found\n",
      "-- Looking for mkstemp\n",
      "-- Looking for mkstemp - found\n",
      "-- Found PkgConfig: /usr/bin/pkg-config (found version \"0.29.1\") \n",
      "-- Checking for one of the modules 'check'\n",
      "Tests disabled because Check was not found\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /tmp/libgpuarray/build\n",
      "2\n",
      "[  1%] \u001b[34m\u001b[1mGenerating ../../src/cluda_opencl.h.c\u001b[0m\n",
      "[  2%] \u001b[34m\u001b[1mGenerating ../../src/cluda_cuda.h.c\u001b[0m\n",
      "[  3%] \u001b[34m\u001b[1mGenerating ../../src/cluda_opencl.h.c\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target gpuarray-static\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target gpuarray\u001b[0m\n",
      "[  5%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/cache/lru.c.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/cache/twoq.c.o\u001b[0m\n",
      "[  7%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/cache/lru.c.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/cache/disk.c.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/cache/twoq.c.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_types.c.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_error.c.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_util.c.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_buffer.c.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/cache/disk.c.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_buffer_blas.c.o\u001b[0m\n",
      "[ 18%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_buffer_collectives.c.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_types.c.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_array.c.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_array_blas.c.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_error.c.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_util.c.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_buffer.c.o\u001b[0m\n",
      "[ 27%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_array_collectives.c.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_buffer_blas.c.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_kernel.c.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_buffer_collectives.c.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_extension.c.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_array.c.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_array_blas.c.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_elemwise.c.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_reduction.c.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_array_collectives.c.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_buffer_cuda.c.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_kernel.c.o\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_extension.c.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_blas_cuda_cublas.c.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_elemwise.c.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_reduction.c.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_collectives_cuda_nccl.c.o\u001b[0m\n",
      "[ 48%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_buffer_opencl.c.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_blas_opencl_clblas.c.o\u001b[0m\n",
      "[ 51%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_buffer_cuda.c.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_blas_cuda_cublas.c.o\u001b[0m\n",
      "\u001b[01m\u001b[K/tmp/libgpuarray/src/gpuarray_buffer_opencl.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcl_memset\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/tmp/libgpuarray/src/gpuarray_buffer_opencl.c:969:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Km\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kk->refcnt--\u001b[m\u001b[K;\n",
      "   \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/tmp/libgpuarray/src/gpuarray_buffer_opencl.c:690:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[Km\u001b[m\u001b[K’ was declared here\n",
      "   gpukernel *\u001b[01;36m\u001b[Km\u001b[m\u001b[K;\n",
      "              \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "[ 53%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_blas_opencl_clblast.c.o\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_collectives_cuda_nccl.c.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_buffer_opencl.c.o\u001b[0m\n",
      "[ 57%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/gpuarray_strl.c.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_blas_opencl_clblas.c.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/util/strb.c.o\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/util/error.c.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_blas_opencl_clblast.c.o\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/util/xxhash.c.o\u001b[0m\n",
      "[ 65%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/util/integerfactoring.c.o\u001b[0m\n",
      "\u001b[01m\u001b[K/tmp/libgpuarray/src/gpuarray_buffer_opencl.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcl_memset\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K/tmp/libgpuarray/src/gpuarray_buffer_opencl.c:969:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Km\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kk->refcnt--\u001b[m\u001b[K;\n",
      "   \u001b[01;35m\u001b[K~~~~~~~~~^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K/tmp/libgpuarray/src/gpuarray_buffer_opencl.c:690:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[Km\u001b[m\u001b[K’ was declared here\n",
      "   gpukernel *\u001b[01;36m\u001b[Km\u001b[m\u001b[K;\n",
      "              \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "[ 66%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/util/skein.c.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/gpuarray_strl.c.o\u001b[0m\n",
      "[ 68%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/util/strb.c.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/util/error.c.o\u001b[0m\n",
      "[ 71%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/util/xxhash.c.o\u001b[0m\n",
      "[ 72%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/loaders/dyn_load.c.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/util/integerfactoring.c.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/loaders/libcuda.c.o\u001b[0m\n",
      "[ 76%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/util/skein.c.o\u001b[0m\n",
      "[ 77%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/loaders/libnvrtc.c.o\u001b[0m\n",
      "[ 78%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/loaders/libcublas.c.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/loaders/libnccl.c.o\u001b[0m\n",
      "[ 81%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/loaders/libopencl.c.o\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/loaders/dyn_load.c.o\u001b[0m\n",
      "[ 83%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/loaders/libclblas.c.o\u001b[0m\n",
      "[ 85%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/loaders/libcuda.c.o\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/loaders/libnvrtc.c.o\u001b[0m\n",
      "[ 87%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray-static.dir/loaders/libclblast.c.o\u001b[0m\n",
      "[ 88%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/loaders/libcublas.c.o\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/loaders/libnccl.c.o\u001b[0m\n",
      "[ 91%] \u001b[32m\u001b[1mLinking C static library ../../lib/libgpuarray-static.a\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/loaders/libopencl.c.o\u001b[0m\n",
      "[ 93%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/loaders/libclblas.c.o\u001b[0m\n",
      "[ 95%] Built target gpuarray-static\n",
      "[ 96%] \u001b[32mBuilding C object src/CMakeFiles/gpuarray.dir/loaders/libclblast.c.o\u001b[0m\n",
      "[ 97%] \u001b[32m\u001b[1mLinking C shared library ../../lib/libgpuarray.so\u001b[0m\n",
      "[100%] Built target gpuarray\n",
      "[ 50%] Built target gpuarray-static\n",
      "[100%] Built target gpuarray\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "-- Installing: /usr/local/include/gpuarray/array.h\n",
      "-- Installing: /usr/local/include/gpuarray/blas.h\n",
      "-- Installing: /usr/local/include/gpuarray/collectives.h\n",
      "-- Installing: /usr/local/include/gpuarray/buffer.h\n",
      "-- Installing: /usr/local/include/gpuarray/buffer_blas.h\n",
      "-- Installing: /usr/local/include/gpuarray/buffer_collectives.h\n",
      "-- Installing: /usr/local/include/gpuarray/abi_version.h\n",
      "-- Installing: /usr/local/include/gpuarray/config.h\n",
      "-- Installing: /usr/local/include/gpuarray/elemwise.h\n",
      "-- Installing: /usr/local/include/gpuarray/error.h\n",
      "-- Installing: /usr/local/include/gpuarray/extension.h\n",
      "-- Installing: /usr/local/include/gpuarray/ext_cuda.h\n",
      "-- Installing: /usr/local/include/gpuarray/kernel.h\n",
      "-- Installing: /usr/local/include/gpuarray/types.h\n",
      "-- Installing: /usr/local/include/gpuarray/util.h\n",
      "-- Installing: /usr/local/lib/libgpuarray.so.3.0\n",
      "-- Installing: /usr/local/lib/libgpuarray.so.3\n",
      "-- Installing: /usr/local/lib/libgpuarray.so\n",
      "-- Installing: /usr/local/lib/libgpuarray-static.a\n",
      "Compiling pygpu/gpuarray.pyx because it changed.\n",
      "Compiling pygpu/blas.pyx because it changed.\n",
      "Compiling pygpu/_elemwise.pyx because it changed.\n",
      "Compiling pygpu/collectives.pyx because it changed.\n",
      "[1/4] Cythonizing pygpu/_elemwise.pyx\n",
      "/usr/local/lib/python2.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/libgpuarray/pygpu/_elemwise.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "[2/4] Cythonizing pygpu/blas.pyx\n",
      "/usr/local/lib/python2.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/libgpuarray/pygpu/blas.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "[3/4] Cythonizing pygpu/collectives.pyx\n",
      "/usr/local/lib/python2.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/libgpuarray/pygpu/collectives.pxd\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "[4/4] Cythonizing pygpu/gpuarray.pyx\n",
      "/usr/local/lib/python2.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/libgpuarray/pygpu/gpuarray.pxd\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "running build\n",
      "running build_py\n",
      "creating build/lib.linux-x86_64-2.7\n",
      "creating build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/tools.py -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/basic.py -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/__init__.py -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/dtypes.py -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/operations.py -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/reduction.py -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/_version.py -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/elemwise.py -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/_array.py -> build/lib.linux-x86_64-2.7/pygpu\n",
      "creating build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "copying pygpu/tests/test_blas.py -> build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "copying pygpu/tests/test_operations.py -> build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "copying pygpu/tests/main.py -> build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "copying pygpu/tests/test_elemwise.py -> build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "copying pygpu/tests/test_collectives.py -> build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "copying pygpu/tests/support.py -> build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "copying pygpu/tests/__init__.py -> build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "copying pygpu/tests/test_gpu_ndarray.py -> build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "copying pygpu/tests/test_reduction.py -> build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "copying pygpu/tests/test_tools.py -> build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "copying pygpu/tests/test_basic.py -> build/lib.linux-x86_64-2.7/pygpu/tests\n",
      "running egg_info\n",
      "creating pygpu.egg-info\n",
      "writing requirements to pygpu.egg-info/requires.txt\n",
      "writing pygpu.egg-info/PKG-INFO\n",
      "writing top-level names to pygpu.egg-info/top_level.txt\n",
      "writing dependency_links to pygpu.egg-info/dependency_links.txt\n",
      "writing manifest file 'pygpu.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "writing manifest file 'pygpu.egg-info/SOURCES.txt'\n",
      "copying pygpu/_elemwise.c -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/_elemwise.pyx -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/blas.c -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/blas.pyx -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/collectives.c -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/collectives.pxd -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/collectives.pyx -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/gpuarray.c -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/gpuarray.pxd -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/gpuarray.pyx -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/numpy_compat.h -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/gpuarray.h -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/gpuarray_api.h -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/blas_api.h -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/collectives.h -> build/lib.linux-x86_64-2.7/pygpu\n",
      "copying pygpu/collectives_api.h -> build/lib.linux-x86_64-2.7/pygpu\n",
      "UPDATING build/lib.linux-x86_64-2.7/pygpu/_version.py\n",
      "set build/lib.linux-x86_64-2.7/pygpu/_version.py to '0.7.6+20.g9cec614'\n",
      "running build_ext\n",
      "building 'pygpu.gpuarray' extension\n",
      "creating build/temp.linux-x86_64-2.7\n",
      "creating build/temp.linux-x86_64-2.7/pygpu\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -DGPUARRAY_SHARED -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I/usr/include/python2.7 -c pygpu/gpuarray.c -o build/temp.linux-x86_64-2.7/pygpu/gpuarray.o\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kpygpu/gpuarray.c:627\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/gpuarray.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_8GpuArray___index_helper\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kpygpu/gpuarray.c:20843:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KPySlice_GetIndicesEx\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
      "     __pyx_t_9 = PySlice_GetIndicesEx(\u001b[01;35m\u001b[K__pyx_v_key\u001b[m\u001b[K, (__pyx_v_self->ga.dimensions[__pyx_v_i]), ((Py_ssize_t *)__pyx_v_start), ((Py_ssize_t *)__pyx_v_stop), ((Py_ssize_t *)__pyx_v_step), (&__pyx_v_dummy)); if (unlikely(__pyx_t_9 == ((int)-1))) __PYX_ERR(0, 1607, __pyx_L1_error)\n",
      "                                      \u001b[01;35m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/python2.7/Python.h:115:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kpygpu/gpuarray.c:32\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/python2.7/sliceobject.h:37:17:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[KPySliceObject * {aka struct <anonymous> *}\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[KPyObject * {aka struct _object *}\u001b[m\u001b[K’\n",
      " PyAPI_FUNC(int) \u001b[01;36m\u001b[KPySlice_GetIndicesEx\u001b[m\u001b[K(PySliceObject *r, Py_ssize_t length,\n",
      "                 \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "At top level:\n",
      "\u001b[01m\u001b[Kpygpu/gpuarray.c:21968:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_pw_5pygpu_8gpuarray_8GpuArray_17__bool__\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
      " static int \u001b[01;35m\u001b[K__pyx_pw_5pygpu_8gpuarray_8GpuArray_17__bool__\u001b[m\u001b[K(PyObject *__pyx_v_self) {\n",
      "            \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security -Wl,-Bsymbolic-functions -Wl,-z,relro -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security build/temp.linux-x86_64-2.7/pygpu/gpuarray.o -lgpuarray -o build/lib.linux-x86_64-2.7/pygpu/gpuarray.so\n",
      "building 'pygpu.blas' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -DGPUARRAY_SHARED -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I/usr/include/python2.7 -c pygpu/blas.c -o build/temp.linux-x86_64-2.7/pygpu/blas.o\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kpygpu/blas.c:627\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1725:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_concatenate\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_concatenate\u001b[m\u001b[K)(GpuArray const **, size_t, unsigned int, int, PyObject *, struct PyGpuContextObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1724:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transfer\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transfer\u001b[m\u001b[K)(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1723:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transpose\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transpose\u001b[m\u001b[K)(struct PyGpuArrayObject *, unsigned int const *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1722:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_reshape\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_reshape\u001b[m\u001b[K)(struct PyGpuArrayObject *, unsigned int, size_t const *, ga_order, int, int); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1721:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_index\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_index\u001b[m\u001b[K)(struct PyGpuArrayObject *, Py_ssize_t const *, Py_ssize_t const *, Py_ssize_t const *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1720:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_as_ndarray\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static PyArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_as_ndarray\u001b[m\u001b[K)(struct PyGpuArrayObject *); /*proto*/\n",
      "                         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1719:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_empty_like\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_empty_like\u001b[m\u001b[K)(struct PyGpuArrayObject *, ga_order, int); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1718:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_sync\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_sync\u001b[m\u001b[K)(struct PyGpuArrayObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1717:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_view\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_view\u001b[m\u001b[K)(struct PyGpuArrayObject *, PyObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1716:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_move\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_move\u001b[m\u001b[K)(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1714:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_fromgpudata\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_fromgpudata\u001b[m\u001b[K)(gpudata *, size_t, int, unsigned int, size_t const *, Py_ssize_t const *, struct PyGpuContextObject *, int, PyObject *, PyObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1711:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_init\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuContextObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_init\u001b[m\u001b[K)(PyObject *, gpucontext_props *); /*proto*/\n",
      "                                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1710:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_GpuArray_Check\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_GpuArray_Check\u001b[m\u001b[K)(PyObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1709:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_default_context\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuContextObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_default_context\u001b[m\u001b[K)(void); /*proto*/\n",
      "                                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1708:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_get_typecode\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_get_typecode\u001b[m\u001b[K)(PyObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/blas.c:1707:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_typecode_to_dtype\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static PyArray_Descr *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_typecode_to_dtype\u001b[m\u001b[K)(int); /*proto*/\n",
      "                         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security -Wl,-Bsymbolic-functions -Wl,-z,relro -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security build/temp.linux-x86_64-2.7/pygpu/blas.o -lgpuarray -o build/lib.linux-x86_64-2.7/pygpu/blas.so\n",
      "building 'pygpu._elemwise' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -DGPUARRAY_SHARED -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I/usr/include/python2.7 -c pygpu/_elemwise.c -o build/temp.linux-x86_64-2.7/pygpu/_elemwise.o\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kpygpu/_elemwise.c:627\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_5pygpu_9_elemwise_3arg_2__init__\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:2408:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[Kfree\u001b[m\u001b[K’ discards ‘\u001b[01m\u001b[Kconst\u001b[m\u001b[K’ qualifier from pointer target type [\u001b[01;35m\u001b[K-Wdiscarded-qualifiers\u001b[m\u001b[K]\n",
      "   free(\u001b[01;35m\u001b[K__pyx_v_self\u001b[m\u001b[K->a.name);\n",
      "        \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/python2.7/Python.h:42:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kpygpu/_elemwise.c:32\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/stdlib.h:563:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid *\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kconst char *\u001b[m\u001b[K’\n",
      " extern void \u001b[01;36m\u001b[Kfree\u001b[m\u001b[K (void *__ptr) __THROW;\n",
      "             \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__pyx_pf_5pygpu_9_elemwise_3arg_4__dealloc__\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:2650:8:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[Kfree\u001b[m\u001b[K’ discards ‘\u001b[01m\u001b[Kconst\u001b[m\u001b[K’ qualifier from pointer target type [\u001b[01;35m\u001b[K-Wdiscarded-qualifiers\u001b[m\u001b[K]\n",
      "   free(\u001b[01;35m\u001b[K__pyx_v_self\u001b[m\u001b[K->a.name);\n",
      "        \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/python2.7/Python.h:42:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kpygpu/_elemwise.c:32\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/stdlib.h:563:13:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid *\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kconst char *\u001b[m\u001b[K’\n",
      " extern void \u001b[01;36m\u001b[Kfree\u001b[m\u001b[K (void *__ptr) __THROW;\n",
      "             \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "At top level:\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1931:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_concatenate\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_concatenate\u001b[m\u001b[K)(GpuArray const **, size_t, unsigned int, int, PyObject *, struct PyGpuContextObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1930:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transfer\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transfer\u001b[m\u001b[K)(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1929:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transpose\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transpose\u001b[m\u001b[K)(struct PyGpuArrayObject *, unsigned int const *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1928:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_reshape\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_reshape\u001b[m\u001b[K)(struct PyGpuArrayObject *, unsigned int, size_t const *, ga_order, int, int); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1927:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_index\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_index\u001b[m\u001b[K)(struct PyGpuArrayObject *, Py_ssize_t const *, Py_ssize_t const *, Py_ssize_t const *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1926:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_as_ndarray\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static PyArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_as_ndarray\u001b[m\u001b[K)(struct PyGpuArrayObject *); /*proto*/\n",
      "                         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1925:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_empty_like\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_empty_like\u001b[m\u001b[K)(struct PyGpuArrayObject *, ga_order, int); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1924:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_sync\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_sync\u001b[m\u001b[K)(struct PyGpuArrayObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1923:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_view\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_view\u001b[m\u001b[K)(struct PyGpuArrayObject *, PyObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1922:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_move\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_move\u001b[m\u001b[K)(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1921:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_copy\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_copy\u001b[m\u001b[K)(struct PyGpuArrayObject *, ga_order); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1920:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_fromgpudata\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_fromgpudata\u001b[m\u001b[K)(gpudata *, size_t, int, unsigned int, size_t const *, Py_ssize_t const *, struct PyGpuContextObject *, int, PyObject *, PyObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1919:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_empty\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_empty\u001b[m\u001b[K)(unsigned int, size_t const *, int, ga_order, struct PyGpuContextObject *, PyObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1918:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_zeros\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_zeros\u001b[m\u001b[K)(unsigned int, size_t const *, int, ga_order, struct PyGpuContextObject *, PyObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1917:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_init\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuContextObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_init\u001b[m\u001b[K)(PyObject *, gpucontext_props *); /*proto*/\n",
      "                                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1916:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_GpuArray_Check\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_GpuArray_Check\u001b[m\u001b[K)(PyObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/_elemwise.c:1915:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_default_context\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuContextObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_default_context\u001b[m\u001b[K)(void); /*proto*/\n",
      "                                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security -Wl,-Bsymbolic-functions -Wl,-z,relro -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security build/temp.linux-x86_64-2.7/pygpu/_elemwise.o -lgpuarray -o build/lib.linux-x86_64-2.7/pygpu/_elemwise.so\n",
      "building 'pygpu.collectives' extension\n",
      "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -fno-strict-aliasing -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -DGPUARRAY_SHARED -I/usr/local/lib/python2.7/dist-packages/numpy/core/include -I/usr/include/python2.7 -c pygpu/collectives.c -o build/temp.linux-x86_64-2.7/pygpu/collectives.o\n",
      "In file included from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kpygpu/collectives.c:627\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/lib/python2.7/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
      " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
      "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2417:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_concatenate\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_concatenate\u001b[m\u001b[K)(GpuArray const **, size_t, unsigned int, int, PyObject *, struct PyGpuContextObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2416:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transfer\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transfer\u001b[m\u001b[K)(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2415:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transpose\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_transpose\u001b[m\u001b[K)(struct PyGpuArrayObject *, unsigned int const *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2414:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_reshape\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_reshape\u001b[m\u001b[K)(struct PyGpuArrayObject *, unsigned int, size_t const *, ga_order, int, int); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2413:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_index\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_index\u001b[m\u001b[K)(struct PyGpuArrayObject *, Py_ssize_t const *, Py_ssize_t const *, Py_ssize_t const *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2412:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_as_ndarray\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static PyArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_as_ndarray\u001b[m\u001b[K)(struct PyGpuArrayObject *); /*proto*/\n",
      "                         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2410:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_sync\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_sync\u001b[m\u001b[K)(struct PyGpuArrayObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2409:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_view\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_view\u001b[m\u001b[K)(struct PyGpuArrayObject *, PyObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2408:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_move\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_move\u001b[m\u001b[K)(struct PyGpuArrayObject *, struct PyGpuArrayObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2407:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_copy\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_copy\u001b[m\u001b[K)(struct PyGpuArrayObject *, ga_order); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2406:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_fromgpudata\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_fromgpudata\u001b[m\u001b[K)(gpudata *, size_t, int, unsigned int, size_t const *, Py_ssize_t const *, struct PyGpuContextObject *, int, PyObject *, PyObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2404:35:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_zeros\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuArrayObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_zeros\u001b[m\u001b[K)(unsigned int, size_t const *, int, ga_order, struct PyGpuContextObject *, PyObject *); /*proto*/\n",
      "                                   \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2403:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_init\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuContextObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_init\u001b[m\u001b[K)(PyObject *, gpucontext_props *); /*proto*/\n",
      "                                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2402:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_GpuArray_Check\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_GpuArray_Check\u001b[m\u001b[K)(PyObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2401:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_default_context\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static struct PyGpuContextObject *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_pygpu_default_context\u001b[m\u001b[K)(void); /*proto*/\n",
      "                                     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2399:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_get_typecode\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static int (*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_get_typecode\u001b[m\u001b[K)(PyObject *); /*proto*/\n",
      "              \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[Kpygpu/collectives.c:2398:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__pyx_f_5pygpu_8gpuarray_typecode_to_dtype\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
      " static PyArray_Descr *(*\u001b[01;35m\u001b[K__pyx_f_5pygpu_8gpuarray_typecode_to_dtype\u001b[m\u001b[K)(int); /*proto*/\n",
      "                         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -fno-strict-aliasing -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security -Wl,-Bsymbolic-functions -Wl,-z,relro -Wdate-time -D_FORTIFY_SOURCE=2 -g -fdebug-prefix-map=/build/python2.7-MW0004/python2.7-2.7.15=. -fstack-protector-strong -Wformat -Werror=format-security build/temp.linux-x86_64-2.7/pygpu/collectives.o -lgpuarray -o build/lib.linux-x86_64-2.7/pygpu/collectives.so\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing requirements to pygpu.egg-info/requires.txt\n",
      "writing pygpu.egg-info/PKG-INFO\n",
      "writing top-level names to pygpu.egg-info/top_level.txt\n",
      "writing dependency_links to pygpu.egg-info/dependency_links.txt\n",
      "reading manifest template 'MANIFEST.in'\n",
      "writing manifest file 'pygpu.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "UPDATING build/lib.linux-x86_64-2.7/pygpu/_version.py\n",
      "set build/lib.linux-x86_64-2.7/pygpu/_version.py to '0.7.6+20.g9cec614'\n",
      "running build_ext\n",
      "creating build/bdist.linux-x86_64\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/gpuarray.h -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/gpuarray_api.h -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/numpy_compat.h -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/blas.c -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/_elemwise.so -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/collectives.pxd -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/gpuarray.pyx -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tools.py -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/_elemwise.pyx -> build/bdist.linux-x86_64/egg/pygpu\n",
      "creating build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tests/test_blas.py -> build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tests/test_operations.py -> build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tests/main.py -> build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tests/test_elemwise.py -> build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tests/test_collectives.py -> build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tests/support.py -> build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tests/__init__.py -> build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tests/test_gpu_ndarray.py -> build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tests/test_reduction.py -> build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tests/test_tools.py -> build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/tests/test_basic.py -> build/bdist.linux-x86_64/egg/pygpu/tests\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/basic.py -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/collectives_api.h -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/collectives.h -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/collectives.c -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/blas_api.h -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/collectives.pyx -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/__init__.py -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/dtypes.py -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/gpuarray.so -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/operations.py -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/blas.pyx -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/reduction.py -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/gpuarray.pxd -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/_version.py -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/blas.so -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/gpuarray.c -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/_elemwise.c -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/collectives.so -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/elemwise.py -> build/bdist.linux-x86_64/egg/pygpu\n",
      "copying build/lib.linux-x86_64-2.7/pygpu/_array.py -> build/bdist.linux-x86_64/egg/pygpu\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tools.py to tools.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tests/test_blas.py to test_blas.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tests/test_operations.py to test_operations.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tests/main.py to main.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tests/test_elemwise.py to test_elemwise.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tests/test_collectives.py to test_collectives.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tests/support.py to support.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tests/__init__.py to __init__.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tests/test_gpu_ndarray.py to test_gpu_ndarray.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tests/test_reduction.py to test_reduction.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tests/test_tools.py to test_tools.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/tests/test_basic.py to test_basic.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/basic.py to basic.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/__init__.py to __init__.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/dtypes.py to dtypes.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/operations.py to operations.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/reduction.py to reduction.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/_version.py to _version.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/elemwise.py to elemwise.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/_array.py to _array.pyc\n",
      "creating stub loader for pygpu/gpuarray.so\n",
      "creating stub loader for pygpu/blas.so\n",
      "creating stub loader for pygpu/_elemwise.so\n",
      "creating stub loader for pygpu/collectives.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/gpuarray.py to gpuarray.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/blas.py to blas.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/_elemwise.py to _elemwise.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/pygpu/collectives.py to collectives.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pygpu.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pygpu.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pygpu.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pygpu.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying pygpu.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "pygpu.__init__: module references __file__\n",
      "pygpu.tests.main: module references __file__\n",
      "creating dist\n",
      "creating 'dist/pygpu-0.7.6+20.g9cec614-py2.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing pygpu-0.7.6+20.g9cec614-py2.7-linux-x86_64.egg\n",
      "creating /usr/local/lib/python2.7/dist-packages/pygpu-0.7.6+20.g9cec614-py2.7-linux-x86_64.egg\n",
      "Extracting pygpu-0.7.6+20.g9cec614-py2.7-linux-x86_64.egg to /usr/local/lib/python2.7/dist-packages\n",
      "Adding pygpu 0.7.6+20.g9cec614 to easy-install.pth file\n",
      "\n",
      "Installed /usr/local/lib/python2.7/dist-packages/pygpu-0.7.6+20.g9cec614-py2.7-linux-x86_64.egg\n",
      "Processing dependencies for pygpu==0.7.6+20.g9cec614\n",
      "Searching for mako>=0.7\n",
      "Reading https://pypi.org/simple/mako/\n",
      "Downloading https://files.pythonhosted.org/packages/b0/3c/8dcd6883d009f7cae0f3157fb53e9afb05a0d3d33b3db1268ec2e6f4a56b/Mako-1.1.0.tar.gz#sha256=a36919599a9b7dc5d86a7a8988f23a9a3a3d083070023bab23d64f7f1d1e0a4b\n",
      "Best match: Mako 1.1.0\n",
      "Processing Mako-1.1.0.tar.gz\n",
      "Writing /tmp/easy_install-t2ek9M/Mako-1.1.0/setup.cfg\n",
      "Running Mako-1.1.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-t2ek9M/Mako-1.1.0/egg-dist-tmp-HbVmOJ\n",
      "warning: no files found matching '*.mako' under directory 'doc'\n",
      "warning: no files found matching '*.xml' under directory 'examples'\n",
      "warning: no files found matching '*.mako' under directory 'examples'\n",
      "no previously-included directories found matching 'doc/build/output'\n",
      "creating /usr/local/lib/python2.7/dist-packages/Mako-1.1.0-py2.7.egg\n",
      "Extracting Mako-1.1.0-py2.7.egg to /usr/local/lib/python2.7/dist-packages\n",
      "Adding Mako 1.1.0 to easy-install.pth file\n",
      "Installing mako-render script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python2.7/dist-packages/Mako-1.1.0-py2.7.egg\n",
      "Searching for six==1.12.0\n",
      "Best match: six 1.12.0\n",
      "Adding six 1.12.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python2.7/dist-packages\n",
      "Searching for MarkupSafe==1.1.1\n",
      "Best match: MarkupSafe 1.1.1\n",
      "Adding MarkupSafe 1.1.1 to easy-install.pth file\n",
      "\n",
      "Using /usr/local/lib/python2.7/dist-packages\n",
      "Finished processing dependencies for pygpu==0.7.6+20.g9cec614\n",
      "\tlibgpuarray.so.3 (libc6,x86-64) => /usr/local/lib/libgpuarray.so.3\n",
      "\tlibgpuarray.so (libc6,x86-64) => /usr/local/lib/libgpuarray.so\n",
      "Set up has finished\n"
     ]
    }
   ],
   "source": [
    "# Setup CUDA library for GPU training\n",
    "!chmod +x ./dummy_dataset_fpga/train.sh\n",
    "!./dummy_dataset_fpga/train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "kj9FWrnjQ1ML",
    "outputId": "f540ad86-6996-41a1-b952-d5e8eaed0bbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[global]\n",
      "floatX = float32\n",
      "device = cuda\n",
      "openmp = True\n",
      "openmp_elemwise_minsize = 200000\n",
      "\n",
      "[nvcc]\n",
      "fastmath = True\n",
      "\n",
      "[blas]\n",
      "ldflags = -lopenblas\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup theano to use GPU\n",
    "%%shell\n",
    "rm -rf ~/.theanorc\n",
    "\n",
    "echo \"[global]\" >> ~/.theanorc\n",
    "\n",
    "echo \"floatX = float32\" >> ~/.theanorc\n",
    "\n",
    "echo \"device = cuda\" >> ~/.theanorc\n",
    "\n",
    "echo \"openmp = True\" >> ~/.theanorc\n",
    "\n",
    "echo \"openmp_elemwise_minsize = 200000\" >> ~/.theanorc\n",
    "\n",
    "echo \"\" >> ~/.theanorc\n",
    "\n",
    "echo \"[nvcc]\" >> ~/.theanorc\n",
    "\n",
    "echo \"fastmath = True\" >> ~/.theanorc\n",
    "\n",
    "echo \"\" >> ~/.theanorc\n",
    "\n",
    "echo \"[blas]\" >> ~/.theanorc\n",
    "\n",
    "echo \"ldflags = -lopenblas\" >> ~/.theanorc\n",
    "\n",
    "cat ~/.theanorc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "wIcGFNRiCXTm",
    "outputId": "0b105293-ca63-440d-e23c-6ad4240aa906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Shell python path #\n",
      "['/content/drive/My Drive/Colab Notebooks/dummy_dataset_fpga', '/env/python', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/local/lib/python2.7/dist-packages/pygpu-0.7.6+20.g9cec614-py2.7-linux-x86_64.egg', '/usr/local/lib/python2.7/dist-packages/Mako-1.1.0-py2.7.egg', '/usr/lib/python2.7/dist-packages']\n",
      "/usr/bin/python2\n",
      "# Google colab python path #\n",
      "['', '/env/python', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/local/lib/python2.7/dist-packages/IPython/extensions', '/root/.ipython']\n",
      "/usr/bin/python2\n"
     ]
    }
   ],
   "source": [
    "print(\"# Shell python path #\")\n",
    "!python /content/drive/My\\ Drive/Colab\\ Notebooks/dummy_dataset_fpga/test.py\n",
    "print(\"# Google colab python path #\")\n",
    "import sys\n",
    "print(sys.path)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rhIHwe6V_RzP",
    "outputId": "0ef441de-f7dd-44d5-cbdd-acdd828668de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/env/python', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/usr/local/lib/python2.7/dist-packages', '/usr/lib/python2.7/dist-packages', '/usr/local/lib/python2.7/dist-packages/IPython/extensions', '/root/.ipython', '/usr/local/lib/python2.7/dist-packages/pygpu-0.7.6+20.g9cec614-py2.7-linux-x86_64.egg', '/usr/local/lib/python2.7/dist-packages/Mako-1.1.0-py2.7.egg', '/usr/local/lib/python2.7/dist-packages/Lasagne-0.2.dev1-py2.7.egg', '/content/drive/My Drive/Colab Notebooks/BNN-PYNQ/bnn/src/training']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Update google colab python path, compare between the 2 result in the previous cell\n",
    "sys.path += ('/usr/local/lib/python2.7/dist-packages/pygpu-0.7.6+20.g9cec614-py2.7-linux-x86_64.egg', '/usr/local/lib/python2.7/dist-packages/Mako-1.1.0-py2.7.egg', '/usr/local/lib/python2.7/dist-packages/Lasagne-0.2.dev1-py2.7.egg')\n",
    "\n",
    "# Add training lib path\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/BNN-PYNQ/bnn/src/training')\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iUPNSTBNRvF0"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "# Main stuff start down below #\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "zFCI3-Ojddu3",
    "outputId": "bb76747e-5041-4d85-ea29-717f8b1341de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/theano/gpuarray/dnn.py:184: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to a version >= v5 and <= v7.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 7603 on context None\n",
      "Mapped name None to device cuda: Tesla K80 (0000:00:04.0)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1234)  # for reproducibility\n",
    "\n",
    "# specifying the gpu to use\n",
    "# import theano.sandbox.cuda\n",
    "# theano.sandbox.cuda.use('gpu1') \n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "import cPickle as pickle\n",
    "import gzip\n",
    "\n",
    "import quantized_net\n",
    "import lfc\n",
    "\n",
    "#from pylearn2.datasets.mnist import MNIST\n",
    "#from pylearn2.utils import serial\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "id": "bjcbEBENgqs5",
    "outputId": "df3140b4-0755-43f5-9a9b-b84ce480f3aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_bits = 1\n",
      "weight_bits = 1\n",
      "batch_size = 100\n",
      "alpha = 0.1\n",
      "epsilon = 0.0001\n",
      "num_epochs = 1000\n",
      "dropout_in = 0.2\n",
      "dropout_hidden = 0.5\n",
      "W_LR_scale = Glorot\n",
      "LR_start = 0.003\n",
      "LR_fin = 3e-07\n",
      "LR_decay = 0.990831944893\n",
      "save_path = mnist-1w-1a.npz\n",
      "shuffle_parts = 1\n"
     ]
    }
   ],
   "source": [
    "# Parse some command line options\n",
    "#parser = ArgumentParser(\n",
    "#    description=\"Train the LFC network on the MNIST dataset\")\n",
    "#parser.add_argument('-ab', '--activation-bits', type=int, default=1, choices=[1, 2],\n",
    "#    help=\"Quantized the activations to the specified number of bits, default: %(default)s\")\n",
    "#parser.add_argument('-wb', '--weight-bits', type=int, default=1, choices=[1],\n",
    "#    help=\"Quantized the weights to the specified number of bits, default: %(default)s\")\n",
    "#args = parser.parse_args()\n",
    "\n",
    "learning_parameters = OrderedDict()\n",
    "\n",
    "# Quantization parameters\n",
    "learning_parameters.activation_bits = 1#args.activation_bits\n",
    "print(\"activation_bits = \"+str(learning_parameters.activation_bits))\n",
    "learning_parameters.weight_bits = 1#args.weight_bits\n",
    "print(\"weight_bits = \"+str(learning_parameters.weight_bits))\n",
    "\n",
    "# BN parameters\n",
    "batch_size = 100\n",
    "print(\"batch_size = \"+str(batch_size))\n",
    "# alpha is the exponential moving average factor\n",
    "# alpha = .15\n",
    "learning_parameters.alpha = .1\n",
    "print(\"alpha = \"+str(learning_parameters.alpha))\n",
    "learning_parameters.epsilon = 1e-4\n",
    "print(\"epsilon = \"+str(learning_parameters.epsilon))\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 1000\n",
    "print(\"num_epochs = \"+str(num_epochs))\n",
    "\n",
    "# Dropout parameters\n",
    "learning_parameters.dropout_in = .2 # 0. means no dropout\n",
    "print(\"dropout_in = \"+str(learning_parameters.dropout_in))\n",
    "learning_parameters.dropout_hidden = .5\n",
    "print(\"dropout_hidden = \"+str(learning_parameters.dropout_hidden))\n",
    "\n",
    "# W_LR_scale = 1.    \n",
    "learning_parameters.W_LR_scale = \"Glorot\" # \"Glorot\" means we are using the coefficients from Glorot's paper\n",
    "print(\"W_LR_scale = \"+str(learning_parameters.W_LR_scale))\n",
    "\n",
    "# Decaying LR \n",
    "LR_start = .003\n",
    "print(\"LR_start = \"+str(LR_start))\n",
    "LR_fin = 0.0000003\n",
    "print(\"LR_fin = \"+str(LR_fin))\n",
    "LR_decay = (LR_fin/LR_start)**(1./num_epochs)\n",
    "print(\"LR_decay = \"+str(LR_decay))\n",
    "# BTW, LR decay might good for the BN moving average...\n",
    "\n",
    "save_path = \"mnist-%dw-%da.npz\" % (learning_parameters.weight_bits, learning_parameters.activation_bits)\n",
    "print(\"save_path = \"+str(save_path))\n",
    "\n",
    "shuffle_parts = 1\n",
    "print(\"shuffle_parts = \"+str(shuffle_parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pr9KqRQWrnqy",
    "outputId": "8c05d3e3-73d0-417c-80ae-b6ab19fbb838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "print('Loading dataset...')\n",
    "\n",
    "####################\n",
    "## Implement here ##\n",
    "####################\n",
    "import pandas\n",
    "\n",
    "# Loading data\n",
    "csv_path_test = './dummy_dataset_fpga/dataset/Plate_license_test.csv'\n",
    "csv_path_train = './dummy_dataset_fpga/dataset/Plate_license_train.csv'\n",
    "csv_path_val = './dummy_dataset_fpga/dataset/Plate_license_val.csv'\n",
    "\n",
    "train_dataset = pandas.read_csv(csv_path_train, header=None).to_numpy()\n",
    "test_dataset = pandas.read_csv(csv_path_test, header=None).to_numpy()\n",
    "val_dataset = pandas.read_csv(csv_path_val, header=None).to_numpy()\n",
    "\n",
    "train_label = train_dataset[:, 0]\n",
    "test_label = train_dataset[:, 0]\n",
    "val_label = val_dataset[:, 0]\n",
    "\n",
    "train_dataset = train_dataset[:, 1:785].reshape(-1, 1, 28, 28)\n",
    "test_dataset = test_dataset[:, 1:785].reshape(-1, 1, 28, 28)\n",
    "val_dataset = val_dataset[:, 1:785].reshape(-1, 1, 28, 28)\n",
    "\n",
    "# Normalise to data to range of [-1; +1]\n",
    "train_dataset = 2 * (train_dataset / 255.) - 1\n",
    "test_dataset = 2 * (test_dataset / 255.) - 1\n",
    "val_dataset = 2 * (val_dataset / 255.) - 1\n",
    "\n",
    "# Binarise the inputs\n",
    "train_dataset = np.where(train_dataset < 0, -1, 1).astype(theano.config.floatX)\n",
    "test_dataset = np.where(test_dataset < 0, -1, 1).astype(theano.config.floatX)\n",
    "val_dataset = np.where(val_dataset < 0, -1, 1).astype(theano.config.floatX)\n",
    "\n",
    "# flatten targets\n",
    "train_label = np.hstack(train_label)\n",
    "test_label = np.hstack(test_label)\n",
    "val_label = np.hstack(val_label)\n",
    "\n",
    "# Onehot the targets\n",
    "train_label = np.float32(np.eye(10)[train_label])\n",
    "test_label = np.float32(np.eye(10)[test_label])\n",
    "val_label = np.float32(np.eye(10)[val_label])\n",
    "\n",
    "# for hinge loss\n",
    "train_label = 2 * train_label - 1\n",
    "test_label = 2 * test_label - 1\n",
    "val_label = 2 * val_label - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "sTQ-OYC5t7JD",
    "outputId": "3ae8bec3-80ac-410d-9c1e-ffd0434aa9a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_LR_scale = 34.71791\n",
      "H = 1.0\n",
      "W_LR_scale = 36.950417\n",
      "H = 1.0\n",
      "W_LR_scale = 36.950417\n",
      "H = 1.0\n",
      "W_LR_scale = 26.255157\n",
      "H = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Prepare Theano variables for inputs and targets\n",
    "input = T.tensor4('inputs')\n",
    "target = T.matrix('targets')\n",
    "LR = T.scalar('LR', dtype=theano.config.floatX)\n",
    "\n",
    "mlp = lfc.genLfc(input, 10, learning_parameters)\n",
    "\n",
    "train_output = lasagne.layers.get_output(mlp, deterministic=False)\n",
    "\n",
    "# squared hinge loss\n",
    "loss = T.mean(T.sqr(T.maximum(0.,1.-target*train_output)))\n",
    "\n",
    "# W updates\n",
    "W = lasagne.layers.get_all_params(mlp, quantized=True)\n",
    "W_grads = quantized_net.compute_grads(loss,mlp)\n",
    "updates = lasagne.updates.adam(loss_or_grads=W_grads, params=W, learning_rate=LR)\n",
    "updates = quantized_net.clipping_scaling(updates,mlp)\n",
    "\n",
    "# other parameters updates\n",
    "params = lasagne.layers.get_all_params(mlp, trainable=True, quantized=False)\n",
    "updates = OrderedDict(updates.items() + lasagne.updates.adam(loss_or_grads=loss, params=params, learning_rate=LR).items())\n",
    "    \n",
    "test_output = lasagne.layers.get_output(mlp, deterministic=True)\n",
    "test_loss = T.mean(T.sqr(T.maximum(0.,1.-target*test_output)))\n",
    "test_err = T.mean(T.neq(T.argmax(test_output, axis=1), T.argmax(target, axis=1)),dtype=theano.config.floatX)\n",
    "\n",
    "# Compile a function performing a training step on a mini-batch (by giving the updates dictionary) \n",
    "# and returning the corresponding training loss:\n",
    "train_fn = theano.function([input, target, LR], loss, updates=updates)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "val_fn = theano.function([input, target], [test_loss, test_err])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "60EzoG-at-6A",
    "outputId": "ac15b0f6-aa3e-40fe-888e-f7aa90b7164f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1 of 1000 took 1.71559119225s\n",
      "  LR:                            0.003\n",
      "  training loss:                 0.5400454682462356\n",
      "  validation loss:               0.21029662500534738\n",
      "  validation error rate:         2.464285652552332%\n",
      "  best epoch:                    1\n",
      "  best validation error rate:    2.464285652552332%\n",
      "  test loss:                     2.016111386673791\n",
      "  test error rate:               90.67857159035546%\n",
      "Epoch 2 of 1000 took 1.52758193016s\n",
      "  LR:                            0.00297249583468\n",
      "  training loss:                 0.1865746574366794\n",
      "  validation loss:               0.09210849074380738\n",
      "  validation error rate:         2.2857142479291985%\n",
      "  best epoch:                    2\n",
      "  best validation error rate:    2.2857142479291985%\n",
      "  test loss:                     1.957188293470868\n",
      "  test error rate:               90.71428584200996%\n",
      "Epoch 3 of 1000 took 1.5129108429s\n",
      "  LR:                            0.00294524382906\n",
      "  training loss:                 0.09850170897210346\n",
      "  validation loss:               0.04204606856884701\n",
      "  validation error rate:         1.9999999686011245%\n",
      "  best epoch:                    3\n",
      "  best validation error rate:    1.9999999686011245%\n",
      "  test loss:                     1.922490913886577\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 4 of 1000 took 1.62512993813s\n",
      "  LR:                            0.00291824167133\n",
      "  training loss:                 0.06013962679049548\n",
      "  validation loss:               0.028091201093047857\n",
      "  validation error rate:         1.9999999619488205%\n",
      "  best epoch:                    4\n",
      "  best validation error rate:    1.9999999619488205%\n",
      "  test loss:                     1.8988379787188023\n",
      "  test error rate:               90.67857159035546%\n",
      "Epoch 5 of 1000 took 1.62257695198s\n",
      "  LR:                            0.00289148707087\n",
      "  training loss:                 0.03862331811996067\n",
      "  validation loss:               0.020116588727562754\n",
      "  validation error rate:         1.714285695925355%\n",
      "  best epoch:                    5\n",
      "  best validation error rate:    1.714285695925355%\n",
      "  test loss:                     1.8121611197618352\n",
      "  test error rate:               90.78571434531894%\n",
      "Epoch 6 of 1000 took 1.56420397758s\n",
      "  LR:                            0.00286497775806\n",
      "  training loss:                 0.0286621982779573\n",
      "  validation loss:               0.017502783866283216\n",
      "  validation error rate:         1.678571430966258%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 7 of 1000 took 1.01678299904s\n",
      "  LR:                            0.0028387114841\n",
      "  training loss:                 0.025294519380173262\n",
      "  validation loss:               0.01852411425664156\n",
      "  validation error rate:         1.9999999619488205%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 8 of 1000 took 1.02245903015s\n",
      "  LR:                            0.00281268602078\n",
      "  training loss:                 0.020552814790212055\n",
      "  validation loss:               0.020396681226494757\n",
      "  validation error rate:         2.0714285716946637%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 9 of 1000 took 1.00751590729s\n",
      "  LR:                            0.00278689916034\n",
      "  training loss:                 0.0182448952951852\n",
      "  validation loss:               0.016281036068124064\n",
      "  validation error rate:         1.7857142591050694%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 10 of 1000 took 1.0179131031s\n",
      "  LR:                            0.00276134871526\n",
      "  training loss:                 0.01849628447500222\n",
      "  validation loss:               0.01649972417232805\n",
      "  validation error rate:         2.071428551737751%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 11 of 1000 took 1.01737093925s\n",
      "  LR:                            0.00273603251807\n",
      "  training loss:                 0.015887515466002856\n",
      "  validation loss:               0.016320790368549103\n",
      "  validation error rate:         1.9642856836851155%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 12 of 1000 took 1.01593613625s\n",
      "  LR:                            0.00271094842117\n",
      "  training loss:                 0.014085650668643854\n",
      "  validation loss:               0.01566789233788768\n",
      "  validation error rate:         1.7857142591050694%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 13 of 1000 took 1.07808804512s\n",
      "  LR:                            0.00268609429665\n",
      "  training loss:                 0.014800776174182401\n",
      "  validation loss:               0.019755931979619033\n",
      "  validation error rate:         2.32142855280212%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 14 of 1000 took 1.02355194092s\n",
      "  LR:                            0.00266146803611\n",
      "  training loss:                 0.017101083271314994\n",
      "  validation loss:               0.014212531139134756\n",
      "  validation error rate:         1.8214285373687744%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 15 of 1000 took 1.02358794212s\n",
      "  LR:                            0.00263706755049\n",
      "  training loss:                 0.015410413521835033\n",
      "  validation loss:               0.015546522237335532\n",
      "  validation error rate:         1.892857120505401%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 16 of 1000 took 1.01653289795s\n",
      "  LR:                            0.00261289076987\n",
      "  training loss:                 0.014145242307773408\n",
      "  validation loss:               0.015288285206354755\n",
      "  validation error rate:         2.2499999829701016%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 17 of 1000 took 1.0152990818s\n",
      "  LR:                            0.0025889356433\n",
      "  training loss:                 0.014203072503647383\n",
      "  validation loss:               0.01694658174788596\n",
      "  validation error rate:         1.9999999552965164%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 18 of 1000 took 1.03132200241s\n",
      "  LR:                            0.00256520013865\n",
      "  training loss:                 0.012819899117354962\n",
      "  validation loss:               0.0186859447107476\n",
      "  validation error rate:         2.2857142678861107%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 19 of 1000 took 1.00873613358s\n",
      "  LR:                            0.00254168224242\n",
      "  training loss:                 0.013713428830070531\n",
      "  validation loss:               0.014991719612895946\n",
      "  validation error rate:         2.0357142335602214%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 20 of 1000 took 1.00567579269s\n",
      "  LR:                            0.00251837995956\n",
      "  training loss:                 0.015356874791905284\n",
      "  validation loss:               0.013220981770505855\n",
      "  validation error rate:         1.8571428222847834%\n",
      "  best epoch:                    6\n",
      "  best validation error rate:    1.678571430966258%\n",
      "  test loss:                     1.75315184291685\n",
      "  test error rate:               90.75000009366444%\n",
      "Epoch 21 of 1000 took 1.5350279808s\n",
      "  LR:                            0.00249529131331\n",
      "  training loss:                 0.01401228232528357\n",
      "  validation loss:               0.011486949167842144\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 22 of 1000 took 1.0227200985s\n",
      "  LR:                            0.00247241434504\n",
      "  training loss:                 0.014067070818889667\n",
      "  validation loss:               0.012311066322061899\n",
      "  validation error rate:         1.6428571194410324%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 23 of 1000 took 1.04010510445s\n",
      "  LR:                            0.00244974711408\n",
      "  training loss:                 0.013283193659256487\n",
      "  validation loss:               0.016672389629673847\n",
      "  validation error rate:         2.035714260169438%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 24 of 1000 took 1.02543306351s\n",
      "  LR:                            0.00242728769754\n",
      "  training loss:                 0.01523282496149049\n",
      "  validation loss:               0.015023960612747292\n",
      "  validation error rate:         2.071428518476231%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 25 of 1000 took 1.02401185036s\n",
      "  LR:                            0.00240503419016\n",
      "  training loss:                 0.01685152165591717\n",
      "  validation loss:               0.013961202047149917\n",
      "  validation error rate:         1.607142827872719%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 26 of 1000 took 1.01867198944s\n",
      "  LR:                            0.00238298470417\n",
      "  training loss:                 0.015898681059479714\n",
      "  validation loss:               0.01606944465726861\n",
      "  validation error rate:         2.249999969665493%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 27 of 1000 took 1.03287386894s\n",
      "  LR:                            0.00236113736909\n",
      "  training loss:                 0.01617091847309733\n",
      "  validation loss:               0.01413159255415459\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 28 of 1000 took 1.02785992622s\n",
      "  LR:                            0.00233949033157\n",
      "  training loss:                 0.017120164709494394\n",
      "  validation loss:               0.014192060713607393\n",
      "  validation error rate:         1.714285695925355%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 29 of 1000 took 1.02486300468s\n",
      "  LR:                            0.00231804175529\n",
      "  training loss:                 0.015280842123662724\n",
      "  validation loss:               0.012668629115946064\n",
      "  validation error rate:         1.607142827872719%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 30 of 1000 took 1.03404402733s\n",
      "  LR:                            0.00229678982073\n",
      "  training loss:                 0.015734470726045616\n",
      "  validation loss:               0.013684440549565937\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 31 of 1000 took 1.04366183281s\n",
      "  LR:                            0.00227573272509\n",
      "  training loss:                 0.017551894222988803\n",
      "  validation loss:               0.01707862922194181\n",
      "  validation error rate:         2.03571424686483%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 32 of 1000 took 1.03281617165s\n",
      "  LR:                            0.00225486868205\n",
      "  training loss:                 0.018466178974246277\n",
      "  validation loss:               0.014810811911908266\n",
      "  validation error rate:         1.9285714054214105%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 33 of 1000 took 1.03610301018s\n",
      "  LR:                            0.00223419592172\n",
      "  training loss:                 0.019031213267761117\n",
      "  validation loss:               0.013025700747415872\n",
      "  validation error rate:         1.607142827872719%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 34 of 1000 took 1.03763508797s\n",
      "  LR:                            0.00221371269039\n",
      "  training loss:                 0.017877165025428816\n",
      "  validation loss:               0.013137599368113635\n",
      "  validation error rate:         1.7857142724096775%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 35 of 1000 took 1.04637503624s\n",
      "  LR:                            0.00219341725045\n",
      "  training loss:                 0.01692916083094828\n",
      "  validation loss:               0.01687576095550217\n",
      "  validation error rate:         2.035714260169438%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 36 of 1000 took 1.03596591949s\n",
      "  LR:                            0.00217330788022\n",
      "  training loss:                 0.019270369920003062\n",
      "  validation loss:               0.016284373241798482\n",
      "  validation error rate:         1.9999999552965164%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 37 of 1000 took 1.02774500847s\n",
      "  LR:                            0.00215338287381\n",
      "  training loss:                 0.018152519320959553\n",
      "  validation loss:               0.016437805610166834\n",
      "  validation error rate:         2.035714260169438%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 38 of 1000 took 1.03833413124s\n",
      "  LR:                            0.00213364054096\n",
      "  training loss:                 0.016109019208370764\n",
      "  validation loss:               0.017939347467160718\n",
      "  validation error rate:         2.2499999896224057%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 39 of 1000 took 1.02743315697s\n",
      "  LR:                            0.0021140792069\n",
      "  training loss:                 0.017325051378130035\n",
      "  validation loss:               0.017323556661202538\n",
      "  validation error rate:         2.071428545085447%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 40 of 1000 took 1.03401303291s\n",
      "  LR:                            0.00209469721223\n",
      "  training loss:                 0.017451279506306438\n",
      "  validation loss:               0.015862440186278297\n",
      "  validation error rate:         1.857142842241696%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 41 of 1000 took 1.045347929s\n",
      "  LR:                            0.00207549291276\n",
      "  training loss:                 0.01707382932140985\n",
      "  validation loss:               0.017901319068706862\n",
      "  validation error rate:         2.357142837718129%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 42 of 1000 took 1.0583190918s\n",
      "  LR:                            0.00205646467936\n",
      "  training loss:                 0.016757096254321584\n",
      "  validation loss:               0.01481430390828921\n",
      "  validation error rate:         1.74999997418906%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 43 of 1000 took 1.05746603012s\n",
      "  LR:                            0.00203761089785\n",
      "  training loss:                 0.017400566039278226\n",
      "  validation loss:               0.014862892866923565\n",
      "  validation error rate:         1.8214285573256865%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 44 of 1000 took 1.03071689606s\n",
      "  LR:                            0.00201892996885\n",
      "  training loss:                 0.016797679314828094\n",
      "  validation loss:               0.017009037236752938\n",
      "  validation error rate:         2.071428538433143%\n",
      "  best epoch:                    21\n",
      "  best validation error rate:    1.464285681556378%\n",
      "  test loss:                     1.2791577056971895\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 45 of 1000 took 1.51203179359s\n",
      "  LR:                            0.00200042030764\n",
      "  training loss:                 0.01611414155101075\n",
      "  validation loss:               0.01112708024135957\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 46 of 1000 took 1.02481102943s\n",
      "  LR:                            0.00198208034402\n",
      "  training loss:                 0.015935884498278884\n",
      "  validation loss:               0.01833202930499413\n",
      "  validation error rate:         2.10714280339224%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 47 of 1000 took 1.0141890049s\n",
      "  LR:                            0.0019639085222\n",
      "  training loss:                 0.01658307824502973\n",
      "  validation loss:               0.016435728475763817\n",
      "  validation error rate:         1.9999999686011245%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 48 of 1000 took 1.01767301559s\n",
      "  LR:                            0.00194590330064\n",
      "  training loss:                 0.01598088341929457\n",
      "  validation loss:               0.015649033154529337\n",
      "  validation error rate:         1.9285714120737145%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 49 of 1000 took 1.02714204788s\n",
      "  LR:                            0.00192806315195\n",
      "  training loss:                 0.016568023136214298\n",
      "  validation loss:               0.01608233820690787\n",
      "  validation error rate:         2.1428571149174656%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 50 of 1000 took 1.00957393646s\n",
      "  LR:                            0.00191038656272\n",
      "  training loss:                 0.015516029166824678\n",
      "  validation loss:               0.01608137668751754\n",
      "  validation error rate:         1.9999999619488205%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 51 of 1000 took 1.0064599514s\n",
      "  LR:                            0.00189287203344\n",
      "  training loss:                 0.017159606316400802\n",
      "  validation loss:               0.013020954652347427\n",
      "  validation error rate:         1.6785713977047374%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 52 of 1000 took 1.00076198578s\n",
      "  LR:                            0.00187551807833\n",
      "  training loss:                 0.01632534161703113\n",
      "  validation loss:               0.017051217793258338\n",
      "  validation error rate:         2.2142857180110047%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 53 of 1000 took 1.00990796089s\n",
      "  LR:                            0.00185832322523\n",
      "  training loss:                 0.01527335589806385\n",
      "  validation loss:               0.01821156084272551\n",
      "  validation error rate:         2.2499999829701016%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 54 of 1000 took 0.999819993973s\n",
      "  LR:                            0.00184128601549\n",
      "  training loss:                 0.01669089517227429\n",
      "  validation loss:               0.012410596086868151\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 55 of 1000 took 0.997620105743s\n",
      "  LR:                            0.00182440500384\n",
      "  training loss:                 0.015977960934533793\n",
      "  validation loss:               0.01863297016929469\n",
      "  validation error rate:         2.285714221319982%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 56 of 1000 took 1.00084280968s\n",
      "  LR:                            0.00180767875822\n",
      "  training loss:                 0.016233863125500434\n",
      "  validation loss:               0.014123492965349474\n",
      "  validation error rate:         1.8214285373687744%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 57 of 1000 took 1.0054769516s\n",
      "  LR:                            0.00179110585975\n",
      "  training loss:                 0.0171205298125963\n",
      "  validation loss:               0.01904788784151736\n",
      "  validation error rate:         2.0357142402125254%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 58 of 1000 took 1.00551104546s\n",
      "  LR:                            0.00177468490253\n",
      "  training loss:                 0.01692785867215956\n",
      "  validation loss:               0.01770813049553713\n",
      "  validation error rate:         2.178571419790387%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 59 of 1000 took 1.01729893684s\n",
      "  LR:                            0.00175841449354\n",
      "  training loss:                 0.01695089755470262\n",
      "  validation loss:               0.014517650582612467\n",
      "  validation error rate:         1.749999980841364%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 60 of 1000 took 1.0129070282s\n",
      "  LR:                            0.00174229325256\n",
      "  training loss:                 0.01449131878257236\n",
      "  validation loss:               0.01624598883699946\n",
      "  validation error rate:         2.03571424686483%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 61 of 1000 took 1.01078104973s\n",
      "  LR:                            0.00172631981201\n",
      "  training loss:                 0.01369060967459946\n",
      "  validation loss:               0.016272800948172517\n",
      "  validation error rate:         1.714285715882267%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 62 of 1000 took 1.00333213806s\n",
      "  LR:                            0.00171049281684\n",
      "  training loss:                 0.014533493281616008\n",
      "  validation loss:               0.016263587722359522\n",
      "  validation error rate:         1.8214285506733825%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 63 of 1000 took 1.01068401337s\n",
      "  LR:                            0.00169481092444\n",
      "  training loss:                 0.01465746783240534\n",
      "  validation loss:               0.019212741086058877\n",
      "  validation error rate:         2.0357142402125254%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 64 of 1000 took 0.998895168304s\n",
      "  LR:                            0.00167927280449\n",
      "  training loss:                 0.015471327686956263\n",
      "  validation loss:               0.01392935648543617\n",
      "  validation error rate:         1.7499999874936685%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 65 of 1000 took 1.00720000267s\n",
      "  LR:                            0.00166387713887\n",
      "  training loss:                 0.015075803307049414\n",
      "  validation loss:               0.014763961845476712\n",
      "  validation error rate:         1.6785714043570414%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 66 of 1000 took 1.01779913902s\n",
      "  LR:                            0.00164862262157\n",
      "  training loss:                 0.014767197889330633\n",
      "  validation loss:               0.018737783809358786\n",
      "  validation error rate:         2.1428570883082494%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 67 of 1000 took 1.01539087296s\n",
      "  LR:                            0.00163350795853\n",
      "  training loss:                 0.014443480983540855\n",
      "  validation loss:               0.016290741105357092\n",
      "  validation error rate:         2.0357142402125254%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 68 of 1000 took 1.01718091965s\n",
      "  LR:                            0.00161853186755\n",
      "  training loss:                 0.015520135209183482\n",
      "  validation loss:               0.01574141757298061\n",
      "  validation error rate:         1.9642856770328114%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 69 of 1000 took 1.01526093483s\n",
      "  LR:                            0.00160369307819\n",
      "  training loss:                 0.01456827728132553\n",
      "  validation loss:               0.017432049137044357\n",
      "  validation error rate:         2.1071428499583686%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 70 of 1000 took 1.0031940937s\n",
      "  LR:                            0.00158899033167\n",
      "  training loss:                 0.013640921924482373\n",
      "  validation loss:               0.021608142118046608\n",
      "  validation error rate:         2.142857134874378%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 71 of 1000 took 1.0134139061s\n",
      "  LR:                            0.00157442238075\n",
      "  training loss:                 0.013528571040917406\n",
      "  validation loss:               0.016846424781111376\n",
      "  validation error rate:         2.1071428233491525%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 72 of 1000 took 1.01183915138s\n",
      "  LR:                            0.0015599879896\n",
      "  training loss:                 0.015089940077022595\n",
      "  validation loss:               0.016416103144105625\n",
      "  validation error rate:         1.857142835589392%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 73 of 1000 took 1.02360200882s\n",
      "  LR:                            0.00154568593375\n",
      "  training loss:                 0.013146705420427573\n",
      "  validation loss:               0.015855294170709806\n",
      "  validation error rate:         1.9285714054214105%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 74 of 1000 took 1.01310801506s\n",
      "  LR:                            0.00153151499993\n",
      "  training loss:                 0.016188975368790767\n",
      "  validation loss:               0.015670252846104762\n",
      "  validation error rate:         1.9999999552965164%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 75 of 1000 took 1.02383089066s\n",
      "  LR:                            0.00151747398601\n",
      "  training loss:                 0.014636959431364257\n",
      "  validation loss:               0.0162798877932216\n",
      "  validation error rate:         1.8571428156324794%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 76 of 1000 took 1.02821016312s\n",
      "  LR:                            0.00150356170088\n",
      "  training loss:                 0.013809231727603165\n",
      "  validation loss:               0.016364137316754426\n",
      "  validation error rate:         1.928571398769106%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 77 of 1000 took 1.02497506142s\n",
      "  LR:                            0.00148977696435\n",
      "  training loss:                 0.012964289679246791\n",
      "  validation loss:               0.015077500738438434\n",
      "  validation error rate:         1.6428571260933365%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 78 of 1000 took 1.01714301109s\n",
      "  LR:                            0.00147611860704\n",
      "  training loss:                 0.013411523997509743\n",
      "  validation loss:               0.015883411342705194\n",
      "  validation error rate:         1.7857142857142856%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 79 of 1000 took 1.01488494873s\n",
      "  LR:                            0.00146258547031\n",
      "  training loss:                 0.01354300855412422\n",
      "  validation loss:               0.017831867920514406\n",
      "  validation error rate:         1.9285713788121939%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 80 of 1000 took 1.02125120163s\n",
      "  LR:                            0.00144917640612\n",
      "  training loss:                 0.012933272627346656\n",
      "  validation loss:               0.014668147338625204\n",
      "  validation error rate:         1.892857107200793%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 81 of 1000 took 1.0203230381s\n",
      "  LR:                            0.00143589027697\n",
      "  training loss:                 0.012341378455269425\n",
      "  validation loss:               0.0189305512287434\n",
      "  validation error rate:         2.035714260169438%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 82 of 1000 took 1.02276396751s\n",
      "  LR:                            0.00142272595578\n",
      "  training loss:                 0.014500033680130454\n",
      "  validation loss:               0.017922444312067194\n",
      "  validation error rate:         2.1785713798765625%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 83 of 1000 took 1.0228600502s\n",
      "  LR:                            0.00140968232582\n",
      "  training loss:                 0.012202761125038653\n",
      "  validation loss:               0.013733196584153364\n",
      "  validation error rate:         1.607142827872719%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 84 of 1000 took 1.02085900307s\n",
      "  LR:                            0.00139675828057\n",
      "  training loss:                 0.014060462979764184\n",
      "  validation loss:               0.014253078540475275\n",
      "  validation error rate:         1.678571411009346%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 85 of 1000 took 1.02156805992s\n",
      "  LR:                            0.00138395272368\n",
      "  training loss:                 0.013261894931030624\n",
      "  validation loss:               0.0222493323655572\n",
      "  validation error rate:         2.2500000228839263%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 86 of 1000 took 1.01684689522s\n",
      "  LR:                            0.00137126456884\n",
      "  training loss:                 0.012176318850149127\n",
      "  validation loss:               0.018747590641508185\n",
      "  validation error rate:         2.178571413138083%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 87 of 1000 took 1.01560497284s\n",
      "  LR:                            0.00135869273971\n",
      "  training loss:                 0.012176766063031905\n",
      "  validation loss:               0.01679287651356682\n",
      "  validation error rate:         1.9642856836851155%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 88 of 1000 took 1.01562404633s\n",
      "  LR:                            0.0013462361698\n",
      "  training loss:                 0.01356839009505861\n",
      "  validation loss:               0.012337622014846212\n",
      "  validation error rate:         1.3571428467652626%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 89 of 1000 took 1.00461792946s\n",
      "  LR:                            0.00133389380241\n",
      "  training loss:                 0.012099749459337224\n",
      "  validation loss:               0.01448629670354811\n",
      "  validation error rate:         1.571428549609014%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 90 of 1000 took 1.00594091415s\n",
      "  LR:                            0.00132166459052\n",
      "  training loss:                 0.012210273471496561\n",
      "  validation loss:               0.017203478261210745\n",
      "  validation error rate:         1.74999997418906%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 91 of 1000 took 1.00654911995s\n",
      "  LR:                            0.00130954749672\n",
      "  training loss:                 0.012788826529867948\n",
      "  validation loss:               0.012875034744618168\n",
      "  validation error rate:         1.3928571250289679%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 92 of 1000 took 1.01159596443s\n",
      "  LR:                            0.00129754149311\n",
      "  training loss:                 0.012929041761055807\n",
      "  validation loss:               0.020020637165803885\n",
      "  validation error rate:         2.214285691401788%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 93 of 1000 took 1.0140838623s\n",
      "  LR:                            0.00128564556119\n",
      "  training loss:                 0.012312026719754452\n",
      "  validation loss:               0.013967944344455776\n",
      "  validation error rate:         1.857142828937088%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 94 of 1000 took 1.00197887421s\n",
      "  LR:                            0.00127385869184\n",
      "  training loss:                 0.012954444089657902\n",
      "  validation loss:               0.019592347208280052\n",
      "  validation error rate:         1.928571385464498%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 95 of 1000 took 1.00124597549s\n",
      "  LR:                            0.00126217988515\n",
      "  training loss:                 0.012471466167720364\n",
      "  validation loss:               0.01522024594656354\n",
      "  validation error rate:         1.857142842241696%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 96 of 1000 took 1.00027513504s\n",
      "  LR:                            0.00125060815041\n",
      "  training loss:                 0.012282274845604072\n",
      "  validation loss:               0.016885866391415254\n",
      "  validation error rate:         1.9642856703805074%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 97 of 1000 took 1.01586103439s\n",
      "  LR:                            0.00123914250597\n",
      "  training loss:                 0.012885248265229165\n",
      "  validation loss:               0.012737650097210665\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 98 of 1000 took 1.00445699692s\n",
      "  LR:                            0.00122778197919\n",
      "  training loss:                 0.010833810771103292\n",
      "  validation loss:               0.017497886777344922\n",
      "  validation error rate:         1.999999988558037%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 99 of 1000 took 1.00565004349s\n",
      "  LR:                            0.00121652560635\n",
      "  training loss:                 0.012051070450038157\n",
      "  validation loss:               0.01486431093196318\n",
      "  validation error rate:         1.8214285373687744%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 100 of 1000 took 1.01236510277s\n",
      "  LR:                            0.00120537243255\n",
      "  training loss:                 0.012240930715137545\n",
      "  validation loss:               0.017014125486706888\n",
      "  validation error rate:         1.892857113853097%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 101 of 1000 took 1.01530098915s\n",
      "  LR:                            0.00119432151166\n",
      "  training loss:                 0.012043258045142627\n",
      "  validation loss:               0.018616823508961846\n",
      "  validation error rate:         1.928571392116802%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 102 of 1000 took 1.00153493881s\n",
      "  LR:                            0.00118337190623\n",
      "  training loss:                 0.013193570041809889\n",
      "  validation loss:               0.016286095682809382\n",
      "  validation error rate:         1.9999999752534285%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 103 of 1000 took 0.998147010803s\n",
      "  LR:                            0.00117252268738\n",
      "  training loss:                 0.011958599430234994\n",
      "  validation loss:               0.01758786286760434\n",
      "  validation error rate:         1.9999999686011245%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 104 of 1000 took 1.00537204742s\n",
      "  LR:                            0.00116177293476\n",
      "  training loss:                 0.011164257528862971\n",
      "  validation loss:               0.018474956963257023\n",
      "  validation error rate:         2.0357142402125254%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 105 of 1000 took 1.02172398567s\n",
      "  LR:                            0.00115112173648\n",
      "  training loss:                 0.01106947213274372\n",
      "  validation loss:               0.014093036151592233\n",
      "  validation error rate:         1.535714277997613%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 106 of 1000 took 1.00576210022s\n",
      "  LR:                            0.00114056818896\n",
      "  training loss:                 0.010725295115673147\n",
      "  validation loss:               0.01558364199628873\n",
      "  validation error rate:         1.821428563977991%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 107 of 1000 took 1.00367283821s\n",
      "  LR:                            0.00113011139695\n",
      "  training loss:                 0.01049645836396581\n",
      "  validation loss:               0.013346298967267753\n",
      "  validation error rate:         1.571428562913622%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 108 of 1000 took 1.00531697273s\n",
      "  LR:                            0.00111975047339\n",
      "  training loss:                 0.010187919180059587\n",
      "  validation loss:               0.016788442291135647\n",
      "  validation error rate:         1.714285695925355%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 109 of 1000 took 1.00272202492s\n",
      "  LR:                            0.00110948453934\n",
      "  training loss:                 0.011257640396327\n",
      "  validation loss:               0.014762840801592705\n",
      "  validation error rate:         1.8214285307164704%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 110 of 1000 took 1.00415682793s\n",
      "  LR:                            0.00109931272394\n",
      "  training loss:                 0.009724572722745291\n",
      "  validation loss:               0.015537542858770135\n",
      "  validation error rate:         1.8214285373687744%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 111 of 1000 took 1.0050110817s\n",
      "  LR:                            0.00108923416431\n",
      "  training loss:                 0.010473591150195503\n",
      "  validation loss:               0.018356191527605654\n",
      "  validation error rate:         1.9642856770328114%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 112 of 1000 took 1.00041294098s\n",
      "  LR:                            0.00107924800547\n",
      "  training loss:                 0.01148932832361692\n",
      "  validation loss:               0.018099735036384703\n",
      "  validation error rate:         1.9642856703805074%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 113 of 1000 took 1.00750803947s\n",
      "  LR:                            0.00106935340028\n",
      "  training loss:                 0.0106227633981582\n",
      "  validation loss:               0.014817677319691873\n",
      "  validation error rate:         1.74999997418906%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 114 of 1000 took 1.01264309883s\n",
      "  LR:                            0.00105954950938\n",
      "  training loss:                 0.01106982024400221\n",
      "  validation loss:               0.015326750902334294\n",
      "  validation error rate:         1.9642856770328114%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 115 of 1000 took 1.00431013107s\n",
      "  LR:                            0.00104983550109\n",
      "  training loss:                 0.010619785053217236\n",
      "  validation loss:               0.017620326402850748\n",
      "  validation error rate:         1.928571385464498%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 116 of 1000 took 1.00739693642s\n",
      "  LR:                            0.00104021055136\n",
      "  training loss:                 0.011052067609339513\n",
      "  validation loss:               0.01665197676353663\n",
      "  validation error rate:         1.821428563977991%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 117 of 1000 took 1.00866103172s\n",
      "  LR:                            0.0010306738437\n",
      "  training loss:                 0.008900736444903648\n",
      "  validation loss:               0.015739417560585674\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 118 of 1000 took 1.00376391411s\n",
      "  LR:                            0.0010212245691\n",
      "  training loss:                 0.011507765965207535\n",
      "  validation loss:               0.016121857629189305\n",
      "  validation error rate:         1.7857142657573735%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 119 of 1000 took 0.999436855316s\n",
      "  LR:                            0.00101186192598\n",
      "  training loss:                 0.008945074421353639\n",
      "  validation loss:               0.015347100551285362\n",
      "  validation error rate:         1.857142828937088%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 120 of 1000 took 1.01042604446s\n",
      "  LR:                            0.00100258512008\n",
      "  training loss:                 0.009470529499402105\n",
      "  validation loss:               0.014080144843244316\n",
      "  validation error rate:         1.571428562913622%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 121 of 1000 took 1.00258302689s\n",
      "  LR:                            0.000993393364448\n",
      "  training loss:                 0.010724020741112969\n",
      "  validation loss:               0.01627403804369822\n",
      "  validation error rate:         1.928571385464498%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 122 of 1000 took 1.01484394073s\n",
      "  LR:                            0.000984285879339\n",
      "  training loss:                 0.00958953976206591\n",
      "  validation loss:               0.018640663393723247\n",
      "  validation error rate:         2.035714253517134%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 123 of 1000 took 0.999102115631s\n",
      "  LR:                            0.000975261892156\n",
      "  training loss:                 0.009914330794366405\n",
      "  validation loss:               0.01665742397380297\n",
      "  validation error rate:         1.9642856703805074%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 124 of 1000 took 1.00563311577s\n",
      "  LR:                            0.000966320637385\n",
      "  training loss:                 0.01022774799288634\n",
      "  validation loss:               0.015649029041599403\n",
      "  validation error rate:         1.7857142724096775%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 125 of 1000 took 1.00229096413s\n",
      "  LR:                            0.00095746135653\n",
      "  training loss:                 0.009075389458345906\n",
      "  validation loss:               0.019575305475948972\n",
      "  validation error rate:         1.999999988558037%\n",
      "  best epoch:                    45\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.4799198813955172\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 126 of 1000 took 1.52630710602s\n",
      "  LR:                            0.000948683298051\n",
      "  training loss:                 0.008689470718929762\n",
      "  validation loss:               0.014835590370109588\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    126\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.6989756652287074\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 127 of 1000 took 1.01462888718s\n",
      "  LR:                            0.000939985717295\n",
      "  training loss:                 0.00802512744181406\n",
      "  validation loss:               0.01576984383167915\n",
      "  validation error rate:         1.8214285307164704%\n",
      "  best epoch:                    126\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.6989756652287074\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 128 of 1000 took 1.00190210342s\n",
      "  LR:                            0.000931367876439\n",
      "  training loss:                 0.010184851558947498\n",
      "  validation loss:               0.014776889314896482\n",
      "  validation error rate:         1.74999997418906%\n",
      "  best epoch:                    126\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.6989756652287074\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 129 of 1000 took 1.00787687302s\n",
      "  LR:                            0.000922829044422\n",
      "  training loss:                 0.008453042792526129\n",
      "  validation loss:               0.01585206465873463\n",
      "  validation error rate:         1.8214285506733825%\n",
      "  best epoch:                    126\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.6989756652287074\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 130 of 1000 took 1.00510907173s\n",
      "  LR:                            0.000914368496888\n",
      "  training loss:                 0.008681428054970798\n",
      "  validation loss:               0.015666801906965993\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    126\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.6989756652287074\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 131 of 1000 took 1.00814795494s\n",
      "  LR:                            0.000905985516121\n",
      "  training loss:                 0.009779113024363623\n",
      "  validation loss:               0.015240536587322311\n",
      "  validation error rate:         1.8571428156324794%\n",
      "  best epoch:                    126\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.6989756652287074\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 132 of 1000 took 1.00593900681s\n",
      "  LR:                            0.000897679390982\n",
      "  training loss:                 0.007595728435005773\n",
      "  validation loss:               0.015898357796946323\n",
      "  validation error rate:         1.714285695925355%\n",
      "  best epoch:                    126\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.6989756652287074\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 133 of 1000 took 1.00342798233s\n",
      "  LR:                            0.000889449416857\n",
      "  training loss:                 0.00922358455204898\n",
      "  validation loss:               0.014638960188998573\n",
      "  validation error rate:         1.7142856826207469%\n",
      "  best epoch:                    126\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.6989756652287074\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 134 of 1000 took 1.01022195816s\n",
      "  LR:                            0.000881294895588\n",
      "  training loss:                 0.009065007568706812\n",
      "  validation loss:               0.01431734820127011\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    126\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.6989756652287074\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 135 of 1000 took 1.0113298893s\n",
      "  LR:                            0.00087321513542\n",
      "  training loss:                 0.008774215902153895\n",
      "  validation loss:               0.018143732227291105\n",
      "  validation error rate:         1.928571385464498%\n",
      "  best epoch:                    126\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.6989756652287074\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 136 of 1000 took 1.01875209808s\n",
      "  LR:                            0.000865209450938\n",
      "  training loss:                 0.00861820811748176\n",
      "  validation loss:               0.013121371965618371\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    126\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.6989756652287074\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 137 of 1000 took 1.54241514206s\n",
      "  LR:                            0.000857277163012\n",
      "  training loss:                 0.009445178411175113\n",
      "  validation loss:               0.013225337925421497\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 138 of 1000 took 0.994590044022s\n",
      "  LR:                            0.00084941759874\n",
      "  training loss:                 0.008854063173673828\n",
      "  validation loss:               0.01452290182455686\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 139 of 1000 took 1.00950288773s\n",
      "  LR:                            0.000841630091386\n",
      "  training loss:                 0.009499683564610999\n",
      "  validation loss:               0.014845952718847652\n",
      "  validation error rate:         1.74999997418906%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 140 of 1000 took 1.01066684723s\n",
      "  LR:                            0.000833913980328\n",
      "  training loss:                 0.009494408721665798\n",
      "  validation loss:               0.01781082567673106\n",
      "  validation error rate:         1.9999999619488205%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 141 of 1000 took 1.04085087776s\n",
      "  LR:                            0.000826268611001\n",
      "  training loss:                 0.009238188884303193\n",
      "  validation loss:               0.02122737856494236\n",
      "  validation error rate:         1.999999981905733%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 142 of 1000 took 1.00735998154s\n",
      "  LR:                            0.000818693334842\n",
      "  training loss:                 0.008099780445541802\n",
      "  validation loss:               0.017969677555868202\n",
      "  validation error rate:         1.9999999552965164%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 143 of 1000 took 1.01040697098s\n",
      "  LR:                            0.000811187509233\n",
      "  training loss:                 0.007906516405466177\n",
      "  validation loss:               0.016693891177055775\n",
      "  validation error rate:         1.892857113853097%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 144 of 1000 took 1.01521897316s\n",
      "  LR:                            0.000803750497446\n",
      "  training loss:                 0.008119432903185952\n",
      "  validation loss:               0.014171830923448933\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 145 of 1000 took 1.01841211319s\n",
      "  LR:                            0.000796381668593\n",
      "  training loss:                 0.008213640258455758\n",
      "  validation loss:               0.01858275147580051\n",
      "  validation error rate:         1.928571392116802%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 146 of 1000 took 1.02299499512s\n",
      "  LR:                            0.000789080397569\n",
      "  training loss:                 0.007969186302644255\n",
      "  validation loss:               0.020483955286116334\n",
      "  validation error rate:         1.9999999619488205%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 147 of 1000 took 1.02392292023s\n",
      "  LR:                            0.000781846065\n",
      "  training loss:                 0.008792914967874394\n",
      "  validation loss:               0.01521559465197088\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 148 of 1000 took 1.01976513863s\n",
      "  LR:                            0.00077467805719\n",
      "  training loss:                 0.007828603229855242\n",
      "  validation loss:               0.014759439268280923\n",
      "  validation error rate:         1.464285688208682%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 149 of 1000 took 1.02294111252s\n",
      "  LR:                            0.000767575766072\n",
      "  training loss:                 0.00839362360557596\n",
      "  validation loss:               0.012653155509074818\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 150 of 1000 took 1.01455211639s\n",
      "  LR:                            0.000760538589149\n",
      "  training loss:                 0.007826423393870595\n",
      "  validation loss:               0.015819702448652606\n",
      "  validation error rate:         1.74999997418906%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 151 of 1000 took 1.03727388382s\n",
      "  LR:                            0.000753565929453\n",
      "  training loss:                 0.007523575424463214\n",
      "  validation loss:               0.019072340354503985\n",
      "  validation error rate:         1.9999999486442124%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 152 of 1000 took 1.0312268734s\n",
      "  LR:                            0.000746657195485\n",
      "  training loss:                 0.00890597876311992\n",
      "  validation loss:               0.014768448273571266\n",
      "  validation error rate:         1.571428556261318%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 153 of 1000 took 1.02074980736s\n",
      "  LR:                            0.00073981180117\n",
      "  training loss:                 0.007495513956939035\n",
      "  validation loss:               0.014540153254464323\n",
      "  validation error rate:         1.607142827872719%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 154 of 1000 took 1.02170991898s\n",
      "  LR:                            0.000733029165808\n",
      "  training loss:                 0.008908234679085367\n",
      "  validation loss:               0.018488200358459852\n",
      "  validation error rate:         1.8571428156324794%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 155 of 1000 took 1.01590490341s\n",
      "  LR:                            0.000726308714021\n",
      "  training loss:                 0.008195884001393363\n",
      "  validation loss:               0.0195768455947213\n",
      "  validation error rate:         1.9642856703805074%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 156 of 1000 took 1.0161280632s\n",
      "  LR:                            0.000719649875706\n",
      "  training loss:                 0.007688754889771671\n",
      "  validation loss:               0.013695515378783187\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 157 of 1000 took 1.01962208748s\n",
      "  LR:                            0.000713052085987\n",
      "  training loss:                 0.008210998131920968\n",
      "  validation loss:               0.014941914815156767\n",
      "  validation error rate:         1.749999980841364%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 158 of 1000 took 1.01244997978s\n",
      "  LR:                            0.000706514785169\n",
      "  training loss:                 0.008001765263479147\n",
      "  validation loss:               0.013783357671595045\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 159 of 1000 took 1.0464990139s\n",
      "  LR:                            0.000700037418684\n",
      "  training loss:                 0.007558525841929676\n",
      "  validation loss:               0.013881721022698912\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 160 of 1000 took 1.01594495773s\n",
      "  LR:                            0.000693619437053\n",
      "  training loss:                 0.00760504463875858\n",
      "  validation loss:               0.014027850381820275\n",
      "  validation error rate:         1.571428549609014%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 161 of 1000 took 1.02032399178s\n",
      "  LR:                            0.00068726029583\n",
      "  training loss:                 0.007540637456387391\n",
      "  validation loss:               0.016581686793963563\n",
      "  validation error rate:         1.8928570938961848%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 162 of 1000 took 1.03280186653s\n",
      "  LR:                            0.000680959455565\n",
      "  training loss:                 0.007436131598147125\n",
      "  validation loss:               0.015710598036647254\n",
      "  validation error rate:         1.7142856826207469%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 163 of 1000 took 1.03427696228s\n",
      "  LR:                            0.000674716381751\n",
      "  training loss:                 0.006194214193794109\n",
      "  validation loss:               0.014973566032127548\n",
      "  validation error rate:         1.6071428544819355%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 164 of 1000 took 1.00312805176s\n",
      "  LR:                            0.000668530544781\n",
      "  training loss:                 0.006829574831028688\n",
      "  validation loss:               0.017003212115079287\n",
      "  validation error rate:         1.7142856826207469%\n",
      "  best epoch:                    137\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.722446539572307\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 165 of 1000 took 1.47409796715s\n",
      "  LR:                            0.000662401419906\n",
      "  training loss:                 0.00710428009966991\n",
      "  validation loss:               0.013672674047159359\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    165\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.7570774512631553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 166 of 1000 took 1.03185009956s\n",
      "  LR:                            0.000656328487185\n",
      "  training loss:                 0.007767613799831666\n",
      "  validation loss:               0.018102593888475633\n",
      "  validation error rate:         1.8214285307164704%\n",
      "  best epoch:                    165\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.7570774512631553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 167 of 1000 took 1.01238703728s\n",
      "  LR:                            0.000650311231446\n",
      "  training loss:                 0.007006842781351332\n",
      "  validation loss:               0.017657808876720082\n",
      "  validation error rate:         1.8214285573256865%\n",
      "  best epoch:                    165\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.7570774512631553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 168 of 1000 took 1.02418804169s\n",
      "  LR:                            0.000644349142239\n",
      "  training loss:                 0.006000313836043728\n",
      "  validation loss:               0.01581531654386278\n",
      "  validation error rate:         1.6785713844001293%\n",
      "  best epoch:                    165\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.7570774512631553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 169 of 1000 took 1.00023889542s\n",
      "  LR:                            0.000638441713795\n",
      "  training loss:                 0.008356315051273936\n",
      "  validation loss:               0.01676692541936323\n",
      "  validation error rate:         1.8214285240641663%\n",
      "  best epoch:                    165\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.7570774512631553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 170 of 1000 took 1.00838804245s\n",
      "  LR:                            0.00063258844498\n",
      "  training loss:                 0.0064119989122178485\n",
      "  validation loss:               0.013981784817653014\n",
      "  validation error rate:         1.535714277997613%\n",
      "  best epoch:                    165\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.7570774512631553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 171 of 1000 took 0.997209787369s\n",
      "  LR:                            0.000626788839256\n",
      "  training loss:                 0.006930911650894867\n",
      "  validation loss:               0.015489743792824941\n",
      "  validation error rate:         1.6785713910524334%\n",
      "  best epoch:                    165\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.7570774512631553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 172 of 1000 took 1.01862597466s\n",
      "  LR:                            0.000621042404637\n",
      "  training loss:                 0.0063539701897431826\n",
      "  validation loss:               0.014215916602174567\n",
      "  validation error rate:         1.6071428411773274%\n",
      "  best epoch:                    165\n",
      "  best validation error rate:    1.3571428334606546%\n",
      "  test loss:                     1.7570774512631553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 173 of 1000 took 1.52874422073s\n",
      "  LR:                            0.000615348653648\n",
      "  training loss:                 0.006518779430702767\n",
      "  validation loss:               0.012145237695067732\n",
      "  validation error rate:         1.249999985364931%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 174 of 1000 took 1.02892017365s\n",
      "  LR:                            0.000609707103281\n",
      "  training loss:                 0.005552757889552809\n",
      "  validation loss:               0.014053533504027525\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 175 of 1000 took 1.02379584312s\n",
      "  LR:                            0.000604117274959\n",
      "  training loss:                 0.005786374249916715\n",
      "  validation loss:               0.014349637041440084\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 176 of 1000 took 1.01320385933s\n",
      "  LR:                            0.000598578694491\n",
      "  training loss:                 0.0063827008231515615\n",
      "  validation loss:               0.013945537028322161\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 177 of 1000 took 1.01764297485s\n",
      "  LR:                            0.000593090892034\n",
      "  training loss:                 0.006393986376454396\n",
      "  validation loss:               0.016741524587108154\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 178 of 1000 took 1.01096987724s\n",
      "  LR:                            0.000587653402052\n",
      "  training loss:                 0.006651195580386283\n",
      "  validation loss:               0.01605594382354728\n",
      "  validation error rate:         1.74999997418906%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 179 of 1000 took 1.05985212326s\n",
      "  LR:                            0.000582265763278\n",
      "  training loss:                 0.006419001321816776\n",
      "  validation loss:               0.015772350402845144\n",
      "  validation error rate:         1.8214285506733825%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 180 of 1000 took 1.01870298386s\n",
      "  LR:                            0.000576927518673\n",
      "  training loss:                 0.005477200473850484\n",
      "  validation loss:               0.015391758781301437\n",
      "  validation error rate:         1.6428571127887284%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 181 of 1000 took 1.01766586304s\n",
      "  LR:                            0.000571638215389\n",
      "  training loss:                 0.006935164362349657\n",
      "  validation loss:               0.01179081361753731\n",
      "  validation error rate:         1.285714263628636%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 182 of 1000 took 1.01556301117s\n",
      "  LR:                            0.000566397404729\n",
      "  training loss:                 0.006192573567900313\n",
      "  validation loss:               0.017482309076123265\n",
      "  validation error rate:         1.749999967536756%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 183 of 1000 took 1.00095796585s\n",
      "  LR:                            0.00056120464211\n",
      "  training loss:                 0.006384950697504203\n",
      "  validation loss:               0.014739739876469165\n",
      "  validation error rate:         1.6428571260933365%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 184 of 1000 took 1.0264570713s\n",
      "  LR:                            0.000556059487024\n",
      "  training loss:                 0.005976865959682447\n",
      "  validation loss:               0.016219706721065968\n",
      "  validation error rate:         1.6071428411773274%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 185 of 1000 took 1.00169014931s\n",
      "  LR:                            0.000550961503005\n",
      "  training loss:                 0.0061809273041530215\n",
      "  validation loss:               0.013903527498289492\n",
      "  validation error rate:         1.3214285551969494%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 186 of 1000 took 1.00811290741s\n",
      "  LR:                            0.000545910257583\n",
      "  training loss:                 0.005701075563967393\n",
      "  validation loss:               0.015381761341481186\n",
      "  validation error rate:         1.535714277997613%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 187 of 1000 took 1.0042219162s\n",
      "  LR:                            0.000540905322258\n",
      "  training loss:                 0.005998508962254752\n",
      "  validation loss:               0.014345680943554777\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 188 of 1000 took 1.01684904099s\n",
      "  LR:                            0.000535946272456\n",
      "  training loss:                 0.006471639596651692\n",
      "  validation loss:               0.016097139977299082\n",
      "  validation error rate:         1.5714285429567099%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 189 of 1000 took 1.00848078728s\n",
      "  LR:                            0.000531032687495\n",
      "  training loss:                 0.004827925783191698\n",
      "  validation loss:               0.015877366994232034\n",
      "  validation error rate:         1.6785714043570414%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 190 of 1000 took 1.00771784782s\n",
      "  LR:                            0.000526164150553\n",
      "  training loss:                 0.0061605051134178855\n",
      "  validation loss:               0.022588593761475626\n",
      "  validation error rate:         1.9285714187260186%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 191 of 1000 took 1.01950001717s\n",
      "  LR:                            0.000521340248625\n",
      "  training loss:                 0.005369717087117297\n",
      "  validation loss:               0.015071073068481513\n",
      "  validation error rate:         1.28571427028094%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 192 of 1000 took 1.0263068676s\n",
      "  LR:                            0.000516560572496\n",
      "  training loss:                 0.006189139281153022\n",
      "  validation loss:               0.01509884875223122\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 193 of 1000 took 1.0442738533s\n",
      "  LR:                            0.000511824716701\n",
      "  training loss:                 0.0051190207032264234\n",
      "  validation loss:               0.013857383602498885\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 194 of 1000 took 1.00702404976s\n",
      "  LR:                            0.000507132279493\n",
      "  training loss:                 0.005908933320247075\n",
      "  validation loss:               0.014461846864973284\n",
      "  validation error rate:         1.3571428467652626%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 195 of 1000 took 0.996994018555s\n",
      "  LR:                            0.000502482862808\n",
      "  training loss:                 0.005576483173482462\n",
      "  validation loss:               0.015893005704778522\n",
      "  validation error rate:         1.8214285506733825%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 196 of 1000 took 1.01643800735s\n",
      "  LR:                            0.000497876072231\n",
      "  training loss:                 0.006479581560073284\n",
      "  validation loss:               0.014753706763713126\n",
      "  validation error rate:         1.4999999731246914%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 197 of 1000 took 1.00529503822s\n",
      "  LR:                            0.000493311516964\n",
      "  training loss:                 0.006773495736920535\n",
      "  validation loss:               0.01776824536554094\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 198 of 1000 took 0.999012947083s\n",
      "  LR:                            0.000488788809792\n",
      "  training loss:                 0.005342480669359622\n",
      "  validation loss:               0.01318215168281053\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 199 of 1000 took 1.0065600872s\n",
      "  LR:                            0.000484307567048\n",
      "  training loss:                 0.005745514706081046\n",
      "  validation loss:               0.015740804524373937\n",
      "  validation error rate:         1.6428571260933365%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 200 of 1000 took 1.01483607292s\n",
      "  LR:                            0.000479867408584\n",
      "  training loss:                 0.005011005676565487\n",
      "  validation loss:               0.014476156972965068\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 201 of 1000 took 1.00766921043s\n",
      "  LR:                            0.000475467957738\n",
      "  training loss:                 0.004557269055668953\n",
      "  validation loss:               0.017204451641094107\n",
      "  validation error rate:         1.714285702577659%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 202 of 1000 took 1.02533507347s\n",
      "  LR:                            0.0004711088413\n",
      "  training loss:                 0.004971577796523514\n",
      "  validation loss:               0.013440443357829679\n",
      "  validation error rate:         1.3214285685015577%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 203 of 1000 took 1.00996899605s\n",
      "  LR:                            0.000466789689482\n",
      "  training loss:                 0.005491216050123673\n",
      "  validation loss:               0.01572720172456294\n",
      "  validation error rate:         1.6785713977047374%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 204 of 1000 took 1.00426602364s\n",
      "  LR:                            0.000462510135885\n",
      "  training loss:                 0.005425956256572937\n",
      "  validation loss:               0.015301335201521786\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 205 of 1000 took 1.03109812737s\n",
      "  LR:                            0.000458269817471\n",
      "  training loss:                 0.00520026954875314\n",
      "  validation loss:               0.015702107758114283\n",
      "  validation error rate:         1.571428549609014%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 206 of 1000 took 1.01187992096s\n",
      "  LR:                            0.000454068374531\n",
      "  training loss:                 0.00506836989935597\n",
      "  validation loss:               0.01590896784301878\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 207 of 1000 took 1.02269291878s\n",
      "  LR:                            0.000449905450651\n",
      "  training loss:                 0.005155287210971651\n",
      "  validation loss:               0.01646572859807906\n",
      "  validation error rate:         1.6428571327456405%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 208 of 1000 took 1.00947403908s\n",
      "  LR:                            0.000445780692686\n",
      "  training loss:                 0.005464955400213298\n",
      "  validation loss:               0.013848318733035317\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    173\n",
      "  best validation error rate:    1.249999985364931%\n",
      "  test loss:                     1.74332560811724\n",
      "  test error rate:               90.89285731315613%\n",
      "Epoch 209 of 1000 took 1.48967289925s\n",
      "  LR:                            0.00044169375073\n",
      "  training loss:                 0.006092510661041803\n",
      "  validation loss:               0.012378444412807508\n",
      "  validation error rate:         1.1785714088806085%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 210 of 1000 took 1.01310586929s\n",
      "  LR:                            0.000437644278083\n",
      "  training loss:                 0.004850504339179572\n",
      "  validation loss:               0.013721305165485578\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 211 of 1000 took 1.00749707222s\n",
      "  LR:                            0.000433631931224\n",
      "  training loss:                 0.005245121762238662\n",
      "  validation loss:               0.019289385315460095\n",
      "  validation error rate:         1.8214285240641663%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 212 of 1000 took 1.04452800751s\n",
      "  LR:                            0.000429656369782\n",
      "  training loss:                 0.005294389369630474\n",
      "  validation loss:               0.015213495348949177\n",
      "  validation error rate:         1.4999999731246914%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 213 of 1000 took 1.03212404251s\n",
      "  LR:                            0.000425717256507\n",
      "  training loss:                 0.005413596037543718\n",
      "  validation loss:               0.016518090869470013\n",
      "  validation error rate:         1.6428571127887284%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 214 of 1000 took 1.01128101349s\n",
      "  LR:                            0.000421814257239\n",
      "  training loss:                 0.005028014209100921\n",
      "  validation loss:               0.01640044396520222\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 215 of 1000 took 1.02098989487s\n",
      "  LR:                            0.000417947040884\n",
      "  training loss:                 0.004621018266163232\n",
      "  validation loss:               0.01571144521227552\n",
      "  validation error rate:         1.428571409944977%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 216 of 1000 took 1.01776790619s\n",
      "  LR:                            0.000414115279381\n",
      "  training loss:                 0.004609181052471874\n",
      "  validation loss:               0.015360024303903232\n",
      "  validation error rate:         1.464285688208682%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 217 of 1000 took 1.01713013649s\n",
      "  LR:                            0.000410318647679\n",
      "  training loss:                 0.004372227999984341\n",
      "  validation loss:               0.01367326364996708\n",
      "  validation error rate:         1.357142853417567%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 218 of 1000 took 1.02427196503s\n",
      "  LR:                            0.000406556823705\n",
      "  training loss:                 0.004013327430841267\n",
      "  validation loss:               0.014319111381805019\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 219 of 1000 took 1.01651716232s\n",
      "  LR:                            0.000402829488341\n",
      "  training loss:                 0.004142833208521444\n",
      "  validation loss:               0.014625136070597884\n",
      "  validation error rate:         1.392857131681272%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 220 of 1000 took 1.02078485489s\n",
      "  LR:                            0.000399136325393\n",
      "  training loss:                 0.005372444526352303\n",
      "  validation loss:               0.014441668455195409\n",
      "  validation error rate:         1.392857131681272%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 221 of 1000 took 1.02686786652s\n",
      "  LR:                            0.000395477021567\n",
      "  training loss:                 0.0044700446274980685\n",
      "  validation loss:               0.015544774913256074\n",
      "  validation error rate:         1.6428571194410324%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 222 of 1000 took 1.01722407341s\n",
      "  LR:                            0.00039185126644\n",
      "  training loss:                 0.005126909544325078\n",
      "  validation loss:               0.014546808121305535\n",
      "  validation error rate:         1.4999999731246914%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 223 of 1000 took 1.02585887909s\n",
      "  LR:                            0.000388258752435\n",
      "  training loss:                 0.0033717760284643567\n",
      "  validation loss:               0.016244908978381187\n",
      "  validation error rate:         1.535714271345309%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 224 of 1000 took 1.02206707001s\n",
      "  LR:                            0.000384699174797\n",
      "  training loss:                 0.003481340695383123\n",
      "  validation loss:               0.01503151590129294\n",
      "  validation error rate:         1.535714284649917%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 225 of 1000 took 1.02491593361s\n",
      "  LR:                            0.000381172231563\n",
      "  training loss:                 0.005042679888120962\n",
      "  validation loss:               0.014120350948701343\n",
      "  validation error rate:         1.464285688208682%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 226 of 1000 took 1.01283192635s\n",
      "  LR:                            0.000377677623538\n",
      "  training loss:                 0.004625387507043984\n",
      "  validation loss:               0.014735437386272159\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 227 of 1000 took 1.02636694908s\n",
      "  LR:                            0.000374215054273\n",
      "  training loss:                 0.004043085170433321\n",
      "  validation loss:               0.015213487740173346\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 228 of 1000 took 1.03994107246s\n",
      "  LR:                            0.000370784230033\n",
      "  training loss:                 0.004940208044375622\n",
      "  validation loss:               0.01377135861444653\n",
      "  validation error rate:         1.3214285418923413%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 229 of 1000 took 1.02169299126s\n",
      "  LR:                            0.00036738485978\n",
      "  training loss:                 0.00389826705068117\n",
      "  validation loss:               0.015406596996496904\n",
      "  validation error rate:         1.3214285551969494%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 230 of 1000 took 1.01903605461s\n",
      "  LR:                            0.000364016655139\n",
      "  training loss:                 0.003816742411650279\n",
      "  validation loss:               0.01766255995789834\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    209\n",
      "  best validation error rate:    1.1785714088806085%\n",
      "  test loss:                     1.6716302292687553\n",
      "  test error rate:               90.92857156481061%\n",
      "Epoch 231 of 1000 took 1.51752281189s\n",
      "  LR:                            0.000360679330385\n",
      "  training loss:                 0.0039741741244972\n",
      "  validation loss:               0.012547235554653266\n",
      "  validation error rate:         1.1428571239645993%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 232 of 1000 took 0.999047040939s\n",
      "  LR:                            0.000357372602408\n",
      "  training loss:                 0.004108057287093663\n",
      "  validation loss:               0.014357411397642952\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 233 of 1000 took 1.00968194008s\n",
      "  LR:                            0.000354096190696\n",
      "  training loss:                 0.003774761068138212\n",
      "  validation loss:               0.013699203134582458\n",
      "  validation error rate:         1.28571427028094%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 234 of 1000 took 1.03345990181s\n",
      "  LR:                            0.000350849817306\n",
      "  training loss:                 0.003889043177589295\n",
      "  validation loss:               0.01600146780401701\n",
      "  validation error rate:         1.5357142513883966%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 235 of 1000 took 1.02089214325s\n",
      "  LR:                            0.000347633206847\n",
      "  training loss:                 0.004045572466748126\n",
      "  validation loss:               0.016912531952803938\n",
      "  validation error rate:         1.7500000007982766%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 236 of 1000 took 1.00922489166s\n",
      "  LR:                            0.000344446086449\n",
      "  training loss:                 0.004172785684097428\n",
      "  validation loss:               0.016511665453695708\n",
      "  validation error rate:         1.6428571260933365%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 237 of 1000 took 1.0017311573s\n",
      "  LR:                            0.000341288185747\n",
      "  training loss:                 0.003239894812208256\n",
      "  validation loss:               0.01881061564139941\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 238 of 1000 took 1.03976178169s\n",
      "  LR:                            0.000338159236853\n",
      "  training loss:                 0.004406474164173179\n",
      "  validation loss:               0.015517993536475063\n",
      "  validation error rate:         1.571428549609014%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 239 of 1000 took 1.01330494881s\n",
      "  LR:                            0.000335058974334\n",
      "  training loss:                 0.003551111179010203\n",
      "  validation loss:               0.017214465633661087\n",
      "  validation error rate:         1.607142827872719%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 240 of 1000 took 1.00908207893s\n",
      "  LR:                            0.000331987135193\n",
      "  training loss:                 0.004057899491133011\n",
      "  validation loss:               0.01632609012215523\n",
      "  validation error rate:         1.571428549609014%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 241 of 1000 took 1.02017617226s\n",
      "  LR:                            0.000328943458843\n",
      "  training loss:                 0.003439730743842601\n",
      "  validation loss:               0.019260384643010702\n",
      "  validation error rate:         1.6428571260933365%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 242 of 1000 took 1.01531195641s\n",
      "  LR:                            0.000325927687085\n",
      "  training loss:                 0.0032756711671776003\n",
      "  validation loss:               0.018357179908986967\n",
      "  validation error rate:         1.6785713844001293%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 243 of 1000 took 1.00818586349s\n",
      "  LR:                            0.000322939564089\n",
      "  training loss:                 0.003176206218332107\n",
      "  validation loss:               0.01624172461108207\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 244 of 1000 took 0.998497962952s\n",
      "  LR:                            0.000319978836369\n",
      "  training loss:                 0.0030406776563990314\n",
      "  validation loss:               0.020235253502489416\n",
      "  validation error rate:         1.7857142591050694%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 245 of 1000 took 1.00156092644s\n",
      "  LR:                            0.000317045252764\n",
      "  training loss:                 0.0028599522173715954\n",
      "  validation loss:               0.01692863868368022\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 246 of 1000 took 1.01232385635s\n",
      "  LR:                            0.000314138564415\n",
      "  training loss:                 0.0033468763466397134\n",
      "  validation loss:               0.02056396197960047\n",
      "  validation error rate:         1.7857142591050694%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 247 of 1000 took 1.00581502914s\n",
      "  LR:                            0.000311258524745\n",
      "  training loss:                 0.0031513481572320043\n",
      "  validation loss:               0.016560908181937912\n",
      "  validation error rate:         1.535714271345309%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 248 of 1000 took 1.00498080254s\n",
      "  LR:                            0.000308404889438\n",
      "  training loss:                 0.0033537233661798597\n",
      "  validation loss:               0.018101758487318875\n",
      "  validation error rate:         1.5714285363044058%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 249 of 1000 took 1.00784707069s\n",
      "  LR:                            0.000305577416416\n",
      "  training loss:                 0.004075227513698444\n",
      "  validation loss:               0.017084702140006618\n",
      "  validation error rate:         1.6071428145681108%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 250 of 1000 took 1.03127288818s\n",
      "  LR:                            0.000302775865823\n",
      "  training loss:                 0.00384698863426285\n",
      "  validation loss:               0.016426885470926727\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 251 of 1000 took 1.01953577995s\n",
      "  LR:                            0.0003\n",
      "  training loss:                 0.0033062760236883633\n",
      "  validation loss:               0.015849846677286093\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 252 of 1000 took 1.01778793335s\n",
      "  LR:                            0.000297249583468\n",
      "  training loss:                 0.0029005813174294683\n",
      "  validation loss:               0.015516803177368794\n",
      "  validation error rate:         1.285714263628636%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 253 of 1000 took 1.01308083534s\n",
      "  LR:                            0.000294524382906\n",
      "  training loss:                 0.0031910523051491882\n",
      "  validation loss:               0.014945577379486557\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 254 of 1000 took 1.01316213608s\n",
      "  LR:                            0.000291824167133\n",
      "  training loss:                 0.0025254523781554515\n",
      "  validation loss:               0.016722446437532717\n",
      "  validation error rate:         1.3214285551969494%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 255 of 1000 took 1.02025294304s\n",
      "  LR:                            0.000289148707087\n",
      "  training loss:                 0.003423186790988599\n",
      "  validation loss:               0.016682151349012235\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 256 of 1000 took 1.03170108795s\n",
      "  LR:                            0.000286497775806\n",
      "  training loss:                 0.0039304099787841554\n",
      "  validation loss:               0.015538942388242763\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 257 of 1000 took 1.02588486671s\n",
      "  LR:                            0.00028387114841\n",
      "  training loss:                 0.003108902645031134\n",
      "  validation loss:               0.016740647311910654\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 258 of 1000 took 1.01344609261s\n",
      "  LR:                            0.000281268602078\n",
      "  training loss:                 0.0029370309995797204\n",
      "  validation loss:               0.016731589237679145\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 259 of 1000 took 1.02042484283s\n",
      "  LR:                            0.000278689916034\n",
      "  training loss:                 0.0029860380490337028\n",
      "  validation loss:               0.01616546722263073\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 260 of 1000 took 1.0173330307s\n",
      "  LR:                            0.000276134871526\n",
      "  training loss:                 0.00305409827228419\n",
      "  validation loss:               0.017882304498146238\n",
      "  validation error rate:         1.571428549609014%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 261 of 1000 took 1.01266217232s\n",
      "  LR:                            0.000273603251807\n",
      "  training loss:                 0.0028609336333294566\n",
      "  validation loss:               0.017994695959710465\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 262 of 1000 took 1.01561784744s\n",
      "  LR:                            0.000271094842117\n",
      "  training loss:                 0.0032301794831683392\n",
      "  validation loss:               0.014750928212806562\n",
      "  validation error rate:         1.285714263628636%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 263 of 1000 took 1.00727510452s\n",
      "  LR:                            0.000268609429665\n",
      "  training loss:                 0.003223662502483314\n",
      "  validation loss:               0.018654731992553155\n",
      "  validation error rate:         1.7142856759684428%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 264 of 1000 took 1.0178809166s\n",
      "  LR:                            0.000266146803611\n",
      "  training loss:                 0.0038444576526330547\n",
      "  validation loss:               0.015505769922262809\n",
      "  validation error rate:         1.3571428268083505%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 265 of 1000 took 1.01946902275s\n",
      "  LR:                            0.000263706755049\n",
      "  training loss:                 0.0030487765283289583\n",
      "  validation loss:               0.01667262985016157\n",
      "  validation error rate:         1.285714256976332%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 266 of 1000 took 1.01693582535s\n",
      "  LR:                            0.000261289076987\n",
      "  training loss:                 0.0034368088420545545\n",
      "  validation loss:               0.01470189691975118\n",
      "  validation error rate:         1.249999992017235%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 267 of 1000 took 1.01306390762s\n",
      "  LR:                            0.00025889356433\n",
      "  training loss:                 0.0032796888475679544\n",
      "  validation loss:               0.017616630995397436\n",
      "  validation error rate:         1.6071428145681108%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 268 of 1000 took 1.01763391495s\n",
      "  LR:                            0.000256520013865\n",
      "  training loss:                 0.003636465766602391\n",
      "  validation loss:               0.01729908455802485\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 269 of 1000 took 1.02834105492s\n",
      "  LR:                            0.000254168224242\n",
      "  training loss:                 0.0038931949190501814\n",
      "  validation loss:               0.014645483205250847\n",
      "  validation error rate:         1.3214285685015577%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 270 of 1000 took 1.03872680664s\n",
      "  LR:                            0.000251837995956\n",
      "  training loss:                 0.003324458974726868\n",
      "  validation loss:               0.01733244362217842\n",
      "  validation error rate:         1.5714285762182305%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 271 of 1000 took 1.01972794533s\n",
      "  LR:                            0.000249529131331\n",
      "  training loss:                 0.003069929240946829\n",
      "  validation loss:               0.019363915654918986\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 272 of 1000 took 1.02156686783s\n",
      "  LR:                            0.000247241434504\n",
      "  training loss:                 0.003476593237525763\n",
      "  validation loss:               0.017576136508921536\n",
      "  validation error rate:         1.6071428212204149%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 273 of 1000 took 1.0256690979s\n",
      "  LR:                            0.000244974711408\n",
      "  training loss:                 0.0030803712084247416\n",
      "  validation loss:               0.014981535087856506\n",
      "  validation error rate:         1.285714263628636%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 274 of 1000 took 1.01482105255s\n",
      "  LR:                            0.000242728769754\n",
      "  training loss:                 0.0028392905018509895\n",
      "  validation loss:               0.01823574344440106\n",
      "  validation error rate:         1.6428570994841203%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 275 of 1000 took 1.00665593147s\n",
      "  LR:                            0.000240503419016\n",
      "  training loss:                 0.0037587899920147132\n",
      "  validation loss:               0.018551987543718593\n",
      "  validation error rate:         1.6785713844001293%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 276 of 1000 took 1.01455712318s\n",
      "  LR:                            0.000238298470417\n",
      "  training loss:                 0.0025984686763823608\n",
      "  validation loss:               0.015141186755499803\n",
      "  validation error rate:         1.392857131681272%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 277 of 1000 took 1.00515985489s\n",
      "  LR:                            0.000236113736909\n",
      "  training loss:                 0.002910047119212322\n",
      "  validation loss:               0.015695442326083203\n",
      "  validation error rate:         1.3571428467652626%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 278 of 1000 took 1.00760197639s\n",
      "  LR:                            0.000233949033157\n",
      "  training loss:                 0.002230908135157626\n",
      "  validation loss:               0.01596766283928933\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 279 of 1000 took 1.05293512344s\n",
      "  LR:                            0.000231804175529\n",
      "  training loss:                 0.002450597924331198\n",
      "  validation loss:               0.01623693604778964\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 280 of 1000 took 1.00547194481s\n",
      "  LR:                            0.000229678982073\n",
      "  training loss:                 0.0028782363734843087\n",
      "  validation loss:               0.0180316180922091\n",
      "  validation error rate:         1.6785713910524334%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 281 of 1000 took 1.00897717476s\n",
      "  LR:                            0.000227573272509\n",
      "  training loss:                 0.002305684462707551\n",
      "  validation loss:               0.015613463216880064\n",
      "  validation error rate:         1.428571409944977%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 282 of 1000 took 1.01367115974s\n",
      "  LR:                            0.000225486868205\n",
      "  training loss:                 0.0031928384167579627\n",
      "  validation loss:               0.017402412556553566\n",
      "  validation error rate:         1.5714285429567099%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 283 of 1000 took 1.02365016937s\n",
      "  LR:                            0.000223419592172\n",
      "  training loss:                 0.003396796647923432\n",
      "  validation loss:               0.018312905572266964\n",
      "  validation error rate:         1.6071428212204149%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 284 of 1000 took 1.02452111244s\n",
      "  LR:                            0.000221371269039\n",
      "  training loss:                 0.0022748204721036768\n",
      "  validation loss:               0.016032996326820075\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 285 of 1000 took 1.02471017838s\n",
      "  LR:                            0.000219341725045\n",
      "  training loss:                 0.002499420345841773\n",
      "  validation loss:               0.018134484664049717\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 286 of 1000 took 1.0224301815s\n",
      "  LR:                            0.000217330788022\n",
      "  training loss:                 0.0024497856961716025\n",
      "  validation loss:               0.01677485908310012\n",
      "  validation error rate:         1.571428549609014%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 287 of 1000 took 1.02258706093s\n",
      "  LR:                            0.000215338287381\n",
      "  training loss:                 0.0030259047006599275\n",
      "  validation loss:               0.020690939400083153\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 288 of 1000 took 1.01833796501s\n",
      "  LR:                            0.000213364054096\n",
      "  training loss:                 0.002315795256478904\n",
      "  validation loss:               0.016574876867725914\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 289 of 1000 took 1.03334093094s\n",
      "  LR:                            0.00021140792069\n",
      "  training loss:                 0.002557061373622941\n",
      "  validation loss:               0.016870017092675278\n",
      "  validation error rate:         1.3571428467652626%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 290 of 1000 took 1.02538299561s\n",
      "  LR:                            0.000209469721223\n",
      "  training loss:                 0.0031362920317477005\n",
      "  validation loss:               0.01604411135277774\n",
      "  validation error rate:         1.392857131681272%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 291 of 1000 took 1.02558493614s\n",
      "  LR:                            0.000207549291276\n",
      "  training loss:                 0.0026216739343309873\n",
      "  validation loss:               0.017080918009160735\n",
      "  validation error rate:         1.392857131681272%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 292 of 1000 took 1.01927900314s\n",
      "  LR:                            0.000205646467936\n",
      "  training loss:                 0.0025765778780195807\n",
      "  validation loss:               0.014030873332202987\n",
      "  validation error rate:         1.2499999787126268%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 293 of 1000 took 1.01458907127s\n",
      "  LR:                            0.000203761089785\n",
      "  training loss:                 0.002552375627334079\n",
      "  validation loss:               0.021544114815437103\n",
      "  validation error rate:         1.8214285573256865%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 294 of 1000 took 1.00773215294s\n",
      "  LR:                            0.000201892996885\n",
      "  training loss:                 0.0020396150455460026\n",
      "  validation loss:               0.018543153259607998\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 295 of 1000 took 1.01991295815s\n",
      "  LR:                            0.000200042030764\n",
      "  training loss:                 0.0023820143909394093\n",
      "  validation loss:               0.015340264176675842\n",
      "  validation error rate:         1.285714256976332%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 296 of 1000 took 1.02092409134s\n",
      "  LR:                            0.000198208034402\n",
      "  training loss:                 0.003548200524762572\n",
      "  validation loss:               0.016700132317964744\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 297 of 1000 took 1.00381612778s\n",
      "  LR:                            0.00019639085222\n",
      "  training loss:                 0.0018284887605084484\n",
      "  validation loss:               0.018476771172686313\n",
      "  validation error rate:         1.6785713910524334%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 298 of 1000 took 1.00695300102s\n",
      "  LR:                            0.000194590330064\n",
      "  training loss:                 0.001862684270257459\n",
      "  validation loss:               0.020783688411549\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 299 of 1000 took 1.00085091591s\n",
      "  LR:                            0.000192806315195\n",
      "  training loss:                 0.002325123019949996\n",
      "  validation loss:               0.018302201798048503\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 300 of 1000 took 1.004155159s\n",
      "  LR:                            0.000191038656272\n",
      "  training loss:                 0.0026866297920770253\n",
      "  validation loss:               0.01789565422898574\n",
      "  validation error rate:         1.571428549609014%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 301 of 1000 took 1.01927804947s\n",
      "  LR:                            0.000189287203344\n",
      "  training loss:                 0.002720633130170694\n",
      "  validation loss:               0.0161780169271099\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 302 of 1000 took 1.00835490227s\n",
      "  LR:                            0.000187551807833\n",
      "  training loss:                 0.0022661027036814203\n",
      "  validation loss:               0.017468509577676223\n",
      "  validation error rate:         1.607142827872719%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 303 of 1000 took 1.008934021s\n",
      "  LR:                            0.000185832322523\n",
      "  training loss:                 0.0025165684444646906\n",
      "  validation loss:               0.016084027341094043\n",
      "  validation error rate:         1.2142857004489218%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 304 of 1000 took 1.00177001953s\n",
      "  LR:                            0.000184128601549\n",
      "  training loss:                 0.002561175776047682\n",
      "  validation loss:               0.01991183367382681\n",
      "  validation error rate:         1.7857142923665896%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 305 of 1000 took 1.00461697578s\n",
      "  LR:                            0.000182440500384\n",
      "  training loss:                 0.0023605896015236366\n",
      "  validation loss:               0.016432886758739836\n",
      "  validation error rate:         1.3928571117243596%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 306 of 1000 took 1.01997089386s\n",
      "  LR:                            0.000180767875822\n",
      "  training loss:                 0.0019187932563053277\n",
      "  validation loss:               0.01847166419455399\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 307 of 1000 took 1.01657700539s\n",
      "  LR:                            0.000179110585975\n",
      "  training loss:                 0.0026403232828917734\n",
      "  validation loss:               0.016241714310646267\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 308 of 1000 took 1.00900793076s\n",
      "  LR:                            0.000177468490253\n",
      "  training loss:                 0.0017458886722338588\n",
      "  validation loss:               0.017313855342113778\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 309 of 1000 took 1.01887607574s\n",
      "  LR:                            0.000175841449354\n",
      "  training loss:                 0.0021440589450054067\n",
      "  validation loss:               0.01784336057491081\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 310 of 1000 took 1.01769018173s\n",
      "  LR:                            0.000174229325256\n",
      "  training loss:                 0.0022487822345256597\n",
      "  validation loss:               0.014445348150307577\n",
      "  validation error rate:         1.2142856937966175%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 311 of 1000 took 1.0211379528s\n",
      "  LR:                            0.000172631981201\n",
      "  training loss:                 0.002045611695083447\n",
      "  validation loss:               0.015540746512734975\n",
      "  validation error rate:         1.1785714221852166%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 312 of 1000 took 1.02168107033s\n",
      "  LR:                            0.000171049281684\n",
      "  training loss:                 0.0026242510027274877\n",
      "  validation loss:               0.01856211150318034\n",
      "  validation error rate:         1.6071428544819355%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 313 of 1000 took 1.00711297989s\n",
      "  LR:                            0.000169481092444\n",
      "  training loss:                 0.002037789116161548\n",
      "  validation loss:               0.01758237607374927\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 314 of 1000 took 1.02545213699s\n",
      "  LR:                            0.000167927280449\n",
      "  training loss:                 0.0025226811213796656\n",
      "  validation loss:               0.020011237913942232\n",
      "  validation error rate:         1.6071428212204149%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 315 of 1000 took 1.0189101696s\n",
      "  LR:                            0.000166387713887\n",
      "  training loss:                 0.0020496843744186822\n",
      "  validation loss:               0.018933456297548088\n",
      "  validation error rate:         1.607142827872719%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 316 of 1000 took 1.00532603264s\n",
      "  LR:                            0.000164862262157\n",
      "  training loss:                 0.002435442083311928\n",
      "  validation loss:               0.020100364156773156\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 317 of 1000 took 1.00077319145s\n",
      "  LR:                            0.000163350795853\n",
      "  training loss:                 0.001823315731448862\n",
      "  validation loss:               0.017980658720002145\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 318 of 1000 took 1.00945997238s\n",
      "  LR:                            0.000161853186755\n",
      "  training loss:                 0.0022279498063439594\n",
      "  validation loss:               0.016619745974894937\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 319 of 1000 took 1.00889611244s\n",
      "  LR:                            0.000160369307819\n",
      "  training loss:                 0.0023715267384164583\n",
      "  validation loss:               0.015847374040098266\n",
      "  validation error rate:         1.2142857004489218%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 320 of 1000 took 1.00331997871s\n",
      "  LR:                            0.000158899033167\n",
      "  training loss:                 0.0019331032724982618\n",
      "  validation loss:               0.016510133968300318\n",
      "  validation error rate:         1.3214285685015577%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 321 of 1000 took 1.00681495667s\n",
      "  LR:                            0.000157442238075\n",
      "  training loss:                 0.0022233870204538962\n",
      "  validation loss:               0.019846409906417\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 322 of 1000 took 1.01246714592s\n",
      "  LR:                            0.00015599879896\n",
      "  training loss:                 0.001433001154097891\n",
      "  validation loss:               0.017502388996522962\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 323 of 1000 took 1.01421189308s\n",
      "  LR:                            0.000154568593375\n",
      "  training loss:                 0.0021256135606071945\n",
      "  validation loss:               0.01597999977496199\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 324 of 1000 took 1.01658606529s\n",
      "  LR:                            0.000153151499993\n",
      "  training loss:                 0.002490038737968301\n",
      "  validation loss:               0.018126680987604362\n",
      "  validation error rate:         1.4285714299018895%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 325 of 1000 took 1.01314711571s\n",
      "  LR:                            0.000151747398601\n",
      "  training loss:                 0.0018291093936113612\n",
      "  validation loss:               0.02006858408836771\n",
      "  validation error rate:         1.6428571260933365%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 326 of 1000 took 1.00774908066s\n",
      "  LR:                            0.000150356170088\n",
      "  training loss:                 0.0013851077166069604\n",
      "  validation loss:               0.019275196267603562\n",
      "  validation error rate:         1.6071428212204149%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 327 of 1000 took 1.0050368309s\n",
      "  LR:                            0.000148977696435\n",
      "  training loss:                 0.0015766573209016683\n",
      "  validation loss:               0.018974120241896993\n",
      "  validation error rate:         1.428571409944977%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 328 of 1000 took 1.01054692268s\n",
      "  LR:                            0.000147611860704\n",
      "  training loss:                 0.0016194841847784439\n",
      "  validation loss:               0.017795974571656967\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 329 of 1000 took 1.01372313499s\n",
      "  LR:                            0.000146258547031\n",
      "  training loss:                 0.0017380184006656556\n",
      "  validation loss:               0.019593117820749382\n",
      "  validation error rate:         1.5714285429567099%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 330 of 1000 took 1.01368308067s\n",
      "  LR:                            0.000144917640612\n",
      "  training loss:                 0.001757726798316927\n",
      "  validation loss:               0.01705923180959092\n",
      "  validation error rate:         1.2857142835855484%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 331 of 1000 took 1.03365588188s\n",
      "  LR:                            0.000143589027697\n",
      "  training loss:                 0.0015896637049563117\n",
      "  validation loss:               0.018176221476941073\n",
      "  validation error rate:         1.3214285685015577%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 332 of 1000 took 1.01305198669s\n",
      "  LR:                            0.000142272595578\n",
      "  training loss:                 0.002598265971945533\n",
      "  validation loss:               0.017014568906113987\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 333 of 1000 took 1.01264286041s\n",
      "  LR:                            0.000140968232582\n",
      "  training loss:                 0.00168702425340398\n",
      "  validation loss:               0.019691011418347313\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 334 of 1000 took 1.01408696175s\n",
      "  LR:                            0.000139675828057\n",
      "  training loss:                 0.002136423322243739\n",
      "  validation loss:               0.01855851145192641\n",
      "  validation error rate:         1.5714285429567099%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 335 of 1000 took 1.01340293884s\n",
      "  LR:                            0.000138395272368\n",
      "  training loss:                 0.0017471152060793698\n",
      "  validation loss:               0.018985870184094113\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 336 of 1000 took 1.01547408104s\n",
      "  LR:                            0.000137126456884\n",
      "  training loss:                 0.0017111983898356652\n",
      "  validation loss:               0.021415407910012618\n",
      "  validation error rate:         1.6785714043570414%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 337 of 1000 took 1.01229596138s\n",
      "  LR:                            0.000135869273971\n",
      "  training loss:                 0.002248994611502841\n",
      "  validation loss:               0.016661442780007616\n",
      "  validation error rate:         1.285714263628636%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 338 of 1000 took 1.02221608162s\n",
      "  LR:                            0.00013462361698\n",
      "  training loss:                 0.002051287724266197\n",
      "  validation loss:               0.021925549531130985\n",
      "  validation error rate:         1.714285689273051%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 339 of 1000 took 1.00893497467s\n",
      "  LR:                            0.000133389380241\n",
      "  training loss:                 0.0019483058491352816\n",
      "  validation loss:               0.020179231576877652\n",
      "  validation error rate:         1.6071428145681108%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 340 of 1000 took 1.01164197922s\n",
      "  LR:                            0.000132166459052\n",
      "  training loss:                 0.001899077039164735\n",
      "  validation loss:               0.016938326124805565\n",
      "  validation error rate:         1.3214285418923413%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 341 of 1000 took 1.00993013382s\n",
      "  LR:                            0.000130954749672\n",
      "  training loss:                 0.0020302745447693003\n",
      "  validation loss:               0.01754435366816714\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 342 of 1000 took 1.00822401047s\n",
      "  LR:                            0.000129754149311\n",
      "  training loss:                 0.0016680771987995179\n",
      "  validation loss:               0.017262278058816655\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 343 of 1000 took 1.02699303627s\n",
      "  LR:                            0.000128564556119\n",
      "  training loss:                 0.0016690880604461628\n",
      "  validation loss:               0.01849654082809593\n",
      "  validation error rate:         1.5714285429567099%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 344 of 1000 took 1.01005411148s\n",
      "  LR:                            0.000127385869184\n",
      "  training loss:                 0.002124621077609845\n",
      "  validation loss:               0.017412001607356484\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 345 of 1000 took 1.01270794868s\n",
      "  LR:                            0.000126217988515\n",
      "  training loss:                 0.0017266884981095429\n",
      "  validation loss:               0.015514761505102115\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 346 of 1000 took 1.02535581589s\n",
      "  LR:                            0.000125060815041\n",
      "  training loss:                 0.0011743204374825462\n",
      "  validation loss:               0.01855038648467858\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 347 of 1000 took 1.00854420662s\n",
      "  LR:                            0.000123914250597\n",
      "  training loss:                 0.001999042001499915\n",
      "  validation loss:               0.018338412011481914\n",
      "  validation error rate:         1.3571428268083505%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 348 of 1000 took 1.01377797127s\n",
      "  LR:                            0.000122778197919\n",
      "  training loss:                 0.0017737282568435497\n",
      "  validation loss:               0.018080130356143594\n",
      "  validation error rate:         1.535714271345309%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 349 of 1000 took 1.00731301308s\n",
      "  LR:                            0.000121652560635\n",
      "  training loss:                 0.0012540045745053623\n",
      "  validation loss:               0.0182795910417326\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 350 of 1000 took 1.01086401939s\n",
      "  LR:                            0.000120537243255\n",
      "  training loss:                 0.001440244931843532\n",
      "  validation loss:               0.018282990464058457\n",
      "  validation error rate:         1.392857131681272%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 351 of 1000 took 1.00951194763s\n",
      "  LR:                            0.000119432151166\n",
      "  training loss:                 0.0017782444150159988\n",
      "  validation loss:               0.018203857471235096\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 352 of 1000 took 1.00866293907s\n",
      "  LR:                            0.000118337190623\n",
      "  training loss:                 0.0015605162104413788\n",
      "  validation loss:               0.020471782400168843\n",
      "  validation error rate:         1.6071428212204149%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 353 of 1000 took 1.01034212112s\n",
      "  LR:                            0.000117252268738\n",
      "  training loss:                 0.0018049025808175108\n",
      "  validation loss:               0.021038667001578557\n",
      "  validation error rate:         1.6428571260933365%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 354 of 1000 took 1.0128839016s\n",
      "  LR:                            0.000116177293476\n",
      "  training loss:                 0.0018090651628520336\n",
      "  validation loss:               0.01859908759277979\n",
      "  validation error rate:         1.5714285363044058%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 355 of 1000 took 1.01460909843s\n",
      "  LR:                            0.000115112173648\n",
      "  training loss:                 0.0015238534371340882\n",
      "  validation loss:               0.020201611663131707\n",
      "  validation error rate:         1.5714285363044058%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 356 of 1000 took 1.00355005264s\n",
      "  LR:                            0.000114056818896\n",
      "  training loss:                 0.001915245280106854\n",
      "  validation loss:               0.017935663320583575\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 357 of 1000 took 1.00719308853s\n",
      "  LR:                            0.000113011139695\n",
      "  training loss:                 0.0021616472638087583\n",
      "  validation loss:               0.01925378753436949\n",
      "  validation error rate:         1.6071428478296315%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 358 of 1000 took 1.0125579834s\n",
      "  LR:                            0.000111975047339\n",
      "  training loss:                 0.0019154165567884132\n",
      "  validation loss:               0.019992753879965415\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 359 of 1000 took 1.02668905258s\n",
      "  LR:                            0.000110948453934\n",
      "  training loss:                 0.0014452818888859042\n",
      "  validation loss:               0.021741174444528992\n",
      "  validation error rate:         1.678571411009346%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 360 of 1000 took 1.01351380348s\n",
      "  LR:                            0.000109931272394\n",
      "  training loss:                 0.0014748130762220226\n",
      "  validation loss:               0.0170762460141172\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 361 of 1000 took 1.01568603516s\n",
      "  LR:                            0.000108923416431\n",
      "  training loss:                 0.0013616364967457256\n",
      "  validation loss:               0.01815962781880184\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 362 of 1000 took 1.01117610931s\n",
      "  LR:                            0.000107924800547\n",
      "  training loss:                 0.001517691069533184\n",
      "  validation loss:               0.018012552042713587\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 363 of 1000 took 1.01061296463s\n",
      "  LR:                            0.000106935340028\n",
      "  training loss:                 0.0019977790418659637\n",
      "  validation loss:               0.01906211192337131\n",
      "  validation error rate:         1.6071428345250234%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 364 of 1000 took 1.01809597015s\n",
      "  LR:                            0.000105954950938\n",
      "  training loss:                 0.0015540275322065934\n",
      "  validation loss:               0.01827728050972967\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 365 of 1000 took 1.01506090164s\n",
      "  LR:                            0.000104983550109\n",
      "  training loss:                 0.001513380191798152\n",
      "  validation loss:               0.01871928506508474\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 366 of 1000 took 1.0154979229s\n",
      "  LR:                            0.000104021055136\n",
      "  training loss:                 0.0020420644569874888\n",
      "  validation loss:               0.018262864388166884\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 367 of 1000 took 1.01583504677s\n",
      "  LR:                            0.00010306738437\n",
      "  training loss:                 0.0015855605591990323\n",
      "  validation loss:               0.016694190224175794\n",
      "  validation error rate:         1.3571428268083505%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 368 of 1000 took 1.02105903625s\n",
      "  LR:                            0.00010212245691\n",
      "  training loss:                 0.0013996671542586495\n",
      "  validation loss:               0.01769613182425798\n",
      "  validation error rate:         1.3214285418923413%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 369 of 1000 took 1.0173740387s\n",
      "  LR:                            0.000101186192598\n",
      "  training loss:                 0.0013237106741516916\n",
      "  validation loss:               0.017967184237412375\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 370 of 1000 took 1.01245307922s\n",
      "  LR:                            0.000100258512008\n",
      "  training loss:                 0.0012269168671015422\n",
      "  validation loss:               0.02147845371368768\n",
      "  validation error rate:         1.6071428478296315%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 371 of 1000 took 1.00928807259s\n",
      "  LR:                            9.93393364448e-05\n",
      "  training loss:                 0.0019405295422984636\n",
      "  validation loss:               0.020008871992883672\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 372 of 1000 took 1.01453304291s\n",
      "  LR:                            9.84285879339e-05\n",
      "  training loss:                 0.001246798060386776\n",
      "  validation loss:               0.01803238540222602\n",
      "  validation error rate:         1.464285688208682%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 373 of 1000 took 1.01575803757s\n",
      "  LR:                            9.75261892156e-05\n",
      "  training loss:                 0.001789447642611824\n",
      "  validation loss:               0.02115554579696826\n",
      "  validation error rate:         1.6428570994841203%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 374 of 1000 took 1.02205204964s\n",
      "  LR:                            9.66320637385e-05\n",
      "  training loss:                 0.001437657008360351\n",
      "  validation loss:               0.021180725510930642\n",
      "  validation error rate:         1.5714285363044058%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 375 of 1000 took 1.01593899727s\n",
      "  LR:                            9.5746135653e-05\n",
      "  training loss:                 0.0016638350782306375\n",
      "  validation loss:               0.02010098330044587\n",
      "  validation error rate:         1.6428571327456405%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 376 of 1000 took 1.02262592316s\n",
      "  LR:                            9.48683298051e-05\n",
      "  training loss:                 0.001980600324768201\n",
      "  validation loss:               0.0175695698209373\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 377 of 1000 took 1.02210307121s\n",
      "  LR:                            9.39985717295e-05\n",
      "  training loss:                 0.0013441243604344275\n",
      "  validation loss:               0.019912056641520133\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 378 of 1000 took 1.02071809769s\n",
      "  LR:                            9.31367876439e-05\n",
      "  training loss:                 0.001457604285281591\n",
      "  validation loss:               0.01892714887591345\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 379 of 1000 took 1.02373886108s\n",
      "  LR:                            9.22829044422e-05\n",
      "  training loss:                 0.0010784756794584931\n",
      "  validation loss:               0.017387061051229984\n",
      "  validation error rate:         1.3928571250289679%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 380 of 1000 took 1.01768183708s\n",
      "  LR:                            9.14368496888e-05\n",
      "  training loss:                 0.0016603813327984755\n",
      "  validation loss:               0.017824525324093492\n",
      "  validation error rate:         1.3928571117243596%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 381 of 1000 took 1.02105093002s\n",
      "  LR:                            9.05985516121e-05\n",
      "  training loss:                 0.0012550043070186589\n",
      "  validation loss:               0.018264990815493678\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 382 of 1000 took 1.01585698128s\n",
      "  LR:                            8.97679390982e-05\n",
      "  training loss:                 0.0014681452361602631\n",
      "  validation loss:               0.0183728258541253\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 383 of 1000 took 1.01566290855s\n",
      "  LR:                            8.89449416857e-05\n",
      "  training loss:                 0.0012702902370037778\n",
      "  validation loss:               0.019314855894760643\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 384 of 1000 took 1.02126979828s\n",
      "  LR:                            8.81294895588e-05\n",
      "  training loss:                 0.00123024908673281\n",
      "  validation loss:               0.01925189561110788\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 385 of 1000 took 1.01319813728s\n",
      "  LR:                            8.7321513542e-05\n",
      "  training loss:                 0.0011951315229448824\n",
      "  validation loss:               0.01910704097826965\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 386 of 1000 took 1.02055478096s\n",
      "  LR:                            8.65209450938e-05\n",
      "  training loss:                 0.0013539390952266776\n",
      "  validation loss:               0.018896501040144034\n",
      "  validation error rate:         1.285714256976332%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 387 of 1000 took 1.01563501358s\n",
      "  LR:                            8.57277163012e-05\n",
      "  training loss:                 0.001512969167375435\n",
      "  validation loss:               0.02118894392432529\n",
      "  validation error rate:         1.5714285429567099%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 388 of 1000 took 1.02292394638s\n",
      "  LR:                            8.4941759874e-05\n",
      "  training loss:                 0.001999051658486153\n",
      "  validation loss:               0.02009612820568561\n",
      "  validation error rate:         1.6071428478296315%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 389 of 1000 took 1.02168703079s\n",
      "  LR:                            8.41630091386e-05\n",
      "  training loss:                 0.001373353253126866\n",
      "  validation loss:               0.018714341941688924\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 390 of 1000 took 1.0470430851s\n",
      "  LR:                            8.33913980328e-05\n",
      "  training loss:                 0.0013019818055133381\n",
      "  validation loss:               0.02026091671813138\n",
      "  validation error rate:         1.571428562913622%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 391 of 1000 took 1.03795289993s\n",
      "  LR:                            8.26268611001e-05\n",
      "  training loss:                 0.002080052463996842\n",
      "  validation loss:               0.018700521031860262\n",
      "  validation error rate:         1.607142827872719%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 392 of 1000 took 1.0459959507s\n",
      "  LR:                            8.18693334842e-05\n",
      "  training loss:                 0.0013604744508354577\n",
      "  validation loss:               0.020945728712831624\n",
      "  validation error rate:         1.6071428478296315%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 393 of 1000 took 1.02186608315s\n",
      "  LR:                            8.11187509233e-05\n",
      "  training loss:                 0.001211190633781665\n",
      "  validation loss:               0.018715435163371503\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 394 of 1000 took 1.02011299133s\n",
      "  LR:                            8.03750497446e-05\n",
      "  training loss:                 0.0011217334725210418\n",
      "  validation loss:               0.019357084243974247\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 395 of 1000 took 1.02394509315s\n",
      "  LR:                            7.96381668593e-05\n",
      "  training loss:                 0.0020312357707593146\n",
      "  validation loss:               0.019032017465503617\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 396 of 1000 took 1.02076387405s\n",
      "  LR:                            7.89080397569e-05\n",
      "  training loss:                 0.0019597006484165084\n",
      "  validation loss:               0.018856210067066774\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 397 of 1000 took 1.04579901695s\n",
      "  LR:                            7.81846065e-05\n",
      "  training loss:                 0.0013505962793207052\n",
      "  validation loss:               0.017750390464373465\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 398 of 1000 took 1.02322101593s\n",
      "  LR:                            7.7467805719e-05\n",
      "  training loss:                 0.0017579133417725376\n",
      "  validation loss:               0.01892164738842439\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 399 of 1000 took 1.03313183784s\n",
      "  LR:                            7.67575766072e-05\n",
      "  training loss:                 0.0014735857841836097\n",
      "  validation loss:               0.017176823890362618\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 400 of 1000 took 1.03646492958s\n",
      "  LR:                            7.60538589149e-05\n",
      "  training loss:                 0.0011178149026244391\n",
      "  validation loss:               0.017897014522791972\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 401 of 1000 took 1.01760387421s\n",
      "  LR:                            7.53565929453e-05\n",
      "  training loss:                 0.0016429485315149898\n",
      "  validation loss:               0.019561272019927856\n",
      "  validation error rate:         1.6071428212204149%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 402 of 1000 took 1.02495121956s\n",
      "  LR:                            7.46657195485e-05\n",
      "  training loss:                 0.0014207872423730135\n",
      "  validation loss:               0.020733097248726802\n",
      "  validation error rate:         1.5714285429567099%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 403 of 1000 took 1.01422095299s\n",
      "  LR:                            7.3981180117e-05\n",
      "  training loss:                 0.00127554514225026\n",
      "  validation loss:               0.02002217074213673\n",
      "  validation error rate:         1.5714285429567099%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 404 of 1000 took 1.01724791527s\n",
      "  LR:                            7.33029165808e-05\n",
      "  training loss:                 0.0009039753706095072\n",
      "  validation loss:               0.018914383535957313\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 405 of 1000 took 1.03250980377s\n",
      "  LR:                            7.26308714021e-05\n",
      "  training loss:                 0.0021057980435722607\n",
      "  validation loss:               0.018409366063289263\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 406 of 1000 took 1.01278209686s\n",
      "  LR:                            7.19649875706e-05\n",
      "  training loss:                 0.0014080001023363644\n",
      "  validation loss:               0.01739655721134373\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 407 of 1000 took 1.02040791512s\n",
      "  LR:                            7.13052085987e-05\n",
      "  training loss:                 0.001254454499130856\n",
      "  validation loss:               0.016809552646269106\n",
      "  validation error rate:         1.285714263628636%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 408 of 1000 took 1.01138687134s\n",
      "  LR:                            7.06514785169e-05\n",
      "  training loss:                 0.00124673754561199\n",
      "  validation loss:               0.020030805907611336\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 409 of 1000 took 1.01989507675s\n",
      "  LR:                            7.00037418684e-05\n",
      "  training loss:                 0.000985442610768672\n",
      "  validation loss:               0.018559672204511508\n",
      "  validation error rate:         1.535714271345309%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 410 of 1000 took 1.00744700432s\n",
      "  LR:                            6.93619437053e-05\n",
      "  training loss:                 0.0014362561303404592\n",
      "  validation loss:               0.01768140391712742\n",
      "  validation error rate:         1.3571428268083505%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 411 of 1000 took 1.01748514175s\n",
      "  LR:                            6.8726029583e-05\n",
      "  training loss:                 0.0011641704939125595\n",
      "  validation loss:               0.018571484910905513\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 412 of 1000 took 1.0225481987s\n",
      "  LR:                            6.80959455565e-05\n",
      "  training loss:                 0.0009916163336155853\n",
      "  validation loss:               0.018479876736721832\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 413 of 1000 took 1.01698303223s\n",
      "  LR:                            6.74716381751e-05\n",
      "  training loss:                 0.0007653401228307142\n",
      "  validation loss:               0.020485644678826378\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 414 of 1000 took 1.02505803108s\n",
      "  LR:                            6.68530544781e-05\n",
      "  training loss:                 0.0010667463771964695\n",
      "  validation loss:               0.01860366025292543\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 415 of 1000 took 1.03175878525s\n",
      "  LR:                            6.62401419906e-05\n",
      "  training loss:                 0.0013244951138657972\n",
      "  validation loss:               0.017905208664680167\n",
      "  validation error rate:         1.3571428268083505%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 416 of 1000 took 1.0439620018s\n",
      "  LR:                            6.56328487185e-05\n",
      "  training loss:                 0.0014668726786348262\n",
      "  validation loss:               0.01851540759837787\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 417 of 1000 took 1.07253098488s\n",
      "  LR:                            6.50311231446e-05\n",
      "  training loss:                 0.0012458507413531847\n",
      "  validation loss:               0.017314738512920615\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 418 of 1000 took 1.04203486443s\n",
      "  LR:                            6.44349142239e-05\n",
      "  training loss:                 0.0011628744007053512\n",
      "  validation loss:               0.019138193564556007\n",
      "  validation error rate:         1.428571409944977%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 419 of 1000 took 1.02320694923s\n",
      "  LR:                            6.38441713795e-05\n",
      "  training loss:                 0.001381058451031148\n",
      "  validation loss:               0.02115275278421385\n",
      "  validation error rate:         1.5714285429567099%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 420 of 1000 took 1.02445197105s\n",
      "  LR:                            6.3258844498e-05\n",
      "  training loss:                 0.0007928580824078742\n",
      "  validation loss:               0.019181781230664847\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 421 of 1000 took 1.02460694313s\n",
      "  LR:                            6.26788839256e-05\n",
      "  training loss:                 0.0007781947092564386\n",
      "  validation loss:               0.020685744821093976\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 422 of 1000 took 1.03682208061s\n",
      "  LR:                            6.21042404637e-05\n",
      "  training loss:                 0.001615265418095182\n",
      "  validation loss:               0.02098392368072512\n",
      "  validation error rate:         1.4642857214702028%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 423 of 1000 took 1.02291893959s\n",
      "  LR:                            6.15348653648e-05\n",
      "  training loss:                 0.0010339478950540711\n",
      "  validation loss:               0.02107354914603223\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 424 of 1000 took 1.01382493973s\n",
      "  LR:                            6.09707103281e-05\n",
      "  training loss:                 0.001168446282138717\n",
      "  validation loss:               0.018109671122699313\n",
      "  validation error rate:         1.3928571117243596%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 425 of 1000 took 1.03008985519s\n",
      "  LR:                            6.04117274959e-05\n",
      "  training loss:                 0.0021201293498638515\n",
      "  validation loss:               0.019634797515509814\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 426 of 1000 took 1.05896711349s\n",
      "  LR:                            5.98578694491e-05\n",
      "  training loss:                 0.0010407659902585584\n",
      "  validation loss:               0.021254819205816084\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 427 of 1000 took 1.04004883766s\n",
      "  LR:                            5.93090892034e-05\n",
      "  training loss:                 0.0011700127242728045\n",
      "  validation loss:               0.02058936919118943\n",
      "  validation error rate:         1.4999999930816037%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 428 of 1000 took 1.05069899559s\n",
      "  LR:                            5.87653402052e-05\n",
      "  training loss:                 0.0015662605924826026\n",
      "  validation loss:               0.019091229667537846\n",
      "  validation error rate:         1.3571428268083505%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 429 of 1000 took 1.04636383057s\n",
      "  LR:                            5.82265763278e-05\n",
      "  training loss:                 0.0015032749315570767\n",
      "  validation loss:               0.020136860515529622\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 430 of 1000 took 1.04520988464s\n",
      "  LR:                            5.76927518673e-05\n",
      "  training loss:                 0.001204517066654255\n",
      "  validation loss:               0.01848821532835895\n",
      "  validation error rate:         1.3214285418923413%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 431 of 1000 took 1.0529961586s\n",
      "  LR:                            5.71638215389e-05\n",
      "  training loss:                 0.0013910090822936137\n",
      "  validation loss:               0.01800934919655057\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 432 of 1000 took 1.04405713081s\n",
      "  LR:                            5.66397404729e-05\n",
      "  training loss:                 0.001118958604627096\n",
      "  validation loss:               0.01845532890209662\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 433 of 1000 took 1.04955887794s\n",
      "  LR:                            5.6120464211e-05\n",
      "  training loss:                 0.0012265643938088665\n",
      "  validation loss:               0.02066974372110053\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 434 of 1000 took 1.05354690552s\n",
      "  LR:                            5.56059487024e-05\n",
      "  training loss:                 0.0010566907165574146\n",
      "  validation loss:               0.019364736736211592\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 435 of 1000 took 1.01041412354s\n",
      "  LR:                            5.50961503005e-05\n",
      "  training loss:                 0.000998292938798972\n",
      "  validation loss:               0.018741943349596113\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 436 of 1000 took 1.01444602013s\n",
      "  LR:                            5.45910257583e-05\n",
      "  training loss:                 0.0012595761392241362\n",
      "  validation loss:               0.019187520147949857\n",
      "  validation error rate:         1.3571428268083505%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 437 of 1000 took 1.01510310173s\n",
      "  LR:                            5.40905322258e-05\n",
      "  training loss:                 0.0008911446512012797\n",
      "  validation loss:               0.02093228321146106\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 438 of 1000 took 1.02899003029s\n",
      "  LR:                            5.35946272456e-05\n",
      "  training loss:                 0.0007830542322862504\n",
      "  validation loss:               0.01839322763096009\n",
      "  validation error rate:         1.3214285551969494%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 439 of 1000 took 1.02057003975s\n",
      "  LR:                            5.31032687495e-05\n",
      "  training loss:                 0.0006578515158041649\n",
      "  validation loss:               0.019617378737686004\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 440 of 1000 took 1.01872205734s\n",
      "  LR:                            5.26164150553e-05\n",
      "  training loss:                 0.0008671153643196927\n",
      "  validation loss:               0.020150279702323002\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 441 of 1000 took 1.02482700348s\n",
      "  LR:                            5.21340248625e-05\n",
      "  training loss:                 0.001164515536264186\n",
      "  validation loss:               0.020321878666956245\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 442 of 1000 took 1.03111886978s\n",
      "  LR:                            5.16560572496e-05\n",
      "  training loss:                 0.0010126238003008727\n",
      "  validation loss:               0.02015153881594805\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 443 of 1000 took 1.03101086617s\n",
      "  LR:                            5.11824716701e-05\n",
      "  training loss:                 0.0011889896602945234\n",
      "  validation loss:               0.01794031553406025\n",
      "  validation error rate:         1.3214285418923413%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 444 of 1000 took 1.02503705025s\n",
      "  LR:                            5.07132279493e-05\n",
      "  training loss:                 0.0014656035560835455\n",
      "  validation loss:               0.01860324660914817\n",
      "  validation error rate:         1.357142853417567%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 445 of 1000 took 1.02747011185s\n",
      "  LR:                            5.02482862808e-05\n",
      "  training loss:                 0.000845779220500083\n",
      "  validation loss:               0.019257433342448036\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 446 of 1000 took 1.02007603645s\n",
      "  LR:                            4.97876072231e-05\n",
      "  training loss:                 0.0014944911753284587\n",
      "  validation loss:               0.019008636801014438\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 447 of 1000 took 1.02915906906s\n",
      "  LR:                            4.93311516964e-05\n",
      "  training loss:                 0.0008628186157864929\n",
      "  validation loss:               0.01967593596857244\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 448 of 1000 took 1.03939390182s\n",
      "  LR:                            4.88788809792e-05\n",
      "  training loss:                 0.0017510302427277058\n",
      "  validation loss:               0.019096924396373133\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 449 of 1000 took 1.03405404091s\n",
      "  LR:                            4.84307567048e-05\n",
      "  training loss:                 0.0012715114308809248\n",
      "  validation loss:               0.019598453871107528\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 450 of 1000 took 1.0331799984s\n",
      "  LR:                            4.79867408584e-05\n",
      "  training loss:                 0.0009216866813151578\n",
      "  validation loss:               0.01979423559220907\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 451 of 1000 took 1.0327000618s\n",
      "  LR:                            4.75467957738e-05\n",
      "  training loss:                 0.0012927323432844627\n",
      "  validation loss:               0.019470422398756324\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 452 of 1000 took 1.03177309036s\n",
      "  LR:                            4.711088413e-05\n",
      "  training loss:                 0.0014745923453547913\n",
      "  validation loss:               0.019825784254887173\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 453 of 1000 took 1.03537011147s\n",
      "  LR:                            4.66789689482e-05\n",
      "  training loss:                 0.0010947195240586392\n",
      "  validation loss:               0.01970028376841323\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 454 of 1000 took 1.02596688271s\n",
      "  LR:                            4.62510135885e-05\n",
      "  training loss:                 0.0014316617155313047\n",
      "  validation loss:               0.0189775793332631\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 455 of 1000 took 1.05240178108s\n",
      "  LR:                            4.58269817471e-05\n",
      "  training loss:                 0.0009832921809782935\n",
      "  validation loss:               0.020800396513160586\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 456 of 1000 took 1.03255391121s\n",
      "  LR:                            4.54068374531e-05\n",
      "  training loss:                 0.0010246125216949807\n",
      "  validation loss:               0.019685711108780066\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 457 of 1000 took 1.0220580101s\n",
      "  LR:                            4.49905450651e-05\n",
      "  training loss:                 0.0010252211187455243\n",
      "  validation loss:               0.018970612842573637\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 458 of 1000 took 1.02233409882s\n",
      "  LR:                            4.45780692686e-05\n",
      "  training loss:                 0.0009374368965402963\n",
      "  validation loss:               0.019134529573550805\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 459 of 1000 took 1.0213098526s\n",
      "  LR:                            4.4169375073e-05\n",
      "  training loss:                 0.0010165162478679524\n",
      "  validation loss:               0.017240357224429608\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 460 of 1000 took 1.02534008026s\n",
      "  LR:                            4.37644278083e-05\n",
      "  training loss:                 0.0008478979797338163\n",
      "  validation loss:               0.01971978078862386\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 461 of 1000 took 1.04508590698s\n",
      "  LR:                            4.33631931224e-05\n",
      "  training loss:                 0.0012544042176402402\n",
      "  validation loss:               0.01883820144514305\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 462 of 1000 took 1.03450608253s\n",
      "  LR:                            4.29656369782e-05\n",
      "  training loss:                 0.001130946369403987\n",
      "  validation loss:               0.019423241376200804\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 463 of 1000 took 1.04743313789s\n",
      "  LR:                            4.25717256507e-05\n",
      "  training loss:                 0.0006813767379048171\n",
      "  validation loss:               0.017630154850832826\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 464 of 1000 took 1.05973911285s\n",
      "  LR:                            4.21814257239e-05\n",
      "  training loss:                 0.0007538781742464284\n",
      "  validation loss:               0.019264978922105262\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 465 of 1000 took 1.07212710381s\n",
      "  LR:                            4.17947040884e-05\n",
      "  training loss:                 0.001192982083537644\n",
      "  validation loss:               0.016468426136465757\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 466 of 1000 took 1.04955506325s\n",
      "  LR:                            4.14115279381e-05\n",
      "  training loss:                 0.0010878226083430404\n",
      "  validation loss:               0.01718953835058658\n",
      "  validation error rate:         1.2142856937966175%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 467 of 1000 took 1.05110692978s\n",
      "  LR:                            4.10318647679e-05\n",
      "  training loss:                 0.0008576296009814942\n",
      "  validation loss:               0.019285090538297873\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 468 of 1000 took 1.03750419617s\n",
      "  LR:                            4.06556823705e-05\n",
      "  training loss:                 0.0014343634193796047\n",
      "  validation loss:               0.01932896889879235\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 469 of 1000 took 1.0205450058s\n",
      "  LR:                            4.02829488341e-05\n",
      "  training loss:                 0.0009163956831077827\n",
      "  validation loss:               0.01684432079621599\n",
      "  validation error rate:         1.2499999787126268%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 470 of 1000 took 1.03223180771s\n",
      "  LR:                            3.99136325393e-05\n",
      "  training loss:                 0.0011588675610621798\n",
      "  validation loss:               0.017766153272751644\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 471 of 1000 took 1.03597593307s\n",
      "  LR:                            3.95477021567e-05\n",
      "  training loss:                 0.0010588874358200642\n",
      "  validation loss:               0.017889682059600176\n",
      "  validation error rate:         1.357142853417567%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 472 of 1000 took 1.0261900425s\n",
      "  LR:                            3.9185126644e-05\n",
      "  training loss:                 0.001605543417700893\n",
      "  validation loss:               0.019110395970398843\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 473 of 1000 took 1.03043222427s\n",
      "  LR:                            3.88258752435e-05\n",
      "  training loss:                 0.0009731952503273078\n",
      "  validation loss:               0.018509899286008085\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 474 of 1000 took 1.0253059864s\n",
      "  LR:                            3.84699174797e-05\n",
      "  training loss:                 0.000867072669237747\n",
      "  validation loss:               0.019700480442614726\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 475 of 1000 took 1.03575992584s\n",
      "  LR:                            3.81172231563e-05\n",
      "  training loss:                 0.0009739990007054618\n",
      "  validation loss:               0.018733806684817216\n",
      "  validation error rate:         1.285714263628636%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 476 of 1000 took 1.02443504333s\n",
      "  LR:                            3.77677623538e-05\n",
      "  training loss:                 0.0009396165111937899\n",
      "  validation loss:               0.019186580320820212\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 477 of 1000 took 1.03728580475s\n",
      "  LR:                            3.74215054273e-05\n",
      "  training loss:                 0.0008658055229656289\n",
      "  validation loss:               0.019974923054438216\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 478 of 1000 took 1.02739191055s\n",
      "  LR:                            3.70784230033e-05\n",
      "  training loss:                 0.0008729083259689051\n",
      "  validation loss:               0.02114261823797798\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 479 of 1000 took 1.02480792999s\n",
      "  LR:                            3.6738485978e-05\n",
      "  training loss:                 0.0015194458252957876\n",
      "  validation loss:               0.01932596172472196\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 480 of 1000 took 1.02215504646s\n",
      "  LR:                            3.64016655139e-05\n",
      "  training loss:                 0.0011408631325761074\n",
      "  validation loss:               0.020334206409253448\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 481 of 1000 took 1.0219810009s\n",
      "  LR:                            3.60679330385e-05\n",
      "  training loss:                 0.0010450950352913638\n",
      "  validation loss:               0.018941604907273098\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 482 of 1000 took 1.03230500221s\n",
      "  LR:                            3.57372602408e-05\n",
      "  training loss:                 0.00044031187700401166\n",
      "  validation loss:               0.01894313282848868\n",
      "  validation error rate:         1.357142853417567%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 483 of 1000 took 1.02163696289s\n",
      "  LR:                            3.54096190696e-05\n",
      "  training loss:                 0.0007257302914339798\n",
      "  validation loss:               0.018047987556201406\n",
      "  validation error rate:         1.28571427028094%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 484 of 1000 took 1.02547883987s\n",
      "  LR:                            3.50849817306e-05\n",
      "  training loss:                 0.0006725896379638176\n",
      "  validation loss:               0.01844786079579665\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 485 of 1000 took 1.00943017006s\n",
      "  LR:                            3.47633206847e-05\n",
      "  training loss:                 0.0007063519087043139\n",
      "  validation loss:               0.018145805091730187\n",
      "  validation error rate:         1.285714263628636%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 486 of 1000 took 1.01036000252s\n",
      "  LR:                            3.44446086449e-05\n",
      "  training loss:                 0.0012167883355766495\n",
      "  validation loss:               0.019551578787643718\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 487 of 1000 took 1.01246714592s\n",
      "  LR:                            3.41288185747e-05\n",
      "  training loss:                 0.0011702307273728087\n",
      "  validation loss:               0.020476248126834257\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 488 of 1000 took 1.02370810509s\n",
      "  LR:                            3.38159236853e-05\n",
      "  training loss:                 0.0010849768113878192\n",
      "  validation loss:               0.019028404095609273\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 489 of 1000 took 1.02524495125s\n",
      "  LR:                            3.35058974334e-05\n",
      "  training loss:                 0.0009308178541146732\n",
      "  validation loss:               0.01886389392322079\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 490 of 1000 took 1.03505301476s\n",
      "  LR:                            3.31987135193e-05\n",
      "  training loss:                 0.0011432084798813906\n",
      "  validation loss:               0.01978874652533185\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 491 of 1000 took 1.02778697014s\n",
      "  LR:                            3.28943458843e-05\n",
      "  training loss:                 0.0008432385668619911\n",
      "  validation loss:               0.02126282299702455\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 492 of 1000 took 1.02495312691s\n",
      "  LR:                            3.25927687085e-05\n",
      "  training loss:                 0.0008431878286221226\n",
      "  validation loss:               0.020127858544583432\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 493 of 1000 took 1.0197019577s\n",
      "  LR:                            3.22939564089e-05\n",
      "  training loss:                 0.0003911651195330572\n",
      "  validation loss:               0.01963082673527034\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 494 of 1000 took 1.0213060379s\n",
      "  LR:                            3.19978836369e-05\n",
      "  training loss:                 0.0006902097299149212\n",
      "  validation loss:               0.02025612033269551\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 495 of 1000 took 1.02014994621s\n",
      "  LR:                            3.17045252764e-05\n",
      "  training loss:                 0.0011661486614825962\n",
      "  validation loss:               0.020651739425761356\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 496 of 1000 took 1.01487207413s\n",
      "  LR:                            3.14138564415e-05\n",
      "  training loss:                 0.0009731674472987225\n",
      "  validation loss:               0.020061893158916582\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 497 of 1000 took 1.01763105392s\n",
      "  LR:                            3.11258524745e-05\n",
      "  training loss:                 0.000950191661989747\n",
      "  validation loss:               0.01941109267873539\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 498 of 1000 took 1.02318882942s\n",
      "  LR:                            3.08404889438e-05\n",
      "  training loss:                 0.00103227084795517\n",
      "  validation loss:               0.019479457980846097\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 499 of 1000 took 1.02884793282s\n",
      "  LR:                            3.05577416416e-05\n",
      "  training loss:                 0.0007691713142007222\n",
      "  validation loss:               0.01842371215365444\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 500 of 1000 took 1.02676105499s\n",
      "  LR:                            3.02775865823e-05\n",
      "  training loss:                 0.0008334920305086973\n",
      "  validation loss:               0.018424671714975766\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 501 of 1000 took 1.03311395645s\n",
      "  LR:                            3e-05\n",
      "  training loss:                 0.0009208086543202147\n",
      "  validation loss:               0.01852186202064234\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 502 of 1000 took 1.03067803383s\n",
      "  LR:                            2.97249583468e-05\n",
      "  training loss:                 0.0007014707562149169\n",
      "  validation loss:               0.02072595732501473\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 503 of 1000 took 1.01996994019s\n",
      "  LR:                            2.94524382906e-05\n",
      "  training loss:                 0.0011248671455935221\n",
      "  validation loss:               0.018673363596462877\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 504 of 1000 took 1.02489089966s\n",
      "  LR:                            2.91824167133e-05\n",
      "  training loss:                 0.0008803692357751913\n",
      "  validation loss:               0.02036396842731847\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 505 of 1000 took 1.02467298508s\n",
      "  LR:                            2.89148707087e-05\n",
      "  training loss:                 0.0005058319367836863\n",
      "  validation loss:               0.01910015643757796\n",
      "  validation error rate:         1.3214285551969494%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 506 of 1000 took 1.0331261158s\n",
      "  LR:                            2.86497775806e-05\n",
      "  training loss:                 0.0009404529812571508\n",
      "  validation loss:               0.020019735152735457\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 507 of 1000 took 1.03097915649s\n",
      "  LR:                            2.8387114841e-05\n",
      "  training loss:                 0.0008381034352402307\n",
      "  validation loss:               0.019405032803271233\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 508 of 1000 took 1.04183888435s\n",
      "  LR:                            2.81268602078e-05\n",
      "  training loss:                 0.0006941018686655512\n",
      "  validation loss:               0.019667742146079296\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 509 of 1000 took 1.02609586716s\n",
      "  LR:                            2.78689916034e-05\n",
      "  training loss:                 0.0009106907125398907\n",
      "  validation loss:               0.019111786247813307\n",
      "  validation error rate:         1.4285714299018895%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 510 of 1000 took 1.02125811577s\n",
      "  LR:                            2.76134871526e-05\n",
      "  training loss:                 0.000637697920362424\n",
      "  validation loss:               0.019150620834677414\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 511 of 1000 took 1.04112195969s\n",
      "  LR:                            2.73603251807e-05\n",
      "  training loss:                 0.0010331164679083361\n",
      "  validation loss:               0.02074362068924529\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 512 of 1000 took 1.02389192581s\n",
      "  LR:                            2.71094842117e-05\n",
      "  training loss:                 0.0010629191472322846\n",
      "  validation loss:               0.020371675572407964\n",
      "  validation error rate:         1.4999999930816037%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 513 of 1000 took 1.03707885742s\n",
      "  LR:                            2.68609429665e-05\n",
      "  training loss:                 0.0010479404771055493\n",
      "  validation loss:               0.02148141717251357\n",
      "  validation error rate:         1.4999999930816037%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 514 of 1000 took 1.02473902702s\n",
      "  LR:                            2.66146803611e-05\n",
      "  training loss:                 0.001157821896597412\n",
      "  validation loss:               0.021153939455246525\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 515 of 1000 took 1.01947689056s\n",
      "  LR:                            2.63706755049e-05\n",
      "  training loss:                 0.0013129656652119122\n",
      "  validation loss:               0.019502643163182905\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 516 of 1000 took 1.02263593674s\n",
      "  LR:                            2.61289076987e-05\n",
      "  training loss:                 0.0010822785830359378\n",
      "  validation loss:               0.017952317111329257\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 517 of 1000 took 1.02740216255s\n",
      "  LR:                            2.5889356433e-05\n",
      "  training loss:                 0.0007903102869538175\n",
      "  validation loss:               0.021105829659583315\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 518 of 1000 took 1.02107000351s\n",
      "  LR:                            2.56520013865e-05\n",
      "  training loss:                 0.0010999008787741392\n",
      "  validation loss:               0.02002534184872015\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 519 of 1000 took 1.03278899193s\n",
      "  LR:                            2.54168224242e-05\n",
      "  training loss:                 0.0008134359994926399\n",
      "  validation loss:               0.019133186699556454\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 520 of 1000 took 1.02892494202s\n",
      "  LR:                            2.51837995956e-05\n",
      "  training loss:                 0.0006865203261113226\n",
      "  validation loss:               0.018985397348712598\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 521 of 1000 took 1.01930809021s\n",
      "  LR:                            2.49529131331e-05\n",
      "  training loss:                 0.000700659309072699\n",
      "  validation loss:               0.018642454228646393\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 522 of 1000 took 1.03210806847s\n",
      "  LR:                            2.47241434504e-05\n",
      "  training loss:                 0.0009928413438738163\n",
      "  validation loss:               0.018477057796969478\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 523 of 1000 took 1.03857088089s\n",
      "  LR:                            2.44974711408e-05\n",
      "  training loss:                 0.0005457886127032907\n",
      "  validation loss:               0.02022287548814867\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 524 of 1000 took 1.03279399872s\n",
      "  LR:                            2.42728769754e-05\n",
      "  training loss:                 0.0007163488355950128\n",
      "  validation loss:               0.020078067237461385\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 525 of 1000 took 1.03293800354s\n",
      "  LR:                            2.40503419016e-05\n",
      "  training loss:                 0.0010349234296821873\n",
      "  validation loss:               0.01961415397402431\n",
      "  validation error rate:         1.464285688208682%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 526 of 1000 took 1.02901315689s\n",
      "  LR:                            2.38298470417e-05\n",
      "  training loss:                 0.0006379483640897296\n",
      "  validation loss:               0.0196956033133964\n",
      "  validation error rate:         1.3928571250289679%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 527 of 1000 took 1.03286194801s\n",
      "  LR:                            2.36113736909e-05\n",
      "  training loss:                 0.0006960814185295222\n",
      "  validation loss:               0.020466484224016313\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 528 of 1000 took 1.02710795403s\n",
      "  LR:                            2.33949033157e-05\n",
      "  training loss:                 0.0009028205494870763\n",
      "  validation loss:               0.020547098027756356\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 529 of 1000 took 1.02988290787s\n",
      "  LR:                            2.31804175529e-05\n",
      "  training loss:                 0.0012050905970420278\n",
      "  validation loss:               0.018737998479683222\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 530 of 1000 took 1.03109908104s\n",
      "  LR:                            2.29678982073e-05\n",
      "  training loss:                 0.0008748216052539954\n",
      "  validation loss:               0.01955066647480765\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 531 of 1000 took 1.03234410286s\n",
      "  LR:                            2.27573272509e-05\n",
      "  training loss:                 0.0010392361326294096\n",
      "  validation loss:               0.01829376165031655\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 532 of 1000 took 1.06005597115s\n",
      "  LR:                            2.25486868205e-05\n",
      "  training loss:                 0.000850031519663349\n",
      "  validation loss:               0.018243356193774422\n",
      "  validation error rate:         1.3214285418923413%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 533 of 1000 took 1.04767608643s\n",
      "  LR:                            2.23419592172e-05\n",
      "  training loss:                 0.0007032220635179949\n",
      "  validation loss:               0.019311088946519055\n",
      "  validation error rate:         1.4285714299018895%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 534 of 1000 took 1.04342889786s\n",
      "  LR:                            2.21371269039e-05\n",
      "  training loss:                 0.000971799476811404\n",
      "  validation loss:               0.02025678371345358\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 535 of 1000 took 1.02592802048s\n",
      "  LR:                            2.19341725045e-05\n",
      "  training loss:                 0.0009504331781288295\n",
      "  validation loss:               0.01908788755346385\n",
      "  validation error rate:         1.357142860069871%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 536 of 1000 took 1.03098082542s\n",
      "  LR:                            2.17330788023e-05\n",
      "  training loss:                 0.00046896707250385376\n",
      "  validation loss:               0.018689990616037124\n",
      "  validation error rate:         1.3928571250289679%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 537 of 1000 took 1.04286193848s\n",
      "  LR:                            2.15338287381e-05\n",
      "  training loss:                 0.0011830144016450107\n",
      "  validation loss:               0.019337422088158616\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 538 of 1000 took 1.00869393349s\n",
      "  LR:                            2.13364054096e-05\n",
      "  training loss:                 0.0009571743927621997\n",
      "  validation loss:               0.01955947555948764\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 539 of 1000 took 1.00961279869s\n",
      "  LR:                            2.1140792069e-05\n",
      "  training loss:                 0.000916325885250512\n",
      "  validation loss:               0.0197334092746522\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 540 of 1000 took 1.02795910835s\n",
      "  LR:                            2.09469721223e-05\n",
      "  training loss:                 0.0010919282073698405\n",
      "  validation loss:               0.02058448883872188\n",
      "  validation error rate:         1.4999999930816037%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 541 of 1000 took 1.02422904968s\n",
      "  LR:                            2.07549291276e-05\n",
      "  training loss:                 0.0009174030009940679\n",
      "  validation loss:               0.020289966769269085\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 542 of 1000 took 1.0111579895s\n",
      "  LR:                            2.05646467936e-05\n",
      "  training loss:                 0.0008799318330640529\n",
      "  validation loss:               0.019246062399066233\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 543 of 1000 took 1.01598095894s\n",
      "  LR:                            2.03761089785e-05\n",
      "  training loss:                 0.0008383614044479306\n",
      "  validation loss:               0.019838819375893633\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 544 of 1000 took 1.01778411865s\n",
      "  LR:                            2.01892996885e-05\n",
      "  training loss:                 0.0006222012430491892\n",
      "  validation loss:               0.02082785133057184\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 545 of 1000 took 1.02117013931s\n",
      "  LR:                            2.00042030764e-05\n",
      "  training loss:                 0.0005580483935097939\n",
      "  validation loss:               0.019662363230184252\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 546 of 1000 took 1.02088809013s\n",
      "  LR:                            1.98208034402e-05\n",
      "  training loss:                 0.00080454034149594\n",
      "  validation loss:               0.020223814752950733\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 547 of 1000 took 1.01637101173s\n",
      "  LR:                            1.9639085222e-05\n",
      "  training loss:                 0.0008851192376501948\n",
      "  validation loss:               0.02068972698283947\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 548 of 1000 took 1.01424098015s\n",
      "  LR:                            1.94590330064e-05\n",
      "  training loss:                 0.0005912686278010677\n",
      "  validation loss:               0.021871082482643293\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 549 of 1000 took 1.00818896294s\n",
      "  LR:                            1.92806315195e-05\n",
      "  training loss:                 0.0010079539853704237\n",
      "  validation loss:               0.020681888582268066\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 550 of 1000 took 1.01667094231s\n",
      "  LR:                            1.91038656272e-05\n",
      "  training loss:                 0.001221085195009314\n",
      "  validation loss:               0.02096301893886578\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 551 of 1000 took 1.01604890823s\n",
      "  LR:                            1.89287203344e-05\n",
      "  training loss:                 0.0006407411967778805\n",
      "  validation loss:               0.019595768793286488\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 552 of 1000 took 1.02421689034s\n",
      "  LR:                            1.87551807833e-05\n",
      "  training loss:                 0.0007866171411900027\n",
      "  validation loss:               0.019847085408400744\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 553 of 1000 took 1.01266503334s\n",
      "  LR:                            1.85832322523e-05\n",
      "  training loss:                 0.0008179464926598712\n",
      "  validation loss:               0.020285928808984215\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 554 of 1000 took 1.01971387863s\n",
      "  LR:                            1.84128601549e-05\n",
      "  training loss:                 0.0015691787457869817\n",
      "  validation loss:               0.02049256968478273\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 555 of 1000 took 1.02463006973s\n",
      "  LR:                            1.82440500384e-05\n",
      "  training loss:                 0.0007159089622348448\n",
      "  validation loss:               0.020211617397113253\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 556 of 1000 took 1.01414012909s\n",
      "  LR:                            1.80767875822e-05\n",
      "  training loss:                 0.0005724436074046934\n",
      "  validation loss:               0.018857750097855126\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 557 of 1000 took 1.02706813812s\n",
      "  LR:                            1.79110585975e-05\n",
      "  training loss:                 0.0007439052105680044\n",
      "  validation loss:               0.019112157608365772\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 558 of 1000 took 1.03462696075s\n",
      "  LR:                            1.77468490253e-05\n",
      "  training loss:                 0.000518950821672599\n",
      "  validation loss:               0.019452131299268722\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 559 of 1000 took 1.02980303764s\n",
      "  LR:                            1.75841449354e-05\n",
      "  training loss:                 0.0006915793751105906\n",
      "  validation loss:               0.019410023001910304\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 560 of 1000 took 1.02775287628s\n",
      "  LR:                            1.74229325256e-05\n",
      "  training loss:                 0.0006839531766472111\n",
      "  validation loss:               0.01887948121784839\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 561 of 1000 took 1.03004288673s\n",
      "  LR:                            1.72631981201e-05\n",
      "  training loss:                 0.0006090893981991448\n",
      "  validation loss:               0.018342080476096662\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 562 of 1000 took 1.02197694778s\n",
      "  LR:                            1.71049281684e-05\n",
      "  training loss:                 0.0007392112825949812\n",
      "  validation loss:               0.01841013983096218\n",
      "  validation error rate:         1.3214285551969494%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 563 of 1000 took 1.0196518898s\n",
      "  LR:                            1.69481092444e-05\n",
      "  training loss:                 0.0005860429092786286\n",
      "  validation loss:               0.018744205756645118\n",
      "  validation error rate:         1.3214285551969494%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 564 of 1000 took 1.02035403252s\n",
      "  LR:                            1.67927280449e-05\n",
      "  training loss:                 0.0008199330783477709\n",
      "  validation loss:               0.018846373676621755\n",
      "  validation error rate:         1.3214285418923413%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 565 of 1000 took 1.03590917587s\n",
      "  LR:                            1.66387713887e-05\n",
      "  training loss:                 0.0008196985908228652\n",
      "  validation loss:               0.019600003337213172\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 566 of 1000 took 1.0263569355s\n",
      "  LR:                            1.64862262157e-05\n",
      "  training loss:                 0.0008974764392322718\n",
      "  validation loss:               0.0222579093299698\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 567 of 1000 took 1.04306101799s\n",
      "  LR:                            1.63350795853e-05\n",
      "  training loss:                 0.000642627327333181\n",
      "  validation loss:               0.019130430683227524\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 568 of 1000 took 1.01878190041s\n",
      "  LR:                            1.61853186755e-05\n",
      "  training loss:                 0.0008543053932224693\n",
      "  validation loss:               0.019205207996752245\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 569 of 1000 took 1.01520419121s\n",
      "  LR:                            1.60369307819e-05\n",
      "  training loss:                 0.0009350461207980195\n",
      "  validation loss:               0.019336554325296414\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 570 of 1000 took 1.02623987198s\n",
      "  LR:                            1.58899033167e-05\n",
      "  training loss:                 0.0008636745731353932\n",
      "  validation loss:               0.020934112107040295\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 571 of 1000 took 1.02428102493s\n",
      "  LR:                            1.57442238075e-05\n",
      "  training loss:                 0.0010387266554082143\n",
      "  validation loss:               0.020163449771644082\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 572 of 1000 took 1.03954291344s\n",
      "  LR:                            1.5599879896e-05\n",
      "  training loss:                 0.0007183637432082352\n",
      "  validation loss:               0.019819635143254084\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 573 of 1000 took 1.04814195633s\n",
      "  LR:                            1.54568593375e-05\n",
      "  training loss:                 0.0007821366141812673\n",
      "  validation loss:               0.019504172265962034\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 574 of 1000 took 1.05043697357s\n",
      "  LR:                            1.53151499993e-05\n",
      "  training loss:                 0.0007056178018889542\n",
      "  validation loss:               0.0196899804619274\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 575 of 1000 took 1.02669596672s\n",
      "  LR:                            1.51747398601e-05\n",
      "  training loss:                 0.0005399889861698338\n",
      "  validation loss:               0.02071184601767787\n",
      "  validation error rate:         1.5714285429567099%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 576 of 1000 took 1.02472805977s\n",
      "  LR:                            1.50356170088e-05\n",
      "  training loss:                 0.0008325726947475687\n",
      "  validation loss:               0.019699522086739307\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 577 of 1000 took 1.02360510826s\n",
      "  LR:                            1.48977696435e-05\n",
      "  training loss:                 0.0010318742496538433\n",
      "  validation loss:               0.01999332698427939\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 578 of 1000 took 1.02271008492s\n",
      "  LR:                            1.47611860704e-05\n",
      "  training loss:                 0.0009065226384456556\n",
      "  validation loss:               0.019834217748471668\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 579 of 1000 took 1.028840065s\n",
      "  LR:                            1.46258547031e-05\n",
      "  training loss:                 0.0005274461634402131\n",
      "  validation loss:               0.01974685804452747\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 580 of 1000 took 1.03374004364s\n",
      "  LR:                            1.44917640612e-05\n",
      "  training loss:                 0.0010575708352886062\n",
      "  validation loss:               0.01862366711715627\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 581 of 1000 took 1.02682900429s\n",
      "  LR:                            1.43589027697e-05\n",
      "  training loss:                 0.0009459576297751352\n",
      "  validation loss:               0.02089386431699885\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 582 of 1000 took 1.03013396263s\n",
      "  LR:                            1.42272595578e-05\n",
      "  training loss:                 0.0007396761941907592\n",
      "  validation loss:               0.019973811028259143\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 583 of 1000 took 1.02480316162s\n",
      "  LR:                            1.40968232582e-05\n",
      "  training loss:                 0.0007516456707294845\n",
      "  validation loss:               0.01986032244687002\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 584 of 1000 took 1.03393888474s\n",
      "  LR:                            1.39675828057e-05\n",
      "  training loss:                 0.0007789417924973668\n",
      "  validation loss:               0.020267308847646097\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 585 of 1000 took 1.03015613556s\n",
      "  LR:                            1.38395272368e-05\n",
      "  training loss:                 0.0008168723572533372\n",
      "  validation loss:               0.02015186578501016\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 586 of 1000 took 1.04729413986s\n",
      "  LR:                            1.37126456884e-05\n",
      "  training loss:                 0.0005466651010913344\n",
      "  validation loss:               0.02072956898596853\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 587 of 1000 took 1.02201986313s\n",
      "  LR:                            1.35869273971e-05\n",
      "  training loss:                 0.0006384166953018296\n",
      "  validation loss:               0.01907954554605697\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 588 of 1000 took 1.01960086823s\n",
      "  LR:                            1.3462361698e-05\n",
      "  training loss:                 0.0009839357674235965\n",
      "  validation loss:               0.019260727966216758\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 589 of 1000 took 1.01686906815s\n",
      "  LR:                            1.33389380241e-05\n",
      "  training loss:                 0.0009674423322879273\n",
      "  validation loss:               0.019406595483555326\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 590 of 1000 took 1.02364397049s\n",
      "  LR:                            1.32166459052e-05\n",
      "  training loss:                 0.0008599625575709215\n",
      "  validation loss:               0.019368168182804117\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 591 of 1000 took 1.03500080109s\n",
      "  LR:                            1.30954749672e-05\n",
      "  training loss:                 0.0006386055547537331\n",
      "  validation loss:               0.02031554815558983\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 592 of 1000 took 1.02248811722s\n",
      "  LR:                            1.29754149311e-05\n",
      "  training loss:                 0.001016400539268137\n",
      "  validation loss:               0.01931875179692964\n",
      "  validation error rate:         1.28571427028094%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 593 of 1000 took 1.02972984314s\n",
      "  LR:                            1.28564556119e-05\n",
      "  training loss:                 0.0007695880631839667\n",
      "  validation loss:               0.01864800452624747\n",
      "  validation error rate:         1.357142860069871%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 594 of 1000 took 1.01028299332s\n",
      "  LR:                            1.27385869184e-05\n",
      "  training loss:                 0.0006484471599087167\n",
      "  validation loss:               0.019794001377054622\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 595 of 1000 took 1.01497912407s\n",
      "  LR:                            1.26217988515e-05\n",
      "  training loss:                 0.0005837968378183772\n",
      "  validation loss:               0.01910554459651134\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 596 of 1000 took 1.00450706482s\n",
      "  LR:                            1.25060815041e-05\n",
      "  training loss:                 0.0004814779814997691\n",
      "  validation loss:               0.01962344069033861\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 597 of 1000 took 1.01928591728s\n",
      "  LR:                            1.23914250597e-05\n",
      "  training loss:                 0.0011468559368578927\n",
      "  validation loss:               0.019361805378658965\n",
      "  validation error rate:         1.28571427028094%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 598 of 1000 took 1.01452589035s\n",
      "  LR:                            1.22778197919e-05\n",
      "  training loss:                 0.00064836239484056\n",
      "  validation loss:               0.019591331082795347\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 599 of 1000 took 1.01337504387s\n",
      "  LR:                            1.21652560635e-05\n",
      "  training loss:                 0.0011150123852524494\n",
      "  validation loss:               0.02022012005493577\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 600 of 1000 took 1.01817679405s\n",
      "  LR:                            1.20537243255e-05\n",
      "  training loss:                 0.0009365968940628858\n",
      "  validation loss:               0.019901141831983944\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 601 of 1000 took 1.03456783295s\n",
      "  LR:                            1.19432151166e-05\n",
      "  training loss:                 0.0006835660721018358\n",
      "  validation loss:               0.019435864706922854\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 602 of 1000 took 1.02272081375s\n",
      "  LR:                            1.18337190623e-05\n",
      "  training loss:                 0.0005212093076133579\n",
      "  validation loss:               0.019948325020128062\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 603 of 1000 took 1.03500890732s\n",
      "  LR:                            1.17252268738e-05\n",
      "  training loss:                 0.0008126307236205535\n",
      "  validation loss:               0.018852681380036325\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 604 of 1000 took 1.02752804756s\n",
      "  LR:                            1.16177293476e-05\n",
      "  training loss:                 0.0006873364708740958\n",
      "  validation loss:               0.018734833541592315\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 605 of 1000 took 1.02672100067s\n",
      "  LR:                            1.15112173648e-05\n",
      "  training loss:                 0.0006442844552579759\n",
      "  validation loss:               0.020511528052208763\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 606 of 1000 took 1.04308700562s\n",
      "  LR:                            1.14056818896e-05\n",
      "  training loss:                 0.0007305628187273009\n",
      "  validation loss:               0.01994982049135225\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 607 of 1000 took 1.02526211739s\n",
      "  LR:                            1.13011139695e-05\n",
      "  training loss:                 0.0009201752541478008\n",
      "  validation loss:               0.019062532361463776\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 608 of 1000 took 1.01374697685s\n",
      "  LR:                            1.11975047339e-05\n",
      "  training loss:                 0.000615474098249619\n",
      "  validation loss:               0.01869890616425047\n",
      "  validation error rate:         1.3214285551969494%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 609 of 1000 took 1.010242939s\n",
      "  LR:                            1.10948453934e-05\n",
      "  training loss:                 0.0008761993237158094\n",
      "  validation loss:               0.020419900495783492\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 610 of 1000 took 1.0168390274s\n",
      "  LR:                            1.09931272394e-05\n",
      "  training loss:                 0.0010976311346839191\n",
      "  validation loss:               0.019390369220803092\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 611 of 1000 took 1.01388096809s\n",
      "  LR:                            1.08923416431e-05\n",
      "  training loss:                 0.001006451384495556\n",
      "  validation loss:               0.01872809640397983\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 612 of 1000 took 1.00887989998s\n",
      "  LR:                            1.07924800547e-05\n",
      "  training loss:                 0.001102849736074268\n",
      "  validation loss:               0.019697814481332898\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 613 of 1000 took 1.02278804779s\n",
      "  LR:                            1.06935340028e-05\n",
      "  training loss:                 0.0008031999809585453\n",
      "  validation loss:               0.019708244828507304\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 614 of 1000 took 1.02012395859s\n",
      "  LR:                            1.05954950938e-05\n",
      "  training loss:                 0.0006907395193309184\n",
      "  validation loss:               0.018725482412264682\n",
      "  validation error rate:         1.3214285751538617%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 615 of 1000 took 1.01922297478s\n",
      "  LR:                            1.04983550109e-05\n",
      "  training loss:                 0.000572453368554574\n",
      "  validation loss:               0.018244058299805892\n",
      "  validation error rate:         1.3928571250289679%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 616 of 1000 took 1.02372908592s\n",
      "  LR:                            1.04021055136e-05\n",
      "  training loss:                 0.0006330750342405789\n",
      "  validation loss:               0.020364419162173623\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 617 of 1000 took 1.0262131691s\n",
      "  LR:                            1.0306738437e-05\n",
      "  training loss:                 0.0007152364902120567\n",
      "  validation loss:               0.021357395927355225\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 618 of 1000 took 1.02342510223s\n",
      "  LR:                            1.0212245691e-05\n",
      "  training loss:                 0.0006177748611932543\n",
      "  validation loss:               0.02135143251091774\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 619 of 1000 took 1.03042221069s\n",
      "  LR:                            1.01186192598e-05\n",
      "  training loss:                 0.00074256426148132\n",
      "  validation loss:               0.020817070417771383\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 620 of 1000 took 1.01784706116s\n",
      "  LR:                            1.00258512008e-05\n",
      "  training loss:                 0.0009149809122939533\n",
      "  validation loss:               0.020287882388743128\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 621 of 1000 took 1.01841282845s\n",
      "  LR:                            9.93393364448e-06\n",
      "  training loss:                 0.0009746448145153528\n",
      "  validation loss:               0.01980798029178134\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 622 of 1000 took 1.01721096039s\n",
      "  LR:                            9.84285879339e-06\n",
      "  training loss:                 0.0007043793627582151\n",
      "  validation loss:               0.020086634288808063\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 623 of 1000 took 1.00701498985s\n",
      "  LR:                            9.75261892156e-06\n",
      "  training loss:                 0.0011179711300542295\n",
      "  validation loss:               0.02001064662389191\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 624 of 1000 took 1.02243304253s\n",
      "  LR:                            9.66320637385e-06\n",
      "  training loss:                 0.0008584332695342566\n",
      "  validation loss:               0.02056001919638817\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 625 of 1000 took 1.02354502678s\n",
      "  LR:                            9.5746135653e-06\n",
      "  training loss:                 0.0007999133369008358\n",
      "  validation loss:               0.019173184374916934\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 626 of 1000 took 1.05232596397s\n",
      "  LR:                            9.48683298051e-06\n",
      "  training loss:                 0.0005913642858780827\n",
      "  validation loss:               0.0203480811407774\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 627 of 1000 took 1.02826094627s\n",
      "  LR:                            9.39985717295e-06\n",
      "  training loss:                 0.0008565735574777858\n",
      "  validation loss:               0.01892565284755879\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 628 of 1000 took 1.03383398056s\n",
      "  LR:                            9.31367876439e-06\n",
      "  training loss:                 0.0005527141496772254\n",
      "  validation loss:               0.020356068628773625\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 629 of 1000 took 1.0380461216s\n",
      "  LR:                            9.22829044422e-06\n",
      "  training loss:                 0.0006283136299361679\n",
      "  validation loss:               0.01999723228696634\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 630 of 1000 took 1.03898096085s\n",
      "  LR:                            9.14368496888e-06\n",
      "  training loss:                 0.0007354939366418943\n",
      "  validation loss:               0.02117035912150251\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 631 of 1000 took 1.05724287033s\n",
      "  LR:                            9.05985516121e-06\n",
      "  training loss:                 0.0005845154785617979\n",
      "  validation loss:               0.019264530370973688\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 632 of 1000 took 1.0376329422s\n",
      "  LR:                            8.97679390982e-06\n",
      "  training loss:                 0.0003825619144479601\n",
      "  validation loss:               0.021139307163788805\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 633 of 1000 took 1.03745102882s\n",
      "  LR:                            8.89449416857e-06\n",
      "  training loss:                 0.0008354325219630375\n",
      "  validation loss:               0.020370540738180613\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 634 of 1000 took 1.02856111526s\n",
      "  LR:                            8.81294895588e-06\n",
      "  training loss:                 0.0007757575350955827\n",
      "  validation loss:               0.020040754677860866\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 635 of 1000 took 1.02402997017s\n",
      "  LR:                            8.7321513542e-06\n",
      "  training loss:                 0.0006328506461125685\n",
      "  validation loss:               0.019688787421078553\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 636 of 1000 took 1.02072501183s\n",
      "  LR:                            8.65209450938e-06\n",
      "  training loss:                 0.0008298073190883649\n",
      "  validation loss:               0.020252250881250284\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 637 of 1000 took 1.03148603439s\n",
      "  LR:                            8.57277163012e-06\n",
      "  training loss:                 0.0011617983294679092\n",
      "  validation loss:               0.02039097697291124\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 638 of 1000 took 1.02943396568s\n",
      "  LR:                            8.4941759874e-06\n",
      "  training loss:                 0.0006922384079771327\n",
      "  validation loss:               0.0206047267170756\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 639 of 1000 took 1.02980089188s\n",
      "  LR:                            8.41630091386e-06\n",
      "  training loss:                 0.0008863530823366178\n",
      "  validation loss:               0.019370709763003497\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 640 of 1000 took 1.03279185295s\n",
      "  LR:                            8.33913980328e-06\n",
      "  training loss:                 0.0006595854385317441\n",
      "  validation loss:               0.020029327000624368\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 641 of 1000 took 1.03720116615s\n",
      "  LR:                            8.26268611001e-06\n",
      "  training loss:                 0.0009491274676206755\n",
      "  validation loss:               0.019951981583809748\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 642 of 1000 took 1.04685306549s\n",
      "  LR:                            8.18693334842e-06\n",
      "  training loss:                 0.0010046349978633784\n",
      "  validation loss:               0.0197957011239071\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 643 of 1000 took 1.02558994293s\n",
      "  LR:                            8.11187509233e-06\n",
      "  training loss:                 0.0005911887819479071\n",
      "  validation loss:               0.02025848548925881\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 644 of 1000 took 1.02639508247s\n",
      "  LR:                            8.03750497446e-06\n",
      "  training loss:                 0.0004553823580583081\n",
      "  validation loss:               0.018681294370046064\n",
      "  validation error rate:         1.3214285485446453%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 645 of 1000 took 1.02451896667s\n",
      "  LR:                            7.96381668593e-06\n",
      "  training loss:                 0.0011074735656227872\n",
      "  validation loss:               0.019218795467168093\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 646 of 1000 took 1.01767110825s\n",
      "  LR:                            7.89080397569e-06\n",
      "  training loss:                 0.0008909003445871095\n",
      "  validation loss:               0.0196287544174863\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 647 of 1000 took 1.01543784142s\n",
      "  LR:                            7.81846065e-06\n",
      "  training loss:                 0.0007054761172298641\n",
      "  validation loss:               0.020090052907887315\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 648 of 1000 took 1.01164102554s\n",
      "  LR:                            7.7467805719e-06\n",
      "  training loss:                 0.0007425551643837448\n",
      "  validation loss:               0.021225169854428065\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 649 of 1000 took 1.01503109932s\n",
      "  LR:                            7.67575766072e-06\n",
      "  training loss:                 0.0006896035340934511\n",
      "  validation loss:               0.020587161765433848\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 650 of 1000 took 1.01098299026s\n",
      "  LR:                            7.60538589149e-06\n",
      "  training loss:                 0.0003992852740690095\n",
      "  validation loss:               0.02066195983785032\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 651 of 1000 took 1.03565216064s\n",
      "  LR:                            7.53565929453e-06\n",
      "  training loss:                 0.0008626324191433642\n",
      "  validation loss:               0.020270152200412537\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 652 of 1000 took 1.01791286469s\n",
      "  LR:                            7.46657195485e-06\n",
      "  training loss:                 0.0005480263534314222\n",
      "  validation loss:               0.019910549079733237\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 653 of 1000 took 1.02139496803s\n",
      "  LR:                            7.3981180117e-06\n",
      "  training loss:                 0.0006039531474284174\n",
      "  validation loss:               0.020150664545196508\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 654 of 1000 took 1.02329492569s\n",
      "  LR:                            7.33029165808e-06\n",
      "  training loss:                 0.0007544521254902413\n",
      "  validation loss:               0.020114290810722326\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 655 of 1000 took 1.02098202705s\n",
      "  LR:                            7.26308714021e-06\n",
      "  training loss:                 0.0005965742448486988\n",
      "  validation loss:               0.01962675310746168\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 656 of 1000 took 1.01431202888s\n",
      "  LR:                            7.19649875706e-06\n",
      "  training loss:                 0.0007190388476856543\n",
      "  validation loss:               0.018721542637129978\n",
      "  validation error rate:         1.3928571117243596%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 657 of 1000 took 1.01550006866s\n",
      "  LR:                            7.13052085987e-06\n",
      "  training loss:                 0.0009085933301942445\n",
      "  validation loss:               0.020078086909994193\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 658 of 1000 took 1.01208901405s\n",
      "  LR:                            7.06514785169e-06\n",
      "  training loss:                 0.0005402678374329806\n",
      "  validation loss:               0.020687734184321016\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 659 of 1000 took 1.00689005852s\n",
      "  LR:                            7.00037418684e-06\n",
      "  training loss:                 0.0008147907217470581\n",
      "  validation loss:               0.020251291273954815\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 660 of 1000 took 1.01164484024s\n",
      "  LR:                            6.93619437053e-06\n",
      "  training loss:                 0.000955912948761645\n",
      "  validation loss:               0.020621464191244394\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 661 of 1000 took 1.02450013161s\n",
      "  LR:                            6.8726029583e-06\n",
      "  training loss:                 0.0005550950564952399\n",
      "  validation loss:               0.021142686261945137\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 662 of 1000 took 1.01848387718s\n",
      "  LR:                            6.80959455565e-06\n",
      "  training loss:                 0.0005337907844247023\n",
      "  validation loss:               0.019027171467314474\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 663 of 1000 took 1.02323794365s\n",
      "  LR:                            6.74716381751e-06\n",
      "  training loss:                 0.0007710691041194112\n",
      "  validation loss:               0.021640822075174322\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 664 of 1000 took 1.03024697304s\n",
      "  LR:                            6.68530544781e-06\n",
      "  training loss:                 0.0008873861997788638\n",
      "  validation loss:               0.019708497274148078\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 665 of 1000 took 1.02815890312s\n",
      "  LR:                            6.62401419906e-06\n",
      "  training loss:                 0.0005764168912251556\n",
      "  validation loss:               0.019790177725570044\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 666 of 1000 took 1.02488183975s\n",
      "  LR:                            6.56328487185e-06\n",
      "  training loss:                 0.0008251254158869201\n",
      "  validation loss:               0.019222810930971588\n",
      "  validation error rate:         1.3928571117243596%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 667 of 1000 took 1.04382014275s\n",
      "  LR:                            6.50311231446e-06\n",
      "  training loss:                 0.0008969197983594099\n",
      "  validation loss:               0.01897682102901399\n",
      "  validation error rate:         1.3571428268083505%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 668 of 1000 took 1.02751088142s\n",
      "  LR:                            6.44349142239e-06\n",
      "  training loss:                 0.0006828834135597069\n",
      "  validation loss:               0.019311455568640667\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 669 of 1000 took 1.03031301498s\n",
      "  LR:                            6.38441713795e-06\n",
      "  training loss:                 0.000855765121453551\n",
      "  validation loss:               0.02084110499293144\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 670 of 1000 took 1.01159310341s\n",
      "  LR:                            6.3258844498e-06\n",
      "  training loss:                 0.0009097006383610766\n",
      "  validation loss:               0.019301851695802594\n",
      "  validation error rate:         1.3928571117243596%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 671 of 1000 took 1.01808214188s\n",
      "  LR:                            6.26788839256e-06\n",
      "  training loss:                 0.00044540891930911977\n",
      "  validation loss:               0.02077996464712279\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 672 of 1000 took 1.01387381554s\n",
      "  LR:                            6.21042404637e-06\n",
      "  training loss:                 0.00076212834352134\n",
      "  validation loss:               0.020156532011761947\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 673 of 1000 took 1.0158059597s\n",
      "  LR:                            6.15348653648e-06\n",
      "  training loss:                 0.0008019945202363175\n",
      "  validation loss:               0.020630298711385615\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 674 of 1000 took 1.01581597328s\n",
      "  LR:                            6.09707103281e-06\n",
      "  training loss:                 0.0007330688903719149\n",
      "  validation loss:               0.020180747475706085\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 675 of 1000 took 1.03056502342s\n",
      "  LR:                            6.04117274959e-06\n",
      "  training loss:                 0.000540293074279857\n",
      "  validation loss:               0.02206239978451257\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 676 of 1000 took 1.02386307716s\n",
      "  LR:                            5.98578694491e-06\n",
      "  training loss:                 0.0008064374970386472\n",
      "  validation loss:               0.01965738142774041\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 677 of 1000 took 1.02951002121s\n",
      "  LR:                            5.93090892034e-06\n",
      "  training loss:                 0.000730901317194403\n",
      "  validation loss:               0.019268349586387297\n",
      "  validation error rate:         1.3214285418923413%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 678 of 1000 took 1.02034902573s\n",
      "  LR:                            5.87653402052e-06\n",
      "  training loss:                 0.0009506193948891941\n",
      "  validation loss:               0.021232672251894007\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 679 of 1000 took 1.05207395554s\n",
      "  LR:                            5.82265763278e-06\n",
      "  training loss:                 0.0004036966599838909\n",
      "  validation loss:               0.01994606593091573\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 680 of 1000 took 1.03845977783s\n",
      "  LR:                            5.76927518673e-06\n",
      "  training loss:                 0.0006552922386504847\n",
      "  validation loss:               0.020772795548834568\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 681 of 1000 took 1.04136586189s\n",
      "  LR:                            5.71638215389e-06\n",
      "  training loss:                 0.0006559798657932828\n",
      "  validation loss:               0.020780864504298995\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 682 of 1000 took 1.05610609055s\n",
      "  LR:                            5.66397404729e-06\n",
      "  training loss:                 0.0007312160296500301\n",
      "  validation loss:               0.019969687298206345\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 683 of 1000 took 1.03111004829s\n",
      "  LR:                            5.6120464211e-06\n",
      "  training loss:                 0.0006218082521054439\n",
      "  validation loss:               0.017782811479264637\n",
      "  validation error rate:         1.285714263628636%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 684 of 1000 took 1.02347111702s\n",
      "  LR:                            5.56059487024e-06\n",
      "  training loss:                 0.001111059140687169\n",
      "  validation loss:               0.020528598537001334\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 685 of 1000 took 1.0240418911s\n",
      "  LR:                            5.50961503005e-06\n",
      "  training loss:                 0.0007452363477282104\n",
      "  validation loss:               0.019529838231392205\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 686 of 1000 took 1.02849197388s\n",
      "  LR:                            5.45910257583e-06\n",
      "  training loss:                 0.0004870928653158511\n",
      "  validation loss:               0.02058700612984207\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 687 of 1000 took 1.02233600616s\n",
      "  LR:                            5.40905322258e-06\n",
      "  training loss:                 0.0004753811834144371\n",
      "  validation loss:               0.01884971647167991\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 688 of 1000 took 1.0223069191s\n",
      "  LR:                            5.35946272456e-06\n",
      "  training loss:                 0.0006264452653462877\n",
      "  validation loss:               0.019220722656297897\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 689 of 1000 took 1.02555418015s\n",
      "  LR:                            5.31032687495e-06\n",
      "  training loss:                 0.0009511954105498432\n",
      "  validation loss:               0.020624428022918955\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 690 of 1000 took 1.01882195473s\n",
      "  LR:                            5.26164150553e-06\n",
      "  training loss:                 0.0006183437675436126\n",
      "  validation loss:               0.018152556132658253\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 691 of 1000 took 1.0417509079s\n",
      "  LR:                            5.21340248625e-06\n",
      "  training loss:                 0.0009485910779731324\n",
      "  validation loss:               0.01927912835630455\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 692 of 1000 took 1.04766511917s\n",
      "  LR:                            5.16560572496e-06\n",
      "  training loss:                 0.001025442138927272\n",
      "  validation loss:               0.02016580242031653\n",
      "  validation error rate:         1.3928571250289679%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 693 of 1000 took 1.0254919529s\n",
      "  LR:                            5.11824716701e-06\n",
      "  training loss:                 0.0007536422872640421\n",
      "  validation loss:               0.018854429085422453\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 694 of 1000 took 1.03458380699s\n",
      "  LR:                            5.07132279493e-06\n",
      "  training loss:                 0.0005932073524076366\n",
      "  validation loss:               0.019831572933721224\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 695 of 1000 took 1.04359412193s\n",
      "  LR:                            5.02482862808e-06\n",
      "  training loss:                 0.0007795024642121007\n",
      "  validation loss:               0.019658173783682287\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 696 of 1000 took 1.0258140564s\n",
      "  LR:                            4.97876072231e-06\n",
      "  training loss:                 0.0006178868043578067\n",
      "  validation loss:               0.020067976148701355\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 697 of 1000 took 1.02655792236s\n",
      "  LR:                            4.93311516964e-06\n",
      "  training loss:                 0.0009256070066359377\n",
      "  validation loss:               0.019168434465037926\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 698 of 1000 took 1.02729296684s\n",
      "  LR:                            4.88788809792e-06\n",
      "  training loss:                 0.0007897034755327325\n",
      "  validation loss:               0.02006643679591694\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 699 of 1000 took 1.02782797813s\n",
      "  LR:                            4.84307567048e-06\n",
      "  training loss:                 0.0007877646604778978\n",
      "  validation loss:               0.020691232496022036\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 700 of 1000 took 1.02320694923s\n",
      "  LR:                            4.79867408584e-06\n",
      "  training loss:                 0.0006932438885150853\n",
      "  validation loss:               0.02031702207854583\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 701 of 1000 took 1.01606893539s\n",
      "  LR:                            4.75467957738e-06\n",
      "  training loss:                 0.0007131640644666061\n",
      "  validation loss:               0.01992315555357241\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 702 of 1000 took 1.00532984734s\n",
      "  LR:                            4.711088413e-06\n",
      "  training loss:                 0.0006224146154880493\n",
      "  validation loss:               0.01988194169410105\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 703 of 1000 took 1.003002882s\n",
      "  LR:                            4.66789689482e-06\n",
      "  training loss:                 0.0008220869264204446\n",
      "  validation loss:               0.02008719150243061\n",
      "  validation error rate:         1.3928571250289679%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 704 of 1000 took 1.00876283646s\n",
      "  LR:                            4.62510135885e-06\n",
      "  training loss:                 0.0005788962214456566\n",
      "  validation loss:               0.02099548903061077\n",
      "  validation error rate:         1.3928571117243596%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 705 of 1000 took 1.0131790638s\n",
      "  LR:                            4.58269817471e-06\n",
      "  training loss:                 0.0006292449526836542\n",
      "  validation loss:               0.019949560899311183\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 706 of 1000 took 1.01478791237s\n",
      "  LR:                            4.54068374531e-06\n",
      "  training loss:                 0.0007023155514262292\n",
      "  validation loss:               0.02083829686970213\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 707 of 1000 took 1.02562904358s\n",
      "  LR:                            4.49905450651e-06\n",
      "  training loss:                 0.000587699752717232\n",
      "  validation loss:               0.018959923805336336\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 708 of 1000 took 1.04154491425s\n",
      "  LR:                            4.45780692686e-06\n",
      "  training loss:                 0.0006598834973750493\n",
      "  validation loss:               0.01900495988390308\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 709 of 1000 took 1.02631402016s\n",
      "  LR:                            4.4169375073e-06\n",
      "  training loss:                 0.0006611402896747703\n",
      "  validation loss:               0.02071721195365431\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 710 of 1000 took 1.01430296898s\n",
      "  LR:                            4.37644278083e-06\n",
      "  training loss:                 0.0006791832017403762\n",
      "  validation loss:               0.02065927189375673\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 711 of 1000 took 1.0354847908s\n",
      "  LR:                            4.33631931224e-06\n",
      "  training loss:                 0.0005528397806870089\n",
      "  validation loss:               0.02011370791920594\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 712 of 1000 took 1.02584195137s\n",
      "  LR:                            4.29656369782e-06\n",
      "  training loss:                 0.0006502401126773387\n",
      "  validation loss:               0.02149113973220145\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 713 of 1000 took 1.01822400093s\n",
      "  LR:                            4.25717256507e-06\n",
      "  training loss:                 0.0007284230955643763\n",
      "  validation loss:               0.020465714008813456\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 714 of 1000 took 1.01431393623s\n",
      "  LR:                            4.21814257239e-06\n",
      "  training loss:                 0.0007078209015436615\n",
      "  validation loss:               0.020517232722600705\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 715 of 1000 took 1.0103738308s\n",
      "  LR:                            4.17947040884e-06\n",
      "  training loss:                 0.0006556542529080269\n",
      "  validation loss:               0.019705767294258943\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 716 of 1000 took 1.01405715942s\n",
      "  LR:                            4.14115279381e-06\n",
      "  training loss:                 0.0005841837264303168\n",
      "  validation loss:               0.021168877636747702\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 717 of 1000 took 1.02014899254s\n",
      "  LR:                            4.10318647679e-06\n",
      "  training loss:                 0.0006180739558599873\n",
      "  validation loss:               0.020279671380226967\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 718 of 1000 took 1.01867985725s\n",
      "  LR:                            4.06556823705e-06\n",
      "  training loss:                 0.0007633024199600664\n",
      "  validation loss:               0.01934326088907515\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 719 of 1000 took 1.01464796066s\n",
      "  LR:                            4.02829488341e-06\n",
      "  training loss:                 0.0009111571441243213\n",
      "  validation loss:               0.01945472928595596\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 720 of 1000 took 1.01790094376s\n",
      "  LR:                            3.99136325393e-06\n",
      "  training loss:                 0.0009064028766843117\n",
      "  validation loss:               0.01936606613786093\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 721 of 1000 took 1.01128196716s\n",
      "  LR:                            3.95477021567e-06\n",
      "  training loss:                 0.0009732117516049959\n",
      "  validation loss:               0.019930354951481734\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 722 of 1000 took 1.01979207993s\n",
      "  LR:                            3.9185126644e-06\n",
      "  training loss:                 0.0010772314253723976\n",
      "  validation loss:               0.01972319885888802\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 723 of 1000 took 1.04164910316s\n",
      "  LR:                            3.88258752435e-06\n",
      "  training loss:                 0.0007043722196944954\n",
      "  validation loss:               0.020293875061075335\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 724 of 1000 took 1.02670884132s\n",
      "  LR:                            3.84699174797e-06\n",
      "  training loss:                 0.0006416777220801567\n",
      "  validation loss:               0.01956839540175029\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 725 of 1000 took 1.02280306816s\n",
      "  LR:                            3.81172231563e-06\n",
      "  training loss:                 0.0007723338659636336\n",
      "  validation loss:               0.020232032552095398\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 726 of 1000 took 1.01734519005s\n",
      "  LR:                            3.77677623538e-06\n",
      "  training loss:                 0.00042297495212387595\n",
      "  validation loss:               0.019371419682392293\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 727 of 1000 took 1.02765798569s\n",
      "  LR:                            3.74215054273e-06\n",
      "  training loss:                 0.0007007724390981472\n",
      "  validation loss:               0.01934977966759886\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 728 of 1000 took 1.01429796219s\n",
      "  LR:                            3.70784230033e-06\n",
      "  training loss:                 0.0009662571772062566\n",
      "  validation loss:               0.020672274637036026\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 729 of 1000 took 1.01899123192s\n",
      "  LR:                            3.6738485978e-06\n",
      "  training loss:                 0.0005382179141791151\n",
      "  validation loss:               0.020006033585760617\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 730 of 1000 took 1.01427316666s\n",
      "  LR:                            3.6401665514e-06\n",
      "  training loss:                 0.0007746498608178273\n",
      "  validation loss:               0.020339040883949826\n",
      "  validation error rate:         1.3928571250289679%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 731 of 1000 took 1.0069129467s\n",
      "  LR:                            3.60679330385e-06\n",
      "  training loss:                 0.0006302384726358291\n",
      "  validation loss:               0.02012429402176557\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 732 of 1000 took 1.0177590847s\n",
      "  LR:                            3.57372602408e-06\n",
      "  training loss:                 0.000551015580733772\n",
      "  validation loss:               0.019767049824752445\n",
      "  validation error rate:         1.464285688208682%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 733 of 1000 took 1.02456188202s\n",
      "  LR:                            3.54096190696e-06\n",
      "  training loss:                 0.0006504320872294578\n",
      "  validation loss:               0.019383208992491876\n",
      "  validation error rate:         1.3928571250289679%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 734 of 1000 took 1.01462101936s\n",
      "  LR:                            3.50849817306e-06\n",
      "  training loss:                 0.0010225575042422928\n",
      "  validation loss:               0.01996738521847874\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 735 of 1000 took 1.03323793411s\n",
      "  LR:                            3.47633206847e-06\n",
      "  training loss:                 0.0006424516637666333\n",
      "  validation loss:               0.020023113149883493\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 736 of 1000 took 1.0362200737s\n",
      "  LR:                            3.44446086449e-06\n",
      "  training loss:                 0.0005509200001395196\n",
      "  validation loss:               0.019984562699566562\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 737 of 1000 took 1.03027105331s\n",
      "  LR:                            3.41288185747e-06\n",
      "  training loss:                 0.0005273889566192438\n",
      "  validation loss:               0.020754996254774078\n",
      "  validation error rate:         1.4999999664723873%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 738 of 1000 took 1.02866601944s\n",
      "  LR:                            3.38159236853e-06\n",
      "  training loss:                 0.0007070082366432055\n",
      "  validation loss:               0.02166982498186241\n",
      "  validation error rate:         1.464285688208682%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 739 of 1000 took 1.04856300354s\n",
      "  LR:                            3.35058974334e-06\n",
      "  training loss:                 0.0006435402082012294\n",
      "  validation loss:               0.021068985923193395\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 740 of 1000 took 1.03095293045s\n",
      "  LR:                            3.31987135193e-06\n",
      "  training loss:                 0.0007848120655645918\n",
      "  validation loss:               0.021150084296485665\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 741 of 1000 took 1.01633191109s\n",
      "  LR:                            3.28943458843e-06\n",
      "  training loss:                 0.0008553438489743528\n",
      "  validation loss:               0.019256518904252777\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 742 of 1000 took 1.01879692078s\n",
      "  LR:                            3.25927687085e-06\n",
      "  training loss:                 0.0006820924622743138\n",
      "  validation loss:               0.019875094826732363\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 743 of 1000 took 1.02792406082s\n",
      "  LR:                            3.22939564089e-06\n",
      "  training loss:                 0.00045141153901678377\n",
      "  validation loss:               0.02002679864277265\n",
      "  validation error rate:         1.4999999664723873%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 744 of 1000 took 1.03201317787s\n",
      "  LR:                            3.19978836369e-06\n",
      "  training loss:                 0.00047177318435031755\n",
      "  validation loss:               0.020488601859792004\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 745 of 1000 took 1.01917505264s\n",
      "  LR:                            3.17045252764e-06\n",
      "  training loss:                 0.00039985780201431335\n",
      "  validation loss:               0.02010164107196033\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 746 of 1000 took 1.03064894676s\n",
      "  LR:                            3.14138564415e-06\n",
      "  training loss:                 0.00044923838954362953\n",
      "  validation loss:               0.02055389809200798\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 747 of 1000 took 1.05661296844s\n",
      "  LR:                            3.11258524745e-06\n",
      "  training loss:                 0.0004072664177249575\n",
      "  validation loss:               0.020751268081945846\n",
      "  validation error rate:         1.464285688208682%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 748 of 1000 took 1.0341258049s\n",
      "  LR:                            3.08404889438e-06\n",
      "  training loss:                 0.0011518159412655478\n",
      "  validation loss:               0.020175586629193276\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 749 of 1000 took 1.03709506989s\n",
      "  LR:                            3.05577416416e-06\n",
      "  training loss:                 0.0007975636431524004\n",
      "  validation loss:               0.020333915391737328\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 750 of 1000 took 1.01630306244s\n",
      "  LR:                            3.02775865823e-06\n",
      "  training loss:                 0.0008222918473446792\n",
      "  validation loss:               0.019967180576973727\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 751 of 1000 took 1.02909994125s\n",
      "  LR:                            3e-06\n",
      "  training loss:                 0.00040946877111109107\n",
      "  validation loss:               0.020449634965741228\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 752 of 1000 took 1.02320599556s\n",
      "  LR:                            2.97249583468e-06\n",
      "  training loss:                 0.0006356299617129433\n",
      "  validation loss:               0.021406188203919947\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 753 of 1000 took 1.01659393311s\n",
      "  LR:                            2.94524382906e-06\n",
      "  training loss:                 0.0008985478934341566\n",
      "  validation loss:               0.019825404888251796\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 754 of 1000 took 1.01252603531s\n",
      "  LR:                            2.91824167133e-06\n",
      "  training loss:                 0.000725494202532004\n",
      "  validation loss:               0.02007970839414546\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 755 of 1000 took 1.01951003075s\n",
      "  LR:                            2.89148707087e-06\n",
      "  training loss:                 0.0004593944295158829\n",
      "  validation loss:               0.018943706826706017\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 756 of 1000 took 1.00340914726s\n",
      "  LR:                            2.86497775806e-06\n",
      "  training loss:                 0.0007054339917168725\n",
      "  validation loss:               0.02066541115761668\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 757 of 1000 took 1.00695514679s\n",
      "  LR:                            2.8387114841e-06\n",
      "  training loss:                 0.0008211460908812535\n",
      "  validation loss:               0.020079357354136716\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 758 of 1000 took 1.00704908371s\n",
      "  LR:                            2.81268602078e-06\n",
      "  training loss:                 0.0007488284873909734\n",
      "  validation loss:               0.020855045661197176\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 759 of 1000 took 1.01208877563s\n",
      "  LR:                            2.78689916034e-06\n",
      "  training loss:                 0.00070054597509966\n",
      "  validation loss:               0.020453261311299036\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 760 of 1000 took 1.0141851902s\n",
      "  LR:                            2.76134871526e-06\n",
      "  training loss:                 0.0004892603342020319\n",
      "  validation loss:               0.021134581583152925\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 761 of 1000 took 1.01527905464s\n",
      "  LR:                            2.73603251807e-06\n",
      "  training loss:                 0.0004755029418114819\n",
      "  validation loss:               0.020758535560389646\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 762 of 1000 took 1.02313303947s\n",
      "  LR:                            2.71094842117e-06\n",
      "  training loss:                 0.0009299507258617723\n",
      "  validation loss:               0.019541016696686193\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 763 of 1000 took 1.02462315559s\n",
      "  LR:                            2.68609429665e-06\n",
      "  training loss:                 0.00046668873221332273\n",
      "  validation loss:               0.020183630703416253\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 764 of 1000 took 1.01455593109s\n",
      "  LR:                            2.66146803611e-06\n",
      "  training loss:                 0.0010425816293437654\n",
      "  validation loss:               0.019507808203343302\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 765 of 1000 took 1.02647995949s\n",
      "  LR:                            2.63706755049e-06\n",
      "  training loss:                 0.00041374601467325913\n",
      "  validation loss:               0.0201025967294949\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 766 of 1000 took 1.0230550766s\n",
      "  LR:                            2.61289076987e-06\n",
      "  training loss:                 0.0007888951359623942\n",
      "  validation loss:               0.020126832449542626\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 767 of 1000 took 1.01620006561s\n",
      "  LR:                            2.5889356433e-06\n",
      "  training loss:                 0.0004498852492272567\n",
      "  validation loss:               0.020066440936976244\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 768 of 1000 took 1.0124270916s\n",
      "  LR:                            2.56520013865e-06\n",
      "  training loss:                 0.0005983600058487702\n",
      "  validation loss:               0.019276001224560396\n",
      "  validation error rate:         1.3928571117243596%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 769 of 1000 took 1.0223698616s\n",
      "  LR:                            2.54168224242e-06\n",
      "  training loss:                 0.0005512175525024412\n",
      "  validation loss:               0.020595936120116676\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 770 of 1000 took 1.01275205612s\n",
      "  LR:                            2.51837995956e-06\n",
      "  training loss:                 0.0007769346963942446\n",
      "  validation loss:               0.02132216899190098\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 771 of 1000 took 1.0059170723s\n",
      "  LR:                            2.49529131331e-06\n",
      "  training loss:                 0.0006523955954749952\n",
      "  validation loss:               0.020165126795680926\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 772 of 1000 took 1.01506900787s\n",
      "  LR:                            2.47241434504e-06\n",
      "  training loss:                 0.0005622692617890835\n",
      "  validation loss:               0.02055444471937205\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 773 of 1000 took 1.00980615616s\n",
      "  LR:                            2.44974711408e-06\n",
      "  training loss:                 0.0010003754194860234\n",
      "  validation loss:               0.020444322510489395\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 774 of 1000 took 1.00759005547s\n",
      "  LR:                            2.42728769754e-06\n",
      "  training loss:                 0.0006836838228698007\n",
      "  validation loss:               0.02099925205649405\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 775 of 1000 took 1.01311397552s\n",
      "  LR:                            2.40503419016e-06\n",
      "  training loss:                 0.0008580800176043327\n",
      "  validation loss:               0.020775401016830335\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 776 of 1000 took 1.01707196236s\n",
      "  LR:                            2.38298470417e-06\n",
      "  training loss:                 0.00037757974167881093\n",
      "  validation loss:               0.020285554283743425\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 777 of 1000 took 1.01121211052s\n",
      "  LR:                            2.36113736909e-06\n",
      "  training loss:                 0.0007667441235356082\n",
      "  validation loss:               0.020920070985864316\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 778 of 1000 took 1.02022504807s\n",
      "  LR:                            2.33949033157e-06\n",
      "  training loss:                 0.0006035362583265215\n",
      "  validation loss:               0.02050329523626715\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 779 of 1000 took 1.00863599777s\n",
      "  LR:                            2.31804175529e-06\n",
      "  training loss:                 0.0005121036463028815\n",
      "  validation loss:               0.020417099951633384\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 780 of 1000 took 1.01565790176s\n",
      "  LR:                            2.29678982073e-06\n",
      "  training loss:                 0.0008065144507327204\n",
      "  validation loss:               0.021019805487022886\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 781 of 1000 took 1.02219295502s\n",
      "  LR:                            2.27573272509e-06\n",
      "  training loss:                 0.0004980358665689433\n",
      "  validation loss:               0.020778613397851586\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 782 of 1000 took 1.02031803131s\n",
      "  LR:                            2.25486868205e-06\n",
      "  training loss:                 0.0006963323969678052\n",
      "  validation loss:               0.021715893892438283\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 783 of 1000 took 1.01449608803s\n",
      "  LR:                            2.23419592172e-06\n",
      "  training loss:                 0.0006341754376086286\n",
      "  validation loss:               0.019800047307009145\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 784 of 1000 took 1.02272295952s\n",
      "  LR:                            2.21371269039e-06\n",
      "  training loss:                 0.0006745942865453113\n",
      "  validation loss:               0.021231939816581353\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 785 of 1000 took 1.03692507744s\n",
      "  LR:                            2.19341725045e-06\n",
      "  training loss:                 0.0006813945682872552\n",
      "  validation loss:               0.019380245235802413\n",
      "  validation error rate:         1.3928571117243596%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 786 of 1000 took 1.03214287758s\n",
      "  LR:                            2.17330788023e-06\n",
      "  training loss:                 0.0007380450567988423\n",
      "  validation loss:               0.02054084895644337\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 787 of 1000 took 1.02867507935s\n",
      "  LR:                            2.15338287381e-06\n",
      "  training loss:                 0.0006823156606019823\n",
      "  validation loss:               0.019534850923004603\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 788 of 1000 took 1.01878404617s\n",
      "  LR:                            2.13364054096e-06\n",
      "  training loss:                 0.0006420315975564041\n",
      "  validation loss:               0.020848295553142698\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 789 of 1000 took 1.02567195892s\n",
      "  LR:                            2.1140792069e-06\n",
      "  training loss:                 0.0005985720552240892\n",
      "  validation loss:               0.02092009840738943\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 790 of 1000 took 1.01638388634s\n",
      "  LR:                            2.09469721223e-06\n",
      "  training loss:                 0.0004118660417443674\n",
      "  validation loss:               0.021110511523927147\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 791 of 1000 took 1.02798604965s\n",
      "  LR:                            2.07549291276e-06\n",
      "  training loss:                 0.0007191828711958859\n",
      "  validation loss:               0.021457534270165217\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 792 of 1000 took 1.03813695908s\n",
      "  LR:                            2.05646467936e-06\n",
      "  training loss:                 0.0005972337079432782\n",
      "  validation loss:               0.021437097673437426\n",
      "  validation error rate:         1.5357142646930046%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 793 of 1000 took 1.04384803772s\n",
      "  LR:                            2.03761089785e-06\n",
      "  training loss:                 0.000779889885484074\n",
      "  validation loss:               0.021362580176043724\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 794 of 1000 took 1.01647090912s\n",
      "  LR:                            2.01892996885e-06\n",
      "  training loss:                 0.0004353689022372777\n",
      "  validation loss:               0.020444130612304434\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 795 of 1000 took 1.01805305481s\n",
      "  LR:                            2.00042030764e-06\n",
      "  training loss:                 0.0005403050012798406\n",
      "  validation loss:               0.02155799209140241\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 796 of 1000 took 1.01727485657s\n",
      "  LR:                            1.98208034402e-06\n",
      "  training loss:                 0.0005916205651632696\n",
      "  validation loss:               0.021204786110843088\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 797 of 1000 took 1.04045200348s\n",
      "  LR:                            1.9639085222e-06\n",
      "  training loss:                 0.0005283980806487587\n",
      "  validation loss:               0.020531717881161576\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 798 of 1000 took 1.02375721931s\n",
      "  LR:                            1.94590330064e-06\n",
      "  training loss:                 0.0005285001789673896\n",
      "  validation loss:               0.020875286796321495\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 799 of 1000 took 1.01745605469s\n",
      "  LR:                            1.92806315195e-06\n",
      "  training loss:                 0.0006284226783537918\n",
      "  validation loss:               0.02176608269136133\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 800 of 1000 took 1.03495287895s\n",
      "  LR:                            1.91038656272e-06\n",
      "  training loss:                 0.0006384174418338476\n",
      "  validation loss:               0.020510459068256232\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 801 of 1000 took 1.03159308434s\n",
      "  LR:                            1.89287203344e-06\n",
      "  training loss:                 0.0006109934401259783\n",
      "  validation loss:               0.02133706638726705\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 802 of 1000 took 1.02479982376s\n",
      "  LR:                            1.87551807833e-06\n",
      "  training loss:                 0.00044396114033225877\n",
      "  validation loss:               0.019507614967746383\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 803 of 1000 took 1.05481505394s\n",
      "  LR:                            1.85832322523e-06\n",
      "  training loss:                 0.0011072111925563926\n",
      "  validation loss:               0.019235127455820993\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 804 of 1000 took 1.03828978539s\n",
      "  LR:                            1.84128601549e-06\n",
      "  training loss:                 0.0008049838302931241\n",
      "  validation loss:               0.020059802731290283\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 805 of 1000 took 1.02413201332s\n",
      "  LR:                            1.82440500384e-06\n",
      "  training loss:                 0.0006488550918394927\n",
      "  validation loss:               0.019903956417692825\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 806 of 1000 took 1.02806186676s\n",
      "  LR:                            1.80767875822e-06\n",
      "  training loss:                 0.0008755784994762924\n",
      "  validation loss:               0.021331442819376076\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 807 of 1000 took 1.05400013924s\n",
      "  LR:                            1.79110585975e-06\n",
      "  training loss:                 0.0005487567891895803\n",
      "  validation loss:               0.020426528848474845\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 808 of 1000 took 1.02725696564s\n",
      "  LR:                            1.77468490253e-06\n",
      "  training loss:                 0.0004687185793339749\n",
      "  validation loss:               0.021020729446068538\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 809 of 1000 took 1.01063203812s\n",
      "  LR:                            1.75841449354e-06\n",
      "  training loss:                 0.0006500843262616025\n",
      "  validation loss:               0.020796342935195104\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 810 of 1000 took 1.01744413376s\n",
      "  LR:                            1.74229325256e-06\n",
      "  training loss:                 0.0009908202399695736\n",
      "  validation loss:               0.019588729075621814\n",
      "  validation error rate:         1.3928571117243596%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 811 of 1000 took 0.99437212944s\n",
      "  LR:                            1.72631981201e-06\n",
      "  training loss:                 0.0004737908924272126\n",
      "  validation loss:               0.020669626668677665\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 812 of 1000 took 1.01833605766s\n",
      "  LR:                            1.71049281684e-06\n",
      "  training loss:                 0.0003803756574285496\n",
      "  validation loss:               0.02119330324070948\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 813 of 1000 took 1.00450491905s\n",
      "  LR:                            1.69481092444e-06\n",
      "  training loss:                 0.001087997778580864\n",
      "  validation loss:               0.020096432776231916\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 814 of 1000 took 1.01036095619s\n",
      "  LR:                            1.67927280449e-06\n",
      "  training loss:                 0.00045998544701199214\n",
      "  validation loss:               0.01994217849447263\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 815 of 1000 took 1.00998401642s\n",
      "  LR:                            1.66387713887e-06\n",
      "  training loss:                 0.0005466520565605129\n",
      "  validation loss:               0.019936880394068015\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 816 of 1000 took 1.01755404472s\n",
      "  LR:                            1.64862262157e-06\n",
      "  training loss:                 0.0008304222650247021\n",
      "  validation loss:               0.021143296332281483\n",
      "  validation error rate:         1.4999999731246914%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 817 of 1000 took 1.03263902664s\n",
      "  LR:                            1.63350795853e-06\n",
      "  training loss:                 0.0007368715996379482\n",
      "  validation loss:               0.02102376035847036\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 818 of 1000 took 1.03394913673s\n",
      "  LR:                            1.61853186755e-06\n",
      "  training loss:                 0.000434122980620005\n",
      "  validation loss:               0.020179973715650185\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 819 of 1000 took 1.02225494385s\n",
      "  LR:                            1.60369307819e-06\n",
      "  training loss:                 0.0005760539864762477\n",
      "  validation loss:               0.021710192627389397\n",
      "  validation error rate:         1.4999999731246914%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 820 of 1000 took 1.02793908119s\n",
      "  LR:                            1.58899033168e-06\n",
      "  training loss:                 0.00038659158911601106\n",
      "  validation loss:               0.021257537468435266\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 821 of 1000 took 1.02168178558s\n",
      "  LR:                            1.57442238075e-06\n",
      "  training loss:                 0.0006370094985061816\n",
      "  validation loss:               0.02076054759631266\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 822 of 1000 took 1.01828289032s\n",
      "  LR:                            1.5599879896e-06\n",
      "  training loss:                 0.0007563367646981459\n",
      "  validation loss:               0.020337780496837304\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 823 of 1000 took 1.01533317566s\n",
      "  LR:                            1.54568593375e-06\n",
      "  training loss:                 0.0005694599278717092\n",
      "  validation loss:               0.020936944289132953\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 824 of 1000 took 1.02464985847s\n",
      "  LR:                            1.53151499993e-06\n",
      "  training loss:                 0.0009379315833487063\n",
      "  validation loss:               0.020131955517821813\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 825 of 1000 took 1.02016496658s\n",
      "  LR:                            1.51747398601e-06\n",
      "  training loss:                 0.0005025813337954593\n",
      "  validation loss:               0.020309555680601728\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 826 of 1000 took 1.01236701012s\n",
      "  LR:                            1.50356170088e-06\n",
      "  training loss:                 0.0005107791223215272\n",
      "  validation loss:               0.01946995798730963\n",
      "  validation error rate:         1.4285713966403688%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 827 of 1000 took 1.01234292984s\n",
      "  LR:                            1.48977696435e-06\n",
      "  training loss:                 0.0005900018384867214\n",
      "  validation loss:               0.020445962278504988\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 828 of 1000 took 1.01650500298s\n",
      "  LR:                            1.47611860704e-06\n",
      "  training loss:                 0.0005788305422480361\n",
      "  validation loss:               0.01962170036675356\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 829 of 1000 took 1.01815104485s\n",
      "  LR:                            1.46258547031e-06\n",
      "  training loss:                 0.0010318469676106367\n",
      "  validation loss:               0.019644807392199124\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 830 of 1000 took 1.01486492157s\n",
      "  LR:                            1.44917640612e-06\n",
      "  training loss:                 0.0005144928070895022\n",
      "  validation loss:               0.02000243659546998\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 831 of 1000 took 1.00899887085s\n",
      "  LR:                            1.43589027697e-06\n",
      "  training loss:                 0.00041249892410906804\n",
      "  validation loss:               0.019875950762070715\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 832 of 1000 took 1.01328206062s\n",
      "  LR:                            1.42272595578e-06\n",
      "  training loss:                 0.0005885114763006402\n",
      "  validation loss:               0.020014304481979446\n",
      "  validation error rate:         1.464285681556378%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 833 of 1000 took 1.02408981323s\n",
      "  LR:                            1.40968232582e-06\n",
      "  training loss:                 0.0007207581656417361\n",
      "  validation loss:               0.019403690333449828\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 834 of 1000 took 1.02676796913s\n",
      "  LR:                            1.39675828057e-06\n",
      "  training loss:                 0.0005459593460242934\n",
      "  validation loss:               0.020376360634275312\n",
      "  validation error rate:         1.5357142580407006%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 835 of 1000 took 1.03805303574s\n",
      "  LR:                            1.38395272368e-06\n",
      "  training loss:                 0.00047237126556113273\n",
      "  validation loss:               0.020356291422753463\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 836 of 1000 took 1.0322060585s\n",
      "  LR:                            1.37126456884e-06\n",
      "  training loss:                 0.00046442260617207947\n",
      "  validation loss:               0.018894890152296284\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 837 of 1000 took 1.03933906555s\n",
      "  LR:                            1.35869273971e-06\n",
      "  training loss:                 0.0007498482420417539\n",
      "  validation loss:               0.019360304893260554\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 838 of 1000 took 1.02125692368s\n",
      "  LR:                            1.3462361698e-06\n",
      "  training loss:                 0.0008364588260049455\n",
      "  validation loss:               0.019859193915700808\n",
      "  validation error rate:         1.4285714299018895%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 839 of 1000 took 1.02807211876s\n",
      "  LR:                            1.33389380241e-06\n",
      "  training loss:                 0.0008491183142290863\n",
      "  validation loss:               0.0206826342702178\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 840 of 1000 took 1.04107308388s\n",
      "  LR:                            1.32166459052e-06\n",
      "  training loss:                 0.000649971701471293\n",
      "  validation loss:               0.02030099953325199\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 841 of 1000 took 1.04190897942s\n",
      "  LR:                            1.30954749672e-06\n",
      "  training loss:                 0.0005728860129834789\n",
      "  validation loss:               0.020514599068389674\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 842 of 1000 took 1.02567601204s\n",
      "  LR:                            1.29754149311e-06\n",
      "  training loss:                 0.0008345359686505398\n",
      "  validation loss:               0.019950490552998548\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 843 of 1000 took 1.02643704414s\n",
      "  LR:                            1.28564556119e-06\n",
      "  training loss:                 0.0006394376324428585\n",
      "  validation loss:               0.02160849707934176\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 844 of 1000 took 1.0304069519s\n",
      "  LR:                            1.27385869184e-06\n",
      "  training loss:                 0.0005943495284327583\n",
      "  validation loss:               0.020295931799669882\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 845 of 1000 took 1.03502488136s\n",
      "  LR:                            1.26217988515e-06\n",
      "  training loss:                 0.000581429541658535\n",
      "  validation loss:               0.02019276548942019\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 846 of 1000 took 1.03829884529s\n",
      "  LR:                            1.25060815041e-06\n",
      "  training loss:                 0.0005052931702700145\n",
      "  validation loss:               0.019693481111452065\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 847 of 1000 took 1.03030610085s\n",
      "  LR:                            1.23914250597e-06\n",
      "  training loss:                 0.0005291006837361866\n",
      "  validation loss:               0.020138631940686276\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 848 of 1000 took 1.03358006477s\n",
      "  LR:                            1.22778197919e-06\n",
      "  training loss:                 0.00043019107822869155\n",
      "  validation loss:               0.01961271315147834\n",
      "  validation error rate:         1.4285714299018895%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 849 of 1000 took 1.03691697121s\n",
      "  LR:                            1.21652560635e-06\n",
      "  training loss:                 0.0009458244263722758\n",
      "  validation loss:               0.020821589693826224\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 850 of 1000 took 1.02461600304s\n",
      "  LR:                            1.20537243255e-06\n",
      "  training loss:                 0.0008461390483604535\n",
      "  validation loss:               0.02144278650770762\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 851 of 1000 took 1.03009200096s\n",
      "  LR:                            1.19432151166e-06\n",
      "  training loss:                 0.0003701600379283367\n",
      "  validation loss:               0.02025979905322726\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 852 of 1000 took 1.03701114655s\n",
      "  LR:                            1.18337190623e-06\n",
      "  training loss:                 0.0007312604773529267\n",
      "  validation loss:               0.020966661653281853\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 853 of 1000 took 1.05616617203s\n",
      "  LR:                            1.17252268738e-06\n",
      "  training loss:                 0.0005227874539407233\n",
      "  validation loss:               0.020164389336839252\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 854 of 1000 took 1.03354287148s\n",
      "  LR:                            1.16177293476e-06\n",
      "  training loss:                 0.00035275433473215984\n",
      "  validation loss:               0.0193745444079728\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 855 of 1000 took 1.00998282433s\n",
      "  LR:                            1.15112173648e-06\n",
      "  training loss:                 0.0007430668844073774\n",
      "  validation loss:               0.020095885945400887\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 856 of 1000 took 1.03069281578s\n",
      "  LR:                            1.14056818896e-06\n",
      "  training loss:                 0.0007301454671825942\n",
      "  validation loss:               0.020564516657032073\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 857 of 1000 took 1.02672600746s\n",
      "  LR:                            1.13011139695e-06\n",
      "  training loss:                 0.0009508257490914218\n",
      "  validation loss:               0.020419245361283953\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 858 of 1000 took 1.0179541111s\n",
      "  LR:                            1.11975047339e-06\n",
      "  training loss:                 0.0005691099675473766\n",
      "  validation loss:               0.01971337812886174\n",
      "  validation error rate:         1.3571428401129586%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 859 of 1000 took 1.05270600319s\n",
      "  LR:                            1.10948453934e-06\n",
      "  training loss:                 0.0005274054980583956\n",
      "  validation loss:               0.01934381078795663\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 860 of 1000 took 1.03603792191s\n",
      "  LR:                            1.09931272394e-06\n",
      "  training loss:                 0.0006414908581107753\n",
      "  validation loss:               0.021068937960080802\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 861 of 1000 took 1.03040099144s\n",
      "  LR:                            1.08923416431e-06\n",
      "  training loss:                 0.0006138789361403617\n",
      "  validation loss:               0.01995831568326269\n",
      "  validation error rate:         1.4285714299018895%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 862 of 1000 took 1.03444886208s\n",
      "  LR:                            1.07924800547e-06\n",
      "  training loss:                 0.001024580760497638\n",
      "  validation loss:               0.02010291182835187\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 863 of 1000 took 1.0207490921s\n",
      "  LR:                            1.06935340028e-06\n",
      "  training loss:                 0.00047852096452807955\n",
      "  validation loss:               0.019744835575490276\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 864 of 1000 took 1.02089214325s\n",
      "  LR:                            1.05954950938e-06\n",
      "  training loss:                 0.0008489899468217158\n",
      "  validation loss:               0.020763415755936876\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 865 of 1000 took 1.03980398178s\n",
      "  LR:                            1.04983550109e-06\n",
      "  training loss:                 0.0007283789777134456\n",
      "  validation loss:               0.02022535358661161\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 866 of 1000 took 1.02247905731s\n",
      "  LR:                            1.04021055136e-06\n",
      "  training loss:                 0.0006836039538809506\n",
      "  validation loss:               0.019687431509997362\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 867 of 1000 took 1.02730607986s\n",
      "  LR:                            1.0306738437e-06\n",
      "  training loss:                 0.0006315376910806048\n",
      "  validation loss:               0.01991240574924242\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 868 of 1000 took 1.03122711182s\n",
      "  LR:                            1.0212245691e-06\n",
      "  training loss:                 0.0005569039227031466\n",
      "  validation loss:               0.01999309393119932\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 869 of 1000 took 1.01392006874s\n",
      "  LR:                            1.01186192598e-06\n",
      "  training loss:                 0.00046814819316579536\n",
      "  validation loss:               0.020386853072393154\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 870 of 1000 took 1.01742100716s\n",
      "  LR:                            1.00258512008e-06\n",
      "  training loss:                 0.0006597867395224539\n",
      "  validation loss:               0.021025650710466186\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 871 of 1000 took 1.01032805443s\n",
      "  LR:                            9.93393364448e-07\n",
      "  training loss:                 0.0005895988263820474\n",
      "  validation loss:               0.019649306730830825\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 872 of 1000 took 1.01721310616s\n",
      "  LR:                            9.84285879339e-07\n",
      "  training loss:                 0.00042519703850987117\n",
      "  validation loss:               0.02049382641104915\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 873 of 1000 took 1.01657986641s\n",
      "  LR:                            9.75261892156e-07\n",
      "  training loss:                 0.0006724066630186719\n",
      "  validation loss:               0.0212912288885231\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 874 of 1000 took 1.00626802444s\n",
      "  LR:                            9.66320637385e-07\n",
      "  training loss:                 0.0008003065738384574\n",
      "  validation loss:               0.021474512706585562\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 875 of 1000 took 1.00781488419s\n",
      "  LR:                            9.5746135653e-07\n",
      "  training loss:                 0.0006786148527164193\n",
      "  validation loss:               0.02013709721489119\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 876 of 1000 took 1.04457187653s\n",
      "  LR:                            9.48683298051e-07\n",
      "  training loss:                 0.00037751234921656494\n",
      "  validation loss:               0.020161824475508183\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 877 of 1000 took 1.01336097717s\n",
      "  LR:                            9.39985717295e-07\n",
      "  training loss:                 0.0007622882484374613\n",
      "  validation loss:               0.021066711774827645\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 878 of 1000 took 1.01299786568s\n",
      "  LR:                            9.31367876439e-07\n",
      "  training loss:                 0.0008708323306580843\n",
      "  validation loss:               0.019716381411334232\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 879 of 1000 took 1.01860117912s\n",
      "  LR:                            9.22829044422e-07\n",
      "  training loss:                 0.0005460640985090241\n",
      "  validation loss:               0.020489176269620657\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 880 of 1000 took 1.01582098007s\n",
      "  LR:                            9.14368496888e-07\n",
      "  training loss:                 0.0006707651667818733\n",
      "  validation loss:               0.020071262875197653\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 881 of 1000 took 1.02277803421s\n",
      "  LR:                            9.05985516121e-07\n",
      "  training loss:                 0.0006744395804855184\n",
      "  validation loss:               0.019621840290450825\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 882 of 1000 took 1.02560782433s\n",
      "  LR:                            8.97679390982e-07\n",
      "  training loss:                 0.000762593742171951\n",
      "  validation loss:               0.020136764971539378\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 883 of 1000 took 1.02671694756s\n",
      "  LR:                            8.89449416857e-07\n",
      "  training loss:                 0.0007784289438363016\n",
      "  validation loss:               0.019256745165746127\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 884 of 1000 took 1.02829217911s\n",
      "  LR:                            8.81294895588e-07\n",
      "  training loss:                 0.0008474496132401006\n",
      "  validation loss:               0.02071247559173831\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 885 of 1000 took 1.02156019211s\n",
      "  LR:                            8.7321513542e-07\n",
      "  training loss:                 0.00046196804495073876\n",
      "  validation loss:               0.01989721250304553\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 886 of 1000 took 1.01155900955s\n",
      "  LR:                            8.65209450938e-07\n",
      "  training loss:                 0.0003507519878744895\n",
      "  validation loss:               0.020390216646757966\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 887 of 1000 took 1.01263904572s\n",
      "  LR:                            8.57277163013e-07\n",
      "  training loss:                 0.001015273426330793\n",
      "  validation loss:               0.02049394387644757\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 888 of 1000 took 1.01321697235s\n",
      "  LR:                            8.4941759874e-07\n",
      "  training loss:                 0.0004134544763407094\n",
      "  validation loss:               0.020162678782071453\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 889 of 1000 took 1.01505184174s\n",
      "  LR:                            8.41630091386e-07\n",
      "  training loss:                 0.00044660081874555395\n",
      "  validation loss:               0.019953272405213544\n",
      "  validation error rate:         1.3214285751538617%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 890 of 1000 took 1.00648403168s\n",
      "  LR:                            8.33913980328e-07\n",
      "  training loss:                 0.0004608566710488508\n",
      "  validation loss:               0.021135841573206044\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 891 of 1000 took 1.02328705788s\n",
      "  LR:                            8.26268611001e-07\n",
      "  training loss:                 0.0009456515192876308\n",
      "  validation loss:               0.02201405602110234\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 892 of 1000 took 1.01456904411s\n",
      "  LR:                            8.18693334842e-07\n",
      "  training loss:                 0.0004809505140496727\n",
      "  validation loss:               0.020624693141014307\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 893 of 1000 took 1.01189303398s\n",
      "  LR:                            8.11187509233e-07\n",
      "  training loss:                 0.0006445180840198863\n",
      "  validation loss:               0.020180417267381148\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 894 of 1000 took 1.02670383453s\n",
      "  LR:                            8.03750497446e-07\n",
      "  training loss:                 0.0005520956132556876\n",
      "  validation loss:               0.020165388107143047\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 895 of 1000 took 1.02866601944s\n",
      "  LR:                            7.96381668593e-07\n",
      "  training loss:                 0.00046190323195172394\n",
      "  validation loss:               0.020120933520437184\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 896 of 1000 took 1.0311870575s\n",
      "  LR:                            7.89080397569e-07\n",
      "  training loss:                 0.0005401815100751485\n",
      "  validation loss:               0.020706981274997815\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 897 of 1000 took 1.04639220238s\n",
      "  LR:                            7.81846065e-07\n",
      "  training loss:                 0.0005811189076451108\n",
      "  validation loss:               0.0208157143455797\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 898 of 1000 took 1.04191803932s\n",
      "  LR:                            7.7467805719e-07\n",
      "  training loss:                 0.0005605325814124572\n",
      "  validation loss:               0.020975017895190313\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 899 of 1000 took 1.03842306137s\n",
      "  LR:                            7.67575766072e-07\n",
      "  training loss:                 0.0005882857526357303\n",
      "  validation loss:               0.020257557991759052\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 900 of 1000 took 1.04748702049s\n",
      "  LR:                            7.60538589149e-07\n",
      "  training loss:                 0.0007242454330396739\n",
      "  validation loss:               0.020872339614600475\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 901 of 1000 took 1.02447485924s\n",
      "  LR:                            7.53565929453e-07\n",
      "  training loss:                 0.0011751634676570306\n",
      "  validation loss:               0.02061060602532702\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 902 of 1000 took 1.02646398544s\n",
      "  LR:                            7.46657195485e-07\n",
      "  training loss:                 0.0008176438020153482\n",
      "  validation loss:               0.020974721194371732\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 903 of 1000 took 1.02919316292s\n",
      "  LR:                            7.3981180117e-07\n",
      "  training loss:                 0.0008432686970053622\n",
      "  validation loss:               0.021143461344763637\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 904 of 1000 took 1.03576087952s\n",
      "  LR:                            7.33029165808e-07\n",
      "  training loss:                 0.0005186030336719728\n",
      "  validation loss:               0.020537798292934895\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 905 of 1000 took 1.05571007729s\n",
      "  LR:                            7.26308714021e-07\n",
      "  training loss:                 0.00042348220763147656\n",
      "  validation loss:               0.020325858104375323\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 906 of 1000 took 1.03676009178s\n",
      "  LR:                            7.19649875706e-07\n",
      "  training loss:                 0.0005825704236289736\n",
      "  validation loss:               0.020505246766455393\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 907 of 1000 took 1.03144192696s\n",
      "  LR:                            7.13052085987e-07\n",
      "  training loss:                 0.0007348411077563977\n",
      "  validation loss:               0.01983984944490023\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 908 of 1000 took 1.02982187271s\n",
      "  LR:                            7.06514785169e-07\n",
      "  training loss:                 0.0008045963678609044\n",
      "  validation loss:               0.020110579112562327\n",
      "  validation error rate:         1.3928571449858802%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 909 of 1000 took 1.02292203903s\n",
      "  LR:                            7.00037418684e-07\n",
      "  training loss:                 0.000623516794915848\n",
      "  validation loss:               0.019610106867081152\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 910 of 1000 took 1.02711701393s\n",
      "  LR:                            6.93619437053e-07\n",
      "  training loss:                 0.0006740478376070267\n",
      "  validation loss:               0.019023932389765314\n",
      "  validation error rate:         1.3928571183766638%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 911 of 1000 took 1.03507995605s\n",
      "  LR:                            6.8726029583e-07\n",
      "  training loss:                 0.0007881172354205667\n",
      "  validation loss:               0.020086878471602176\n",
      "  validation error rate:         1.3928571383335762%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 912 of 1000 took 1.02129721642s\n",
      "  LR:                            6.80959455565e-07\n",
      "  training loss:                 0.0004791218433103281\n",
      "  validation loss:               0.019651925973968382\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 913 of 1000 took 1.02559900284s\n",
      "  LR:                            6.74716381751e-07\n",
      "  training loss:                 0.0006634644813344186\n",
      "  validation loss:               0.02053073266123257\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 914 of 1000 took 1.00283718109s\n",
      "  LR:                            6.68530544781e-07\n",
      "  training loss:                 0.00048819981147470143\n",
      "  validation loss:               0.020654929639974284\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 915 of 1000 took 1.0126721859s\n",
      "  LR:                            6.62401419906e-07\n",
      "  training loss:                 0.0011909839613479679\n",
      "  validation loss:               0.01950654047375013\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 916 of 1000 took 1.02412891388s\n",
      "  LR:                            6.56328487185e-07\n",
      "  training loss:                 0.0005804525142551769\n",
      "  validation loss:               0.020218072007992305\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 917 of 1000 took 1.02157211304s\n",
      "  LR:                            6.50311231446e-07\n",
      "  training loss:                 0.000578079600507622\n",
      "  validation loss:               0.020204814466913894\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 918 of 1000 took 1.01429009438s\n",
      "  LR:                            6.44349142239e-07\n",
      "  training loss:                 0.0007655530566037072\n",
      "  validation loss:               0.020849965812106217\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 919 of 1000 took 1.02004289627s\n",
      "  LR:                            6.38441713795e-07\n",
      "  training loss:                 0.0006459950670877724\n",
      "  validation loss:               0.020378299772606363\n",
      "  validation error rate:         1.4285714299018895%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 920 of 1000 took 1.01339697838s\n",
      "  LR:                            6.3258844498e-07\n",
      "  training loss:                 0.0008334391349064042\n",
      "  validation loss:               0.019839677710219154\n",
      "  validation error rate:         1.428571403292673%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 921 of 1000 took 1.00634098053s\n",
      "  LR:                            6.26788839256e-07\n",
      "  training loss:                 0.0007047961842769469\n",
      "  validation loss:               0.020292127242100833\n",
      "  validation error rate:         1.4285714299018895%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 922 of 1000 took 1.00813984871s\n",
      "  LR:                            6.21042404637e-07\n",
      "  training loss:                 0.0007906066264084557\n",
      "  validation loss:               0.019705311145766506\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 923 of 1000 took 1.01826190948s\n",
      "  LR:                            6.15348653648e-07\n",
      "  training loss:                 0.0006381066550361649\n",
      "  validation loss:               0.020566634767289673\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 924 of 1000 took 1.01564407349s\n",
      "  LR:                            6.09707103281e-07\n",
      "  training loss:                 0.0008722458252410594\n",
      "  validation loss:               0.02002474831013907\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 925 of 1000 took 1.01667904854s\n",
      "  LR:                            6.04117274959e-07\n",
      "  training loss:                 0.0006756297484803794\n",
      "  validation loss:               0.01995637560373455\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 926 of 1000 took 1.00983405113s\n",
      "  LR:                            5.98578694491e-07\n",
      "  training loss:                 0.0007419971051077821\n",
      "  validation loss:               0.01946085349274134\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 927 of 1000 took 1.01220488548s\n",
      "  LR:                            5.93090892034e-07\n",
      "  training loss:                 0.0006716015555642546\n",
      "  validation loss:               0.021216590380520626\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 928 of 1000 took 1.01272916794s\n",
      "  LR:                            5.87653402052e-07\n",
      "  training loss:                 0.0004690616862448368\n",
      "  validation loss:               0.019270656667816053\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 929 of 1000 took 1.0292801857s\n",
      "  LR:                            5.82265763278e-07\n",
      "  training loss:                 0.0005714964442561536\n",
      "  validation loss:               0.019610947931060503\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 930 of 1000 took 1.03016996384s\n",
      "  LR:                            5.76927518673e-07\n",
      "  training loss:                 0.00047453755383198\n",
      "  validation loss:               0.02005415406269354\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 931 of 1000 took 1.02778315544s\n",
      "  LR:                            5.71638215389e-07\n",
      "  training loss:                 0.0006684960959961556\n",
      "  validation loss:               0.02005122760393923\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 932 of 1000 took 1.02777290344s\n",
      "  LR:                            5.66397404729e-07\n",
      "  training loss:                 0.0007018415178546387\n",
      "  validation loss:               0.019965533292893918\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 933 of 1000 took 1.0403008461s\n",
      "  LR:                            5.6120464211e-07\n",
      "  training loss:                 0.0006555808206003929\n",
      "  validation loss:               0.020488954678668847\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 934 of 1000 took 1.02529597282s\n",
      "  LR:                            5.56059487024e-07\n",
      "  training loss:                 0.000842470682843053\n",
      "  validation loss:               0.020889953003331487\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 935 of 1000 took 1.02964615822s\n",
      "  LR:                            5.50961503005e-07\n",
      "  training loss:                 0.0005935007533733721\n",
      "  validation loss:               0.020526186471386154\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 936 of 1000 took 1.02329611778s\n",
      "  LR:                            5.45910257583e-07\n",
      "  training loss:                 0.0005821296078906148\n",
      "  validation loss:               0.019158712303448868\n",
      "  validation error rate:         1.3571428467652626%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 937 of 1000 took 1.02802920341s\n",
      "  LR:                            5.40905322258e-07\n",
      "  training loss:                 0.0006760456073334688\n",
      "  validation loss:               0.019758325906065823\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 938 of 1000 took 1.02397418022s\n",
      "  LR:                            5.35946272456e-07\n",
      "  training loss:                 0.0008441326912119753\n",
      "  validation loss:               0.020389268335748056\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 939 of 1000 took 1.01821494102s\n",
      "  LR:                            5.31032687495e-07\n",
      "  training loss:                 0.0006000839598300445\n",
      "  validation loss:               0.019972038567565114\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 940 of 1000 took 1.0255689621s\n",
      "  LR:                            5.26164150553e-07\n",
      "  training loss:                 0.0010820533527822484\n",
      "  validation loss:               0.019478642414989217\n",
      "  validation error rate:         1.392857131681272%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 941 of 1000 took 1.02013492584s\n",
      "  LR:                            5.21340248625e-07\n",
      "  training loss:                 0.0006628516946702673\n",
      "  validation loss:               0.01916209836157837\n",
      "  validation error rate:         1.4285714299018895%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 942 of 1000 took 1.01063990593s\n",
      "  LR:                            5.16560572496e-07\n",
      "  training loss:                 0.00071874220423922\n",
      "  validation loss:               0.020091255112285062\n",
      "  validation error rate:         1.4285714299018895%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 943 of 1000 took 1.01585102081s\n",
      "  LR:                            5.11824716701e-07\n",
      "  training loss:                 0.000602354227480905\n",
      "  validation loss:               0.01898401401922456\n",
      "  validation error rate:         1.3571428334606546%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 944 of 1000 took 1.00768899918s\n",
      "  LR:                            5.07132279493e-07\n",
      "  training loss:                 0.0005227122123584723\n",
      "  validation loss:               0.019369289141780297\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 945 of 1000 took 1.01016807556s\n",
      "  LR:                            5.02482862808e-07\n",
      "  training loss:                 0.0004754535348840333\n",
      "  validation loss:               0.020630366032232166\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 946 of 1000 took 1.01041507721s\n",
      "  LR:                            4.97876072231e-07\n",
      "  training loss:                 0.0004812720625635399\n",
      "  validation loss:               0.019685591322870875\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 947 of 1000 took 1.01662397385s\n",
      "  LR:                            4.93311516964e-07\n",
      "  training loss:                 0.0006972148913131063\n",
      "  validation loss:               0.019491503341008798\n",
      "  validation error rate:         1.3571428268083505%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 948 of 1000 took 1.0271191597s\n",
      "  LR:                            4.88788809792e-07\n",
      "  training loss:                 0.00047942805375150916\n",
      "  validation loss:               0.020012168872199254\n",
      "  validation error rate:         1.4285714299018895%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 949 of 1000 took 1.04170584679s\n",
      "  LR:                            4.84307567048e-07\n",
      "  training loss:                 0.000432908334124119\n",
      "  validation loss:               0.01895576632211617\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 950 of 1000 took 1.02576208115s\n",
      "  LR:                            4.79867408584e-07\n",
      "  training loss:                 0.0004980098133570052\n",
      "  validation loss:               0.019615753673341323\n",
      "  validation error rate:         1.357142860069871%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 951 of 1000 took 1.03079795837s\n",
      "  LR:                            4.75467957738e-07\n",
      "  training loss:                 0.0006399460704481144\n",
      "  validation loss:               0.020518876919855496\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 952 of 1000 took 1.04831504822s\n",
      "  LR:                            4.711088413e-07\n",
      "  training loss:                 0.0009932378965789468\n",
      "  validation loss:               0.020138406183832558\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 953 of 1000 took 1.03239393234s\n",
      "  LR:                            4.66789689482e-07\n",
      "  training loss:                 0.0005429181948301221\n",
      "  validation loss:               0.019964360095660334\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 954 of 1000 took 1.03096103668s\n",
      "  LR:                            4.62510135885e-07\n",
      "  training loss:                 0.0006201263139523824\n",
      "  validation loss:               0.02027897369254918\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 955 of 1000 took 1.03537392616s\n",
      "  LR:                            4.58269817471e-07\n",
      "  training loss:                 0.00046564545842019475\n",
      "  validation loss:               0.020643535460944155\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 956 of 1000 took 1.02255606651s\n",
      "  LR:                            4.54068374531e-07\n",
      "  training loss:                 0.0004394244887984906\n",
      "  validation loss:               0.020967859591889595\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 957 of 1000 took 1.0359711647s\n",
      "  LR:                            4.49905450651e-07\n",
      "  training loss:                 0.0005645332721937614\n",
      "  validation loss:               0.020230232548783533\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 958 of 1000 took 1.02715396881s\n",
      "  LR:                            4.45780692686e-07\n",
      "  training loss:                 0.0005689403772084071\n",
      "  validation loss:               0.020504207343037706\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 959 of 1000 took 1.02134799957s\n",
      "  LR:                            4.4169375073e-07\n",
      "  training loss:                 0.0006697980749069795\n",
      "  validation loss:               0.02000263010891753\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 960 of 1000 took 1.03260707855s\n",
      "  LR:                            4.37644278083e-07\n",
      "  training loss:                 0.0006411819861968377\n",
      "  validation loss:               0.020271071976115503\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 961 of 1000 took 1.01689100266s\n",
      "  LR:                            4.33631931224e-07\n",
      "  training loss:                 0.0007928483246176069\n",
      "  validation loss:               0.020095215625977807\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 962 of 1000 took 1.02285885811s\n",
      "  LR:                            4.29656369782e-07\n",
      "  training loss:                 0.0010791945162626395\n",
      "  validation loss:               0.0208446579885536\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 963 of 1000 took 1.02943992615s\n",
      "  LR:                            4.25717256507e-07\n",
      "  training loss:                 0.00023329338972654558\n",
      "  validation loss:               0.019947038953042857\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 964 of 1000 took 1.02880501747s\n",
      "  LR:                            4.21814257239e-07\n",
      "  training loss:                 0.0007002839085590922\n",
      "  validation loss:               0.019569414675061125\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 965 of 1000 took 1.01602005959s\n",
      "  LR:                            4.17947040884e-07\n",
      "  training loss:                 0.0008444235254989398\n",
      "  validation loss:               0.0208222607470816\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 966 of 1000 took 1.03434896469s\n",
      "  LR:                            4.14115279381e-07\n",
      "  training loss:                 0.00041913558761859143\n",
      "  validation loss:               0.020234506637799705\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 967 of 1000 took 1.03392910957s\n",
      "  LR:                            4.10318647679e-07\n",
      "  training loss:                 0.0010491622900566293\n",
      "  validation loss:               0.02002057660346119\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 968 of 1000 took 1.03391695023s\n",
      "  LR:                            4.06556823705e-07\n",
      "  training loss:                 0.0005644850931086948\n",
      "  validation loss:               0.0194695015400157\n",
      "  validation error rate:         1.357142853417567%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 969 of 1000 took 1.02631592751s\n",
      "  LR:                            4.02829488341e-07\n",
      "  training loss:                 0.0008159965408725486\n",
      "  validation loss:               0.01996733200628244\n",
      "  validation error rate:         1.428571409944977%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 970 of 1000 took 1.01654195786s\n",
      "  LR:                            3.99136325393e-07\n",
      "  training loss:                 0.0007914963410703739\n",
      "  validation loss:               0.019809497309633377\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 971 of 1000 took 1.01208281517s\n",
      "  LR:                            3.95477021567e-07\n",
      "  training loss:                 0.0007354856488888953\n",
      "  validation loss:               0.019781459106265435\n",
      "  validation error rate:         1.428571409944977%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 972 of 1000 took 0.997496843338s\n",
      "  LR:                            3.9185126644e-07\n",
      "  training loss:                 0.0005735613356203808\n",
      "  validation loss:               0.019947645056683023\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 973 of 1000 took 1.0053088665s\n",
      "  LR:                            3.88258752435e-07\n",
      "  training loss:                 0.0008324265003907652\n",
      "  validation loss:               0.019973579596678195\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 974 of 1000 took 1.00592303276s\n",
      "  LR:                            3.84699174797e-07\n",
      "  training loss:                 0.0006342829185550827\n",
      "  validation loss:               0.019297205825101367\n",
      "  validation error rate:         1.392857131681272%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 975 of 1000 took 1.01013302803s\n",
      "  LR:                            3.81172231563e-07\n",
      "  training loss:                 0.0008189179014083601\n",
      "  validation loss:               0.020132004024834314\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 976 of 1000 took 1.01713204384s\n",
      "  LR:                            3.77677623538e-07\n",
      "  training loss:                 0.00099318244249506\n",
      "  validation loss:               0.01875943937881987\n",
      "  validation error rate:         1.4642857081655944%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 977 of 1000 took 1.02413702011s\n",
      "  LR:                            3.74215054273e-07\n",
      "  training loss:                 0.0005728571528081104\n",
      "  validation loss:               0.02032721772755914\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 978 of 1000 took 1.02261209488s\n",
      "  LR:                            3.70784230033e-07\n",
      "  training loss:                 0.0005490061787562355\n",
      "  validation loss:               0.01933503491142931\n",
      "  validation error rate:         1.3571428268083505%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 979 of 1000 took 1.02580618858s\n",
      "  LR:                            3.6738485978e-07\n",
      "  training loss:                 0.0004700923193603255\n",
      "  validation loss:               0.019920367500162683\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 980 of 1000 took 1.0302438736s\n",
      "  LR:                            3.6401665514e-07\n",
      "  training loss:                 0.0006558024396666651\n",
      "  validation loss:               0.020182483968272078\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 981 of 1000 took 1.02858710289s\n",
      "  LR:                            3.60679330385e-07\n",
      "  training loss:                 0.0005016846301353573\n",
      "  validation loss:               0.019476758686193665\n",
      "  validation error rate:         1.3214285618492536%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 982 of 1000 took 1.0376291275s\n",
      "  LR:                            3.57372602408e-07\n",
      "  training loss:                 0.00047221915829567254\n",
      "  validation loss:               0.020152902300261694\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 983 of 1000 took 1.02843499184s\n",
      "  LR:                            3.54096190696e-07\n",
      "  training loss:                 0.0007196681963835069\n",
      "  validation loss:               0.020233708024664208\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 984 of 1000 took 1.01485610008s\n",
      "  LR:                            3.50849817306e-07\n",
      "  training loss:                 0.0005241803789672872\n",
      "  validation loss:               0.019626753257636537\n",
      "  validation error rate:         1.4285714165972812%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 985 of 1000 took 1.03112006187s\n",
      "  LR:                            3.47633206847e-07\n",
      "  training loss:                 0.0009328444835730084\n",
      "  validation loss:               0.019472881802357733\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 986 of 1000 took 1.02061009407s\n",
      "  LR:                            3.44446086449e-07\n",
      "  training loss:                 0.0006084004720976816\n",
      "  validation loss:               0.020641369648663904\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 987 of 1000 took 1.01487088203s\n",
      "  LR:                            3.41288185747e-07\n",
      "  training loss:                 0.0007163719797096532\n",
      "  validation loss:               0.020951330734013545\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 988 of 1000 took 1.02007913589s\n",
      "  LR:                            3.38159236853e-07\n",
      "  training loss:                 0.0005653998363666032\n",
      "  validation loss:               0.020381168828212788\n",
      "  validation error rate:         1.3571428268083505%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 989 of 1000 took 1.01081299782s\n",
      "  LR:                            3.35058974334e-07\n",
      "  training loss:                 0.0006343538471769501\n",
      "  validation loss:               0.02058150524473084\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 990 of 1000 took 1.01489210129s\n",
      "  LR:                            3.31987135193e-07\n",
      "  training loss:                 0.0008188047786330167\n",
      "  validation loss:               0.02007704862268968\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 991 of 1000 took 1.00926589966s\n",
      "  LR:                            3.28943458843e-07\n",
      "  training loss:                 0.0004924088672766992\n",
      "  validation loss:               0.019402107873507442\n",
      "  validation error rate:         1.3571428467652626%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 992 of 1000 took 1.02438306808s\n",
      "  LR:                            3.25927687085e-07\n",
      "  training loss:                 0.0007992766332986388\n",
      "  validation loss:               0.01979345397749707\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 993 of 1000 took 1.01028299332s\n",
      "  LR:                            3.22939564089e-07\n",
      "  training loss:                 0.0005377048362380484\n",
      "  validation loss:               0.01960301246383876\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 994 of 1000 took 1.01672315598s\n",
      "  LR:                            3.19978836369e-07\n",
      "  training loss:                 0.0009128049591321114\n",
      "  validation loss:               0.02013031951316537\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 995 of 1000 took 1.01330113411s\n",
      "  LR:                            3.17045252764e-07\n",
      "  training loss:                 0.0004315428123658946\n",
      "  validation loss:               0.01973796226137584\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 996 of 1000 took 1.0209710598s\n",
      "  LR:                            3.14138564415e-07\n",
      "  training loss:                 0.0004553984742548945\n",
      "  validation loss:               0.02029617339199571\n",
      "  validation error rate:         1.4999999864292997%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 997 of 1000 took 1.02816295624s\n",
      "  LR:                            3.11258524745e-07\n",
      "  training loss:                 0.0004262825679002948\n",
      "  validation loss:               0.020565006324302106\n",
      "  validation error rate:         1.4999999797769956%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 998 of 1000 took 1.02618598938s\n",
      "  LR:                            3.08404889438e-07\n",
      "  training loss:                 0.0006962004975929738\n",
      "  validation loss:               0.02029864909179326\n",
      "  validation error rate:         1.4642857015132904%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 999 of 1000 took 1.02088999748s\n",
      "  LR:                            3.05577416416e-07\n",
      "  training loss:                 0.0005796889644662595\n",
      "  validation loss:               0.020780524115260896\n",
      "  validation error rate:         1.4642856948609864%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n",
      "Epoch 1000 of 1000 took 1.01865792274s\n",
      "  LR:                            3.02775865823e-07\n",
      "  training loss:                 0.0004562309483888197\n",
      "  validation loss:               0.020978946941405802\n",
      "  validation error rate:         1.4285714232495852%\n",
      "  best epoch:                    231\n",
      "  best validation error rate:    1.1428571239645993%\n",
      "  test loss:                     1.833052464893886\n",
      "  test error rate:               90.85714306150165%\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "\n",
    "quantized_net.train(\n",
    "        train_fn,val_fn,\n",
    "        mlp,\n",
    "        batch_size,\n",
    "        LR_start,LR_decay,\n",
    "        num_epochs,\n",
    "        train_dataset,train_label,\n",
    "        val_dataset,val_label,\n",
    "        test_dataset,test_label,\n",
    "        save_path,\n",
    "        shuffle_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7dlCOy3roHbb",
    "outputId": "2cb90ff3-4314-41cc-a6ab-dcb149062338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/theano/gpuarray/dnn.py:184: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to a version >= v5 and <= v7.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "ERROR (theano.gpuarray): Could not initialize pygpu, support disabled\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gpuarray/__init__.py\", line 227, in <module>\n",
      "    use(config.device)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gpuarray/__init__.py\", line 214, in use\n",
      "    init_dev(device, preallocate=preallocate)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/theano/gpuarray/__init__.py\", line 65, in init_dev\n",
      "    raise RuntimeError(\"You can't initialize the GPU in a subprocess if the parent process already did it\")\n",
      "RuntimeError: You can't initialize the GPU in a subprocess if the parent process already did it\n",
      "Loading data...\n",
      "Downloading train-images-idx3-ubyte.gz\n",
      "Downloading train-labels-idx1-ubyte.gz\n",
      "Downloading t10k-images-idx3-ubyte.gz\n",
      "Downloading t10k-labels-idx1-ubyte.gz\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 500 took 14.293s\n",
      "  training loss:\t\t1.222282\n",
      "  validation loss:\t\t0.406566\n",
      "  validation accuracy:\t\t88.68 %\n",
      "Epoch 2 of 500 took 13.995s\n",
      "  training loss:\t\t0.564482\n",
      "  validation loss:\t\t0.305454\n",
      "  validation accuracy:\t\t91.08 %\n",
      "Epoch 3 of 500 took 13.875s\n",
      "  training loss:\t\t0.468965\n",
      "  validation loss:\t\t0.264673\n",
      "  validation accuracy:\t\t92.31 %\n",
      "Epoch 4 of 500 took 14.510s\n",
      "  training loss:\t\t0.407894\n",
      "  validation loss:\t\t0.234372\n",
      "  validation accuracy:\t\t93.24 %\n",
      "Epoch 5 of 500 took 14.099s\n",
      "  training loss:\t\t0.371889\n",
      "  validation loss:\t\t0.210953\n",
      "  validation accuracy:\t\t93.90 %\n",
      "Epoch 6 of 500 took 14.450s\n",
      "  training loss:\t\t0.342364\n",
      "  validation loss:\t\t0.194065\n",
      "  validation accuracy:\t\t94.32 %\n",
      "Epoch 7 of 500 took 14.461s\n",
      "  training loss:\t\t0.317359\n",
      "  validation loss:\t\t0.178816\n",
      "  validation accuracy:\t\t94.88 %\n",
      "Epoch 8 of 500 took 14.433s\n",
      "  training loss:\t\t0.295532\n",
      "  validation loss:\t\t0.167403\n",
      "  validation accuracy:\t\t95.28 %\n",
      "Epoch 9 of 500 took 14.148s\n",
      "  training loss:\t\t0.277304\n",
      "  validation loss:\t\t0.157763\n",
      "  validation accuracy:\t\t95.50 %\n",
      "Epoch 10 of 500 took 14.606s\n",
      "  training loss:\t\t0.265529\n",
      "  validation loss:\t\t0.147360\n",
      "  validation accuracy:\t\t95.83 %\n",
      "Epoch 11 of 500 took 13.819s\n",
      "  training loss:\t\t0.251168\n",
      "  validation loss:\t\t0.141389\n",
      "  validation accuracy:\t\t95.99 %\n",
      "Epoch 12 of 500 took 14.004s\n",
      "  training loss:\t\t0.240690\n",
      "  validation loss:\t\t0.134028\n",
      "  validation accuracy:\t\t96.16 %\n",
      "Epoch 13 of 500 took 14.568s\n",
      "  training loss:\t\t0.232001\n",
      "  validation loss:\t\t0.127327\n",
      "  validation accuracy:\t\t96.43 %\n",
      "Epoch 14 of 500 took 14.113s\n",
      "  training loss:\t\t0.220357\n",
      "  validation loss:\t\t0.122440\n",
      "  validation accuracy:\t\t96.59 %\n",
      "Epoch 15 of 500 took 15.209s\n",
      "  training loss:\t\t0.215486\n",
      "  validation loss:\t\t0.119509\n",
      "  validation accuracy:\t\t96.73 %\n",
      "Epoch 16 of 500 took 14.559s\n",
      "  training loss:\t\t0.206610\n",
      "  validation loss:\t\t0.113838\n",
      "  validation accuracy:\t\t96.84 %\n",
      "Epoch 17 of 500 took 14.730s\n",
      "  training loss:\t\t0.197894\n",
      "  validation loss:\t\t0.110591\n",
      "  validation accuracy:\t\t96.93 %\n",
      "Epoch 18 of 500 took 13.683s\n",
      "  training loss:\t\t0.196100\n",
      "  validation loss:\t\t0.108386\n",
      "  validation accuracy:\t\t96.95 %\n",
      "Epoch 19 of 500 took 14.694s\n",
      "  training loss:\t\t0.186332\n",
      "  validation loss:\t\t0.104129\n",
      "  validation accuracy:\t\t97.02 %\n",
      "Epoch 20 of 500 took 14.609s\n",
      "  training loss:\t\t0.180427\n",
      "  validation loss:\t\t0.101928\n",
      "  validation accuracy:\t\t97.09 %\n",
      "Epoch 21 of 500 took 15.313s\n",
      "  training loss:\t\t0.177558\n",
      "  validation loss:\t\t0.098475\n",
      "  validation accuracy:\t\t97.13 %\n",
      "Epoch 22 of 500 took 14.557s\n",
      "  training loss:\t\t0.169347\n",
      "  validation loss:\t\t0.097151\n",
      "  validation accuracy:\t\t97.19 %\n",
      "Epoch 23 of 500 took 14.591s\n",
      "  training loss:\t\t0.167661\n",
      "  validation loss:\t\t0.095208\n",
      "  validation accuracy:\t\t97.19 %\n",
      "Epoch 24 of 500 took 14.841s\n",
      "  training loss:\t\t0.163884\n",
      "  validation loss:\t\t0.093734\n",
      "  validation accuracy:\t\t97.23 %\n",
      "Epoch 25 of 500 took 14.255s\n",
      "  training loss:\t\t0.160495\n",
      "  validation loss:\t\t0.092053\n",
      "  validation accuracy:\t\t97.31 %\n",
      "Epoch 26 of 500 took 15.454s\n",
      "  training loss:\t\t0.157968\n",
      "  validation loss:\t\t0.090505\n",
      "  validation accuracy:\t\t97.28 %\n",
      "Epoch 27 of 500 took 14.038s\n",
      "  training loss:\t\t0.151880\n",
      "  validation loss:\t\t0.088834\n",
      "  validation accuracy:\t\t97.38 %\n",
      "Epoch 28 of 500 took 14.893s\n",
      "  training loss:\t\t0.148355\n",
      "  validation loss:\t\t0.086234\n",
      "  validation accuracy:\t\t97.46 %\n",
      "Epoch 29 of 500 took 14.462s\n",
      "  training loss:\t\t0.145537\n",
      "  validation loss:\t\t0.085283\n",
      "  validation accuracy:\t\t97.44 %\n",
      "Epoch 30 of 500 took 14.387s\n",
      "  training loss:\t\t0.143398\n",
      "  validation loss:\t\t0.084526\n",
      "  validation accuracy:\t\t97.50 %\n",
      "Epoch 31 of 500 took 14.998s\n",
      "  training loss:\t\t0.141681\n",
      "  validation loss:\t\t0.083057\n",
      "  validation accuracy:\t\t97.43 %\n",
      "Epoch 32 of 500 took 14.445s\n",
      "  training loss:\t\t0.138534\n",
      "  validation loss:\t\t0.082006\n",
      "  validation accuracy:\t\t97.48 %\n",
      "Epoch 33 of 500 took 14.380s\n",
      "  training loss:\t\t0.135522\n",
      "  validation loss:\t\t0.080136\n",
      "  validation accuracy:\t\t97.57 %\n",
      "Epoch 34 of 500 took 14.598s\n",
      "  training loss:\t\t0.133301\n",
      "  validation loss:\t\t0.079570\n",
      "  validation accuracy:\t\t97.60 %\n",
      "Epoch 35 of 500 took 14.111s\n",
      "  training loss:\t\t0.129802\n",
      "  validation loss:\t\t0.078546\n",
      "  validation accuracy:\t\t97.61 %\n",
      "Epoch 36 of 500 took 14.378s\n",
      "  training loss:\t\t0.131234\n",
      "  validation loss:\t\t0.077550\n",
      "  validation accuracy:\t\t97.59 %\n"
     ]
    }
   ],
   "source": [
    "! python ./dummy_dataset_fpga/lasagne_mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwxxdY8Kz--r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
